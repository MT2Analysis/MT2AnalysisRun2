2020-01-31 15:30:47.617407: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-31 15:30:47.634684: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294685000 Hz
2020-01-31 15:30:47.643005: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561f0750a1f0 executing computations on platform Host. Devices:
2020-01-31 15:30:47.643051: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(12,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:287: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(10,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:254: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:133: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(20,10))
/work/wjin/CMSSW_8_0_12/src/CMSSW_8_0_12/src/myMT2Analysis/MLnotebooks/MLbinned_V5/methods.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig=plt.figure(figsize=(16,10))
Background set prepared
Now binning
signal set prepared
Now binning
control set MC prepared
Now binning
control set MC prepared
Now binning
data  llep 182353
control set data prepared
Now binning
data  zll 110140
control set data prepared
Now binning
dataset prepared
dataset sampled
for mass1=  1400 , mass2=  1300
train on  8401  background 174366  signals, validate on  934 background 19374 signals
523098 523098 58122 58122
start training on bin  63

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy improved from 0.50000 to 0.76860, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00004: val_accuracy improved from 0.76860 to 0.80010, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00005: val_accuracy improved from 0.80010 to 0.80309, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00006: val_accuracy improved from 0.80309 to 0.81061, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00007: val_accuracy improved from 0.81061 to 0.81366, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00008: val_accuracy improved from 0.81366 to 0.81714, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00009: val_accuracy improved from 0.81714 to 0.81719, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00010: val_accuracy improved from 0.81719 to 0.81732, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00011: val_accuracy improved from 0.81732 to 0.81858, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00012: val_accuracy improved from 0.81858 to 0.81989, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00013: val_accuracy did not improve from 0.81989

Epoch 00014: val_accuracy improved from 0.81989 to 0.82062, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00015: val_accuracy did not improve from 0.82062

Epoch 00016: val_accuracy did not improve from 0.82062

Epoch 00017: val_accuracy did not improve from 0.82062

Epoch 00018: val_accuracy did not improve from 0.82062

Epoch 00019: val_accuracy did not improve from 0.82062

Epoch 00020: val_accuracy did not improve from 0.82062

Epoch 00021: val_accuracy did not improve from 0.82062

Epoch 00022: val_accuracy did not improve from 0.82062

Epoch 00023: val_accuracy did not improve from 0.82062

Epoch 00024: val_accuracy did not improve from 0.82062

Epoch 00025: val_accuracy did not improve from 0.82062

Epoch 00026: val_accuracy did not improve from 0.82062

Epoch 00027: val_accuracy did not improve from 0.82062

Epoch 00028: val_accuracy improved from 0.82062 to 0.82142, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00029: val_accuracy improved from 0.82142 to 0.82237, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00030: val_accuracy did not improve from 0.82237

Epoch 00031: val_accuracy improved from 0.82237 to 0.82399, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00032: val_accuracy did not improve from 0.82399

Epoch 00033: val_accuracy did not improve from 0.82399

Epoch 00034: val_accuracy did not improve from 0.82399

Epoch 00035: val_accuracy did not improve from 0.82399

Epoch 00036: val_accuracy did not improve from 0.82399

Epoch 00037: val_accuracy improved from 0.82399 to 0.82465, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00038: val_accuracy did not improve from 0.82465

Epoch 00039: val_accuracy did not improve from 0.82465

Epoch 00040: val_accuracy did not improve from 0.82465

Epoch 00041: val_accuracy did not improve from 0.82465

Epoch 00042: val_accuracy did not improve from 0.82465

Epoch 00043: val_accuracy did not improve from 0.82465

Epoch 00044: val_accuracy did not improve from 0.82465

Epoch 00045: val_accuracy did not improve from 0.82465

Epoch 00046: val_accuracy did not improve from 0.82465

Epoch 00047: val_accuracy did not improve from 0.82465

Epoch 00048: val_accuracy did not improve from 0.82465

Epoch 00049: val_accuracy did not improve from 0.82465

Epoch 00050: val_accuracy did not improve from 0.82465

Epoch 00051: val_accuracy did not improve from 0.82465

Epoch 00052: val_accuracy did not improve from 0.82465

Epoch 00053: val_accuracy did not improve from 0.82465

Epoch 00054: val_accuracy did not improve from 0.82465

Epoch 00055: val_accuracy did not improve from 0.82465

Epoch 00056: val_accuracy did not improve from 0.82465

Epoch 00057: val_accuracy did not improve from 0.82465

Epoch 00058: val_accuracy improved from 0.82465 to 0.82706, saving model to weights_T1qqqq_bin_63_try4.best.hdf5

Epoch 00059: val_accuracy did not improve from 0.82706

Epoch 00060: val_accuracy did not improve from 0.82706

Epoch 00061: val_accuracy did not improve from 0.82706

Epoch 00062: val_accuracy did not improve from 0.82706

Epoch 00063: val_accuracy did not improve from 0.82706

Epoch 00064: val_accuracy did not improve from 0.82706

Epoch 00065: val_accuracy did not improve from 0.82706

Epoch 00066: val_accuracy did not improve from 0.82706

Epoch 00067: val_accuracy did not improve from 0.82706

Epoch 00068: val_accuracy did not improve from 0.82706

Epoch 00069: val_accuracy did not improve from 0.82706

Epoch 00070: val_accuracy did not improve from 0.82706

Epoch 00071: val_accuracy did not improve from 0.82706

Epoch 00072: val_accuracy did not improve from 0.82706

Epoch 00073: val_accuracy did not improve from 0.82706

Epoch 00074: val_accuracy did not improve from 0.82706

Epoch 00075: val_accuracy did not improve from 0.82706

Epoch 00076: val_accuracy did not improve from 0.82706

Epoch 00077: val_accuracy did not improve from 0.82706

Epoch 00078: val_accuracy did not improve from 0.82706

Epoch 00079: val_accuracy did not improve from 0.82706

Epoch 00080: val_accuracy did not improve from 0.82706

Epoch 00081: val_accuracy did not improve from 0.82706

Epoch 00082: val_accuracy did not improve from 0.82706

Epoch 00083: val_accuracy did not improve from 0.82706

Epoch 00084: val_accuracy did not improve from 0.82706

Epoch 00085: val_accuracy did not improve from 0.82706

Epoch 00086: val_accuracy did not improve from 0.82706

Epoch 00087: val_accuracy did not improve from 0.82706

Epoch 00088: val_accuracy did not improve from 0.82706

Epoch 00089: val_accuracy did not improve from 0.82706

Epoch 00090: val_accuracy did not improve from 0.82706

Epoch 00091: val_accuracy did not improve from 0.82706

Epoch 00092: val_accuracy did not improve from 0.82706

Epoch 00093: val_accuracy did not improve from 0.82706

Epoch 00094: val_accuracy did not improve from 0.82706

Epoch 00095: val_accuracy did not improve from 0.82706

Epoch 00096: val_accuracy did not improve from 0.82706

Epoch 00097: val_accuracy did not improve from 0.82706

Epoch 00098: val_accuracy did not improve from 0.82706

Epoch 00099: val_accuracy did not improve from 0.82706

Epoch 00100: val_accuracy did not improve from 0.82706

Epoch 00101: val_accuracy did not improve from 0.82706

Epoch 00102: val_accuracy did not improve from 0.82706

Epoch 00103: val_accuracy did not improve from 0.82706

Epoch 00104: val_accuracy did not improve from 0.82706

Epoch 00105: val_accuracy did not improve from 0.82706

Epoch 00106: val_accuracy did not improve from 0.82706

Epoch 00107: val_accuracy did not improve from 0.82706

Epoch 00108: val_accuracy did not improve from 0.82706

Epoch 00109: val_accuracy did not improve from 0.82706

Epoch 00110: val_accuracy did not improve from 0.82706

Epoch 00111: val_accuracy did not improve from 0.82706

Epoch 00112: val_accuracy did not improve from 0.82706

Epoch 00113: val_accuracy did not improve from 0.82706

Epoch 00114: val_accuracy did not improve from 0.82706

Epoch 00115: val_accuracy did not improve from 0.82706

Epoch 00116: val_accuracy did not improve from 0.82706

Epoch 00117: val_accuracy did not improve from 0.82706

Epoch 00118: val_accuracy did not improve from 0.82706

Epoch 00119: val_accuracy did not improve from 0.82706

Epoch 00120: val_accuracy did not improve from 0.82706

Epoch 00121: val_accuracy did not improve from 0.82706

Epoch 00122: val_accuracy did not improve from 0.82706

Epoch 00123: val_accuracy did not improve from 0.82706

Epoch 00124: val_accuracy did not improve from 0.82706

Epoch 00125: val_accuracy did not improve from 0.82706

Epoch 00126: val_accuracy did not improve from 0.82706

Epoch 00127: val_accuracy did not improve from 0.82706

Epoch 00128: val_accuracy did not improve from 0.82706

Epoch 00129: val_accuracy did not improve from 0.82706

Epoch 00130: val_accuracy did not improve from 0.82706

Epoch 00131: val_accuracy did not improve from 0.82706

Epoch 00132: val_accuracy did not improve from 0.82706

Epoch 00133: val_accuracy did not improve from 0.82706

Epoch 00134: val_accuracy did not improve from 0.82706

Epoch 00135: val_accuracy did not improve from 0.82706

Epoch 00136: val_accuracy did not improve from 0.82706

Epoch 00137: val_accuracy did not improve from 0.82706

Epoch 00138: val_accuracy did not improve from 0.82706

Epoch 00139: val_accuracy did not improve from 0.82706

Epoch 00140: val_accuracy did not improve from 0.82706

Epoch 00141: val_accuracy did not improve from 0.82706

Epoch 00142: val_accuracy did not improve from 0.82706

Epoch 00143: val_accuracy did not improve from 0.82706

Epoch 00144: val_accuracy did not improve from 0.82706

Epoch 00145: val_accuracy did not improve from 0.82706

Epoch 00146: val_accuracy did not improve from 0.82706

Epoch 00147: val_accuracy did not improve from 0.82706

Epoch 00148: val_accuracy did not improve from 0.82706

Epoch 00149: val_accuracy did not improve from 0.82706

Epoch 00150: val_accuracy did not improve from 0.82706

Epoch 00151: val_accuracy did not improve from 0.82706

Epoch 00152: val_accuracy did not improve from 0.82706

Epoch 00153: val_accuracy did not improve from 0.82706

Epoch 00154: val_accuracy did not improve from 0.82706

Epoch 00155: val_accuracy did not improve from 0.82706

Epoch 00156: val_accuracy did not improve from 0.82706

Epoch 00157: val_accuracy did not improve from 0.82706

Epoch 00158: val_accuracy did not improve from 0.82706

Epoch 00159: val_accuracy did not improve from 0.82706

Epoch 00160: val_accuracy did not improve from 0.82706

Epoch 00161: val_accuracy did not improve from 0.82706

Epoch 00162: val_accuracy did not improve from 0.82706

Epoch 00163: val_accuracy did not improve from 0.82706

Epoch 00164: val_accuracy did not improve from 0.82706

Epoch 00165: val_accuracy did not improve from 0.82706

Epoch 00166: val_accuracy did not improve from 0.82706

Epoch 00167: val_accuracy did not improve from 0.82706

Epoch 00168: val_accuracy did not improve from 0.82706

Epoch 00169: val_accuracy did not improve from 0.82706

Epoch 00170: val_accuracy did not improve from 0.82706

Epoch 00171: val_accuracy did not improve from 0.82706

Epoch 00172: val_accuracy did not improve from 0.82706

Epoch 00173: val_accuracy did not improve from 0.82706

Epoch 00174: val_accuracy did not improve from 0.82706

Epoch 00175: val_accuracy did not improve from 0.82706

Epoch 00176: val_accuracy did not improve from 0.82706

Epoch 00177: val_accuracy did not improve from 0.82706

Epoch 00178: val_accuracy did not improve from 0.82706

Epoch 00179: val_accuracy did not improve from 0.82706

Epoch 00180: val_accuracy did not improve from 0.82706

Epoch 00181: val_accuracy did not improve from 0.82706

Epoch 00182: val_accuracy did not improve from 0.82706

Epoch 00183: val_accuracy did not improve from 0.82706

Epoch 00184: val_accuracy did not improve from 0.82706

Epoch 00185: val_accuracy did not improve from 0.82706

Epoch 00186: val_accuracy did not improve from 0.82706

Epoch 00187: val_accuracy did not improve from 0.82706

Epoch 00188: val_accuracy did not improve from 0.82706

Epoch 00189: val_accuracy did not improve from 0.82706

Epoch 00190: val_accuracy did not improve from 0.82706

Epoch 00191: val_accuracy did not improve from 0.82706

Epoch 00192: val_accuracy did not improve from 0.82706

Epoch 00193: val_accuracy did not improve from 0.82706

Epoch 00194: val_accuracy did not improve from 0.82706

Epoch 00195: val_accuracy did not improve from 0.82706

Epoch 00196: val_accuracy did not improve from 0.82706

Epoch 00197: val_accuracy did not improve from 0.82706

Epoch 00198: val_accuracy did not improve from 0.82706

Epoch 00199: val_accuracy did not improve from 0.82706

Epoch 00200: val_accuracy did not improve from 0.82706
plotting history
plotting score distribution
plotting significance
finished plotting
train on  6995  background 110541  signals, validate on  778 background 12283 signals
331623 331623 36849 36849
start training on bin  43

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy improved from 0.50000 to 0.59287, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00006: val_accuracy improved from 0.59287 to 0.64277, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00007: val_accuracy improved from 0.64277 to 0.65493, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00008: val_accuracy did not improve from 0.65493

Epoch 00009: val_accuracy did not improve from 0.65493

Epoch 00010: val_accuracy did not improve from 0.65493

Epoch 00011: val_accuracy did not improve from 0.65493

Epoch 00012: val_accuracy did not improve from 0.65493

Epoch 00013: val_accuracy did not improve from 0.65493

Epoch 00014: val_accuracy did not improve from 0.65493

Epoch 00015: val_accuracy did not improve from 0.65493

Epoch 00016: val_accuracy did not improve from 0.65493

Epoch 00017: val_accuracy did not improve from 0.65493

Epoch 00018: val_accuracy did not improve from 0.65493

Epoch 00019: val_accuracy did not improve from 0.65493

Epoch 00020: val_accuracy improved from 0.65493 to 0.65504, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00021: val_accuracy did not improve from 0.65504

Epoch 00022: val_accuracy did not improve from 0.65504

Epoch 00023: val_accuracy did not improve from 0.65504

Epoch 00024: val_accuracy did not improve from 0.65504

Epoch 00025: val_accuracy did not improve from 0.65504

Epoch 00026: val_accuracy did not improve from 0.65504

Epoch 00027: val_accuracy did not improve from 0.65504

Epoch 00028: val_accuracy did not improve from 0.65504

Epoch 00029: val_accuracy did not improve from 0.65504

Epoch 00030: val_accuracy did not improve from 0.65504

Epoch 00031: val_accuracy did not improve from 0.65504

Epoch 00032: val_accuracy did not improve from 0.65504

Epoch 00033: val_accuracy did not improve from 0.65504

Epoch 00034: val_accuracy did not improve from 0.65504

Epoch 00035: val_accuracy did not improve from 0.65504

Epoch 00036: val_accuracy improved from 0.65504 to 0.65901, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00037: val_accuracy improved from 0.65901 to 0.66109, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00038: val_accuracy improved from 0.66109 to 0.66352, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00039: val_accuracy improved from 0.66352 to 0.66459, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00040: val_accuracy improved from 0.66459 to 0.66848, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00041: val_accuracy improved from 0.66848 to 0.67068, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00042: val_accuracy improved from 0.67068 to 0.67285, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00043: val_accuracy did not improve from 0.67285

Epoch 00044: val_accuracy improved from 0.67285 to 0.67667, saving model to weights_T1qqqq_bin_43_try4.best.hdf5

Epoch 00045: val_accuracy did not improve from 0.67667

Epoch 00046: val_accuracy did not improve from 0.67667

Epoch 00047: val_accuracy did not improve from 0.67667

Epoch 00048: val_accuracy did not improve from 0.67667

Epoch 00049: val_accuracy did not improve from 0.67667

Epoch 00050: val_accuracy did not improve from 0.67667

Epoch 00051: val_accuracy did not improve from 0.67667

Epoch 00052: val_accuracy did not improve from 0.67667

Epoch 00053: val_accuracy did not improve from 0.67667

Epoch 00054: val_accuracy did not improve from 0.67667

Epoch 00055: val_accuracy did not improve from 0.67667

Epoch 00056: val_accuracy did not improve from 0.67667

Epoch 00057: val_accuracy did not improve from 0.67667

Epoch 00058: val_accuracy did not improve from 0.67667

Epoch 00059: val_accuracy did not improve from 0.67667

Epoch 00060: val_accuracy did not improve from 0.67667

Epoch 00061: val_accuracy did not improve from 0.67667

Epoch 00062: val_accuracy did not improve from 0.67667

Epoch 00063: val_accuracy did not improve from 0.67667

Epoch 00064: val_accuracy did not improve from 0.67667

Epoch 00065: val_accuracy did not improve from 0.67667

Epoch 00066: val_accuracy did not improve from 0.67667

Epoch 00067: val_accuracy did not improve from 0.67667

Epoch 00068: val_accuracy did not improve from 0.67667

Epoch 00069: val_accuracy did not improve from 0.67667

Epoch 00070: val_accuracy did not improve from 0.67667

Epoch 00071: val_accuracy did not improve from 0.67667

Epoch 00072: val_accuracy did not improve from 0.67667

Epoch 00073: val_accuracy did not improve from 0.67667

Epoch 00074: val_accuracy did not improve from 0.67667

Epoch 00075: val_accuracy did not improve from 0.67667

Epoch 00076: val_accuracy did not improve from 0.67667

Epoch 00077: val_accuracy did not improve from 0.67667

Epoch 00078: val_accuracy did not improve from 0.67667

Epoch 00079: val_accuracy did not improve from 0.67667

Epoch 00080: val_accuracy did not improve from 0.67667

Epoch 00081: val_accuracy did not improve from 0.67667

Epoch 00082: val_accuracy did not improve from 0.67667

Epoch 00083: val_accuracy did not improve from 0.67667

Epoch 00084: val_accuracy did not improve from 0.67667

Epoch 00085: val_accuracy did not improve from 0.67667

Epoch 00086: val_accuracy did not improve from 0.67667

Epoch 00087: val_accuracy did not improve from 0.67667

Epoch 00088: val_accuracy did not improve from 0.67667

Epoch 00089: val_accuracy did not improve from 0.67667

Epoch 00090: val_accuracy did not improve from 0.67667

Epoch 00091: val_accuracy did not improve from 0.67667

Epoch 00092: val_accuracy did not improve from 0.67667

Epoch 00093: val_accuracy did not improve from 0.67667

Epoch 00094: val_accuracy did not improve from 0.67667

Epoch 00095: val_accuracy did not improve from 0.67667

Epoch 00096: val_accuracy did not improve from 0.67667

Epoch 00097: val_accuracy did not improve from 0.67667

Epoch 00098: val_accuracy did not improve from 0.67667

Epoch 00099: val_accuracy did not improve from 0.67667

Epoch 00100: val_accuracy did not improve from 0.67667

Epoch 00101: val_accuracy did not improve from 0.67667

Epoch 00102: val_accuracy did not improve from 0.67667

Epoch 00103: val_accuracy did not improve from 0.67667

Epoch 00104: val_accuracy did not improve from 0.67667

Epoch 00105: val_accuracy did not improve from 0.67667

Epoch 00106: val_accuracy did not improve from 0.67667

Epoch 00107: val_accuracy did not improve from 0.67667

Epoch 00108: val_accuracy did not improve from 0.67667

Epoch 00109: val_accuracy did not improve from 0.67667

Epoch 00110: val_accuracy did not improve from 0.67667

Epoch 00111: val_accuracy did not improve from 0.67667

Epoch 00112: val_accuracy did not improve from 0.67667

Epoch 00113: val_accuracy did not improve from 0.67667

Epoch 00114: val_accuracy did not improve from 0.67667

Epoch 00115: val_accuracy did not improve from 0.67667

Epoch 00116: val_accuracy did not improve from 0.67667

Epoch 00117: val_accuracy did not improve from 0.67667

Epoch 00118: val_accuracy did not improve from 0.67667

Epoch 00119: val_accuracy did not improve from 0.67667

Epoch 00120: val_accuracy did not improve from 0.67667

Epoch 00121: val_accuracy did not improve from 0.67667

Epoch 00122: val_accuracy did not improve from 0.67667

Epoch 00123: val_accuracy did not improve from 0.67667

Epoch 00124: val_accuracy did not improve from 0.67667

Epoch 00125: val_accuracy did not improve from 0.67667

Epoch 00126: val_accuracy did not improve from 0.67667

Epoch 00127: val_accuracy did not improve from 0.67667

Epoch 00128: val_accuracy did not improve from 0.67667

Epoch 00129: val_accuracy did not improve from 0.67667

Epoch 00130: val_accuracy did not improve from 0.67667

Epoch 00131: val_accuracy did not improve from 0.67667

Epoch 00132: val_accuracy did not improve from 0.67667

Epoch 00133: val_accuracy did not improve from 0.67667

Epoch 00134: val_accuracy did not improve from 0.67667

Epoch 00135: val_accuracy did not improve from 0.67667

Epoch 00136: val_accuracy did not improve from 0.67667

Epoch 00137: val_accuracy did not improve from 0.67667

Epoch 00138: val_accuracy did not improve from 0.67667

Epoch 00139: val_accuracy did not improve from 0.67667

Epoch 00140: val_accuracy did not improve from 0.67667

Epoch 00141: val_accuracy did not improve from 0.67667

Epoch 00142: val_accuracy did not improve from 0.67667

Epoch 00143: val_accuracy did not improve from 0.67667

Epoch 00144: val_accuracy did not improve from 0.67667

Epoch 00145: val_accuracy did not improve from 0.67667

Epoch 00146: val_accuracy did not improve from 0.67667

Epoch 00147: val_accuracy did not improve from 0.67667

Epoch 00148: val_accuracy did not improve from 0.67667

Epoch 00149: val_accuracy did not improve from 0.67667

Epoch 00150: val_accuracy did not improve from 0.67667

Epoch 00151: val_accuracy did not improve from 0.67667

Epoch 00152: val_accuracy did not improve from 0.67667

Epoch 00153: val_accuracy did not improve from 0.67667

Epoch 00154: val_accuracy did not improve from 0.67667

Epoch 00155: val_accuracy did not improve from 0.67667

Epoch 00156: val_accuracy did not improve from 0.67667

Epoch 00157: val_accuracy did not improve from 0.67667

Epoch 00158: val_accuracy did not improve from 0.67667

Epoch 00159: val_accuracy did not improve from 0.67667

Epoch 00160: val_accuracy did not improve from 0.67667

Epoch 00161: val_accuracy did not improve from 0.67667

Epoch 00162: val_accuracy did not improve from 0.67667

Epoch 00163: val_accuracy did not improve from 0.67667

Epoch 00164: val_accuracy did not improve from 0.67667

Epoch 00165: val_accuracy did not improve from 0.67667

Epoch 00166: val_accuracy did not improve from 0.67667

Epoch 00167: val_accuracy did not improve from 0.67667

Epoch 00168: val_accuracy did not improve from 0.67667

Epoch 00169: val_accuracy did not improve from 0.67667

Epoch 00170: val_accuracy did not improve from 0.67667

Epoch 00171: val_accuracy did not improve from 0.67667

Epoch 00172: val_accuracy did not improve from 0.67667

Epoch 00173: val_accuracy did not improve from 0.67667

Epoch 00174: val_accuracy did not improve from 0.67667

Epoch 00175: val_accuracy did not improve from 0.67667

Epoch 00176: val_accuracy did not improve from 0.67667

Epoch 00177: val_accuracy did not improve from 0.67667

Epoch 00178: val_accuracy did not improve from 0.67667

Epoch 00179: val_accuracy did not improve from 0.67667

Epoch 00180: val_accuracy did not improve from 0.67667

Epoch 00181: val_accuracy did not improve from 0.67667

Epoch 00182: val_accuracy did not improve from 0.67667

Epoch 00183: val_accuracy did not improve from 0.67667

Epoch 00184: val_accuracy did not improve from 0.67667

Epoch 00185: val_accuracy did not improve from 0.67667

Epoch 00186: val_accuracy did not improve from 0.67667

Epoch 00187: val_accuracy did not improve from 0.67667

Epoch 00188: val_accuracy did not improve from 0.67667

Epoch 00189: val_accuracy did not improve from 0.67667

Epoch 00190: val_accuracy did not improve from 0.67667

Epoch 00191: val_accuracy did not improve from 0.67667

Epoch 00192: val_accuracy did not improve from 0.67667

Epoch 00193: val_accuracy did not improve from 0.67667

Epoch 00194: val_accuracy did not improve from 0.67667

Epoch 00195: val_accuracy did not improve from 0.67667

Epoch 00196: val_accuracy did not improve from 0.67667

Epoch 00197: val_accuracy did not improve from 0.67667

Epoch 00198: val_accuracy did not improve from 0.67667

Epoch 00199: val_accuracy did not improve from 0.67667

Epoch 00200: val_accuracy did not improve from 0.67667
plotting history
plotting score distribution
plotting significance
finished plotting
train on  1516  background 19568  signals, validate on  169 background 2175 signals
58704 58704 6525 6525
start training on bin  68

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy did not improve from 0.50000

Epoch 00010: val_accuracy did not improve from 0.50000

Epoch 00011: val_accuracy did not improve from 0.50000

Epoch 00012: val_accuracy did not improve from 0.50000

Epoch 00013: val_accuracy did not improve from 0.50000

Epoch 00014: val_accuracy did not improve from 0.50000

Epoch 00015: val_accuracy did not improve from 0.50000

Epoch 00016: val_accuracy did not improve from 0.50000

Epoch 00017: val_accuracy did not improve from 0.50000

Epoch 00018: val_accuracy did not improve from 0.50000

Epoch 00019: val_accuracy did not improve from 0.50000

Epoch 00020: val_accuracy improved from 0.50000 to 0.50866, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00021: val_accuracy improved from 0.50866 to 0.55142, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00022: val_accuracy improved from 0.55142 to 0.61801, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00023: val_accuracy improved from 0.61801 to 0.68521, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00024: val_accuracy improved from 0.68521 to 0.74391, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00025: val_accuracy improved from 0.74391 to 0.77326, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00026: val_accuracy improved from 0.77326 to 0.80123, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00027: val_accuracy improved from 0.80123 to 0.81548, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00028: val_accuracy improved from 0.81548 to 0.83050, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00029: val_accuracy did not improve from 0.83050

Epoch 00030: val_accuracy did not improve from 0.83050

Epoch 00031: val_accuracy improved from 0.83050 to 0.83119, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00032: val_accuracy improved from 0.83119 to 0.83195, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00033: val_accuracy did not improve from 0.83195

Epoch 00034: val_accuracy did not improve from 0.83195

Epoch 00035: val_accuracy did not improve from 0.83195

Epoch 00036: val_accuracy did not improve from 0.83195

Epoch 00037: val_accuracy did not improve from 0.83195

Epoch 00038: val_accuracy did not improve from 0.83195

Epoch 00039: val_accuracy did not improve from 0.83195

Epoch 00040: val_accuracy did not improve from 0.83195

Epoch 00041: val_accuracy did not improve from 0.83195

Epoch 00042: val_accuracy did not improve from 0.83195

Epoch 00043: val_accuracy did not improve from 0.83195

Epoch 00044: val_accuracy did not improve from 0.83195

Epoch 00045: val_accuracy did not improve from 0.83195

Epoch 00046: val_accuracy did not improve from 0.83195

Epoch 00047: val_accuracy did not improve from 0.83195

Epoch 00048: val_accuracy did not improve from 0.83195

Epoch 00049: val_accuracy did not improve from 0.83195

Epoch 00050: val_accuracy did not improve from 0.83195

Epoch 00051: val_accuracy did not improve from 0.83195

Epoch 00052: val_accuracy did not improve from 0.83195

Epoch 00053: val_accuracy did not improve from 0.83195

Epoch 00054: val_accuracy did not improve from 0.83195

Epoch 00055: val_accuracy did not improve from 0.83195

Epoch 00056: val_accuracy did not improve from 0.83195

Epoch 00057: val_accuracy did not improve from 0.83195

Epoch 00058: val_accuracy did not improve from 0.83195

Epoch 00059: val_accuracy did not improve from 0.83195

Epoch 00060: val_accuracy did not improve from 0.83195

Epoch 00061: val_accuracy did not improve from 0.83195

Epoch 00062: val_accuracy did not improve from 0.83195

Epoch 00063: val_accuracy did not improve from 0.83195

Epoch 00064: val_accuracy did not improve from 0.83195

Epoch 00065: val_accuracy did not improve from 0.83195

Epoch 00066: val_accuracy did not improve from 0.83195

Epoch 00067: val_accuracy did not improve from 0.83195

Epoch 00068: val_accuracy did not improve from 0.83195

Epoch 00069: val_accuracy did not improve from 0.83195

Epoch 00070: val_accuracy did not improve from 0.83195

Epoch 00071: val_accuracy did not improve from 0.83195

Epoch 00072: val_accuracy did not improve from 0.83195

Epoch 00073: val_accuracy did not improve from 0.83195

Epoch 00074: val_accuracy did not improve from 0.83195

Epoch 00075: val_accuracy did not improve from 0.83195

Epoch 00076: val_accuracy did not improve from 0.83195

Epoch 00077: val_accuracy did not improve from 0.83195

Epoch 00078: val_accuracy did not improve from 0.83195

Epoch 00079: val_accuracy did not improve from 0.83195

Epoch 00080: val_accuracy improved from 0.83195 to 0.83280, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00081: val_accuracy did not improve from 0.83280

Epoch 00082: val_accuracy improved from 0.83280 to 0.83326, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00083: val_accuracy did not improve from 0.83326

Epoch 00084: val_accuracy did not improve from 0.83326

Epoch 00085: val_accuracy improved from 0.83326 to 0.83487, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00086: val_accuracy improved from 0.83487 to 0.83594, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00087: val_accuracy improved from 0.83594 to 0.83609, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00088: val_accuracy did not improve from 0.83609

Epoch 00089: val_accuracy did not improve from 0.83609

Epoch 00090: val_accuracy did not improve from 0.83609

Epoch 00091: val_accuracy did not improve from 0.83609

Epoch 00092: val_accuracy improved from 0.83609 to 0.83632, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00093: val_accuracy improved from 0.83632 to 0.83670, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00094: val_accuracy did not improve from 0.83670

Epoch 00095: val_accuracy did not improve from 0.83670

Epoch 00096: val_accuracy improved from 0.83670 to 0.83716, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00097: val_accuracy improved from 0.83716 to 0.83732, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00098: val_accuracy improved from 0.83732 to 0.83816, saving model to weights_T1qqqq_bin_68_try4.best.hdf5

Epoch 00099: val_accuracy did not improve from 0.83816

Epoch 00100: val_accuracy did not improve from 0.83816

Epoch 00101: val_accuracy did not improve from 0.83816

Epoch 00102: val_accuracy did not improve from 0.83816

Epoch 00103: val_accuracy did not improve from 0.83816

Epoch 00104: val_accuracy did not improve from 0.83816

Epoch 00105: val_accuracy did not improve from 0.83816

Epoch 00106: val_accuracy did not improve from 0.83816

Epoch 00107: val_accuracy did not improve from 0.83816

Epoch 00108: val_accuracy did not improve from 0.83816

Epoch 00109: val_accuracy did not improve from 0.83816

Epoch 00110: val_accuracy did not improve from 0.83816

Epoch 00111: val_accuracy did not improve from 0.83816

Epoch 00112: val_accuracy did not improve from 0.83816

Epoch 00113: val_accuracy did not improve from 0.83816

Epoch 00114: val_accuracy did not improve from 0.83816

Epoch 00115: val_accuracy did not improve from 0.83816

Epoch 00116: val_accuracy did not improve from 0.83816

Epoch 00117: val_accuracy did not improve from 0.83816

Epoch 00118: val_accuracy did not improve from 0.83816

Epoch 00119: val_accuracy did not improve from 0.83816

Epoch 00120: val_accuracy did not improve from 0.83816

Epoch 00121: val_accuracy did not improve from 0.83816

Epoch 00122: val_accuracy did not improve from 0.83816

Epoch 00123: val_accuracy did not improve from 0.83816

Epoch 00124: val_accuracy did not improve from 0.83816

Epoch 00125: val_accuracy did not improve from 0.83816

Epoch 00126: val_accuracy did not improve from 0.83816

Epoch 00127: val_accuracy did not improve from 0.83816

Epoch 00128: val_accuracy did not improve from 0.83816

Epoch 00129: val_accuracy did not improve from 0.83816

Epoch 00130: val_accuracy did not improve from 0.83816

Epoch 00131: val_accuracy did not improve from 0.83816

Epoch 00132: val_accuracy did not improve from 0.83816

Epoch 00133: val_accuracy did not improve from 0.83816

Epoch 00134: val_accuracy did not improve from 0.83816

Epoch 00135: val_accuracy did not improve from 0.83816

Epoch 00136: val_accuracy did not improve from 0.83816

Epoch 00137: val_accuracy did not improve from 0.83816

Epoch 00138: val_accuracy did not improve from 0.83816

Epoch 00139: val_accuracy did not improve from 0.83816

Epoch 00140: val_accuracy did not improve from 0.83816

Epoch 00141: val_accuracy did not improve from 0.83816

Epoch 00142: val_accuracy did not improve from 0.83816

Epoch 00143: val_accuracy did not improve from 0.83816

Epoch 00144: val_accuracy did not improve from 0.83816

Epoch 00145: val_accuracy did not improve from 0.83816

Epoch 00146: val_accuracy did not improve from 0.83816

Epoch 00147: val_accuracy did not improve from 0.83816

Epoch 00148: val_accuracy did not improve from 0.83816

Epoch 00149: val_accuracy did not improve from 0.83816

Epoch 00150: val_accuracy did not improve from 0.83816

Epoch 00151: val_accuracy did not improve from 0.83816

Epoch 00152: val_accuracy did not improve from 0.83816

Epoch 00153: val_accuracy did not improve from 0.83816

Epoch 00154: val_accuracy did not improve from 0.83816

Epoch 00155: val_accuracy did not improve from 0.83816

Epoch 00156: val_accuracy did not improve from 0.83816

Epoch 00157: val_accuracy did not improve from 0.83816

Epoch 00158: val_accuracy did not improve from 0.83816

Epoch 00159: val_accuracy did not improve from 0.83816

Epoch 00160: val_accuracy did not improve from 0.83816

Epoch 00161: val_accuracy did not improve from 0.83816

Epoch 00162: val_accuracy did not improve from 0.83816

Epoch 00163: val_accuracy did not improve from 0.83816

Epoch 00164: val_accuracy did not improve from 0.83816

Epoch 00165: val_accuracy did not improve from 0.83816

Epoch 00166: val_accuracy did not improve from 0.83816

Epoch 00167: val_accuracy did not improve from 0.83816

Epoch 00168: val_accuracy did not improve from 0.83816

Epoch 00169: val_accuracy did not improve from 0.83816

Epoch 00170: val_accuracy did not improve from 0.83816

Epoch 00171: val_accuracy did not improve from 0.83816

Epoch 00172: val_accuracy did not improve from 0.83816

Epoch 00173: val_accuracy did not improve from 0.83816

Epoch 00174: val_accuracy did not improve from 0.83816

Epoch 00175: val_accuracy did not improve from 0.83816

Epoch 00176: val_accuracy did not improve from 0.83816

Epoch 00177: val_accuracy did not improve from 0.83816

Epoch 00178: val_accuracy did not improve from 0.83816

Epoch 00179: val_accuracy did not improve from 0.83816

Epoch 00180: val_accuracy did not improve from 0.83816

Epoch 00181: val_accuracy did not improve from 0.83816

Epoch 00182: val_accuracy did not improve from 0.83816

Epoch 00183: val_accuracy did not improve from 0.83816

Epoch 00184: val_accuracy did not improve from 0.83816

Epoch 00185: val_accuracy did not improve from 0.83816

Epoch 00186: val_accuracy did not improve from 0.83816

Epoch 00187: val_accuracy did not improve from 0.83816

Epoch 00188: val_accuracy did not improve from 0.83816

Epoch 00189: val_accuracy did not improve from 0.83816

Epoch 00190: val_accuracy did not improve from 0.83816

Epoch 00191: val_accuracy did not improve from 0.83816

Epoch 00192: val_accuracy did not improve from 0.83816

Epoch 00193: val_accuracy did not improve from 0.83816

Epoch 00194: val_accuracy did not improve from 0.83816

Epoch 00195: val_accuracy did not improve from 0.83816

Epoch 00196: val_accuracy did not improve from 0.83816

Epoch 00197: val_accuracy did not improve from 0.83816

Epoch 00198: val_accuracy did not improve from 0.83816

Epoch 00199: val_accuracy did not improve from 0.83816

Epoch 00200: val_accuracy did not improve from 0.83816
plotting history
plotting score distribution
plotting significance
finished plotting
train on  7771  background 47975  signals, validate on  864 background 5331 signals
143925 143925 15993 15993
start training on bin  53

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy improved from 0.50000 to 0.53017, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00010: val_accuracy improved from 0.53017 to 0.63509, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00011: val_accuracy improved from 0.63509 to 0.70281, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00012: val_accuracy improved from 0.70281 to 0.73182, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00013: val_accuracy improved from 0.73182 to 0.73967, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00014: val_accuracy improved from 0.73967 to 0.74370, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00015: val_accuracy did not improve from 0.74370

Epoch 00016: val_accuracy did not improve from 0.74370

Epoch 00017: val_accuracy did not improve from 0.74370

Epoch 00018: val_accuracy did not improve from 0.74370

Epoch 00019: val_accuracy did not improve from 0.74370

Epoch 00020: val_accuracy improved from 0.74370 to 0.74445, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00021: val_accuracy improved from 0.74445 to 0.74476, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00022: val_accuracy did not improve from 0.74476

Epoch 00023: val_accuracy improved from 0.74476 to 0.74695, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00024: val_accuracy did not improve from 0.74695

Epoch 00025: val_accuracy improved from 0.74695 to 0.74739, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00026: val_accuracy did not improve from 0.74739

Epoch 00027: val_accuracy did not improve from 0.74739

Epoch 00028: val_accuracy did not improve from 0.74739

Epoch 00029: val_accuracy did not improve from 0.74739

Epoch 00030: val_accuracy did not improve from 0.74739

Epoch 00031: val_accuracy did not improve from 0.74739

Epoch 00032: val_accuracy did not improve from 0.74739

Epoch 00033: val_accuracy did not improve from 0.74739

Epoch 00034: val_accuracy did not improve from 0.74739

Epoch 00035: val_accuracy did not improve from 0.74739

Epoch 00036: val_accuracy did not improve from 0.74739

Epoch 00037: val_accuracy did not improve from 0.74739

Epoch 00038: val_accuracy did not improve from 0.74739

Epoch 00039: val_accuracy did not improve from 0.74739

Epoch 00040: val_accuracy did not improve from 0.74739

Epoch 00041: val_accuracy did not improve from 0.74739

Epoch 00042: val_accuracy did not improve from 0.74739

Epoch 00043: val_accuracy did not improve from 0.74739

Epoch 00044: val_accuracy did not improve from 0.74739

Epoch 00045: val_accuracy did not improve from 0.74739

Epoch 00046: val_accuracy did not improve from 0.74739

Epoch 00047: val_accuracy did not improve from 0.74739

Epoch 00048: val_accuracy did not improve from 0.74739

Epoch 00049: val_accuracy did not improve from 0.74739

Epoch 00050: val_accuracy did not improve from 0.74739

Epoch 00051: val_accuracy did not improve from 0.74739

Epoch 00052: val_accuracy did not improve from 0.74739

Epoch 00053: val_accuracy did not improve from 0.74739

Epoch 00054: val_accuracy did not improve from 0.74739

Epoch 00055: val_accuracy did not improve from 0.74739

Epoch 00056: val_accuracy did not improve from 0.74739

Epoch 00057: val_accuracy did not improve from 0.74739

Epoch 00058: val_accuracy did not improve from 0.74739

Epoch 00059: val_accuracy did not improve from 0.74739

Epoch 00060: val_accuracy did not improve from 0.74739

Epoch 00061: val_accuracy did not improve from 0.74739

Epoch 00062: val_accuracy did not improve from 0.74739

Epoch 00063: val_accuracy did not improve from 0.74739

Epoch 00064: val_accuracy did not improve from 0.74739

Epoch 00065: val_accuracy did not improve from 0.74739

Epoch 00066: val_accuracy did not improve from 0.74739

Epoch 00067: val_accuracy did not improve from 0.74739

Epoch 00068: val_accuracy did not improve from 0.74739

Epoch 00069: val_accuracy did not improve from 0.74739

Epoch 00070: val_accuracy did not improve from 0.74739

Epoch 00071: val_accuracy did not improve from 0.74739

Epoch 00072: val_accuracy did not improve from 0.74739

Epoch 00073: val_accuracy did not improve from 0.74739

Epoch 00074: val_accuracy did not improve from 0.74739

Epoch 00075: val_accuracy did not improve from 0.74739

Epoch 00076: val_accuracy did not improve from 0.74739

Epoch 00077: val_accuracy did not improve from 0.74739

Epoch 00078: val_accuracy did not improve from 0.74739

Epoch 00079: val_accuracy did not improve from 0.74739

Epoch 00080: val_accuracy did not improve from 0.74739

Epoch 00081: val_accuracy did not improve from 0.74739

Epoch 00082: val_accuracy did not improve from 0.74739

Epoch 00083: val_accuracy did not improve from 0.74739

Epoch 00084: val_accuracy did not improve from 0.74739

Epoch 00085: val_accuracy did not improve from 0.74739

Epoch 00086: val_accuracy did not improve from 0.74739

Epoch 00087: val_accuracy did not improve from 0.74739

Epoch 00088: val_accuracy did not improve from 0.74739

Epoch 00089: val_accuracy did not improve from 0.74739

Epoch 00090: val_accuracy did not improve from 0.74739

Epoch 00091: val_accuracy did not improve from 0.74739

Epoch 00092: val_accuracy did not improve from 0.74739

Epoch 00093: val_accuracy did not improve from 0.74739

Epoch 00094: val_accuracy did not improve from 0.74739

Epoch 00095: val_accuracy did not improve from 0.74739

Epoch 00096: val_accuracy did not improve from 0.74739

Epoch 00097: val_accuracy did not improve from 0.74739

Epoch 00098: val_accuracy did not improve from 0.74739

Epoch 00099: val_accuracy did not improve from 0.74739

Epoch 00100: val_accuracy did not improve from 0.74739

Epoch 00101: val_accuracy did not improve from 0.74739

Epoch 00102: val_accuracy did not improve from 0.74739

Epoch 00103: val_accuracy did not improve from 0.74739

Epoch 00104: val_accuracy did not improve from 0.74739

Epoch 00105: val_accuracy did not improve from 0.74739

Epoch 00106: val_accuracy did not improve from 0.74739

Epoch 00107: val_accuracy did not improve from 0.74739

Epoch 00108: val_accuracy did not improve from 0.74739

Epoch 00109: val_accuracy did not improve from 0.74739

Epoch 00110: val_accuracy did not improve from 0.74739

Epoch 00111: val_accuracy did not improve from 0.74739

Epoch 00112: val_accuracy did not improve from 0.74739

Epoch 00113: val_accuracy did not improve from 0.74739

Epoch 00114: val_accuracy improved from 0.74739 to 0.74758, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00115: val_accuracy improved from 0.74758 to 0.74945, saving model to weights_T1qqqq_bin_53_try4.best.hdf5

Epoch 00116: val_accuracy did not improve from 0.74945

Epoch 00117: val_accuracy did not improve from 0.74945

Epoch 00118: val_accuracy did not improve from 0.74945

Epoch 00119: val_accuracy did not improve from 0.74945

Epoch 00120: val_accuracy did not improve from 0.74945

Epoch 00121: val_accuracy did not improve from 0.74945

Epoch 00122: val_accuracy did not improve from 0.74945

Epoch 00123: val_accuracy did not improve from 0.74945

Epoch 00124: val_accuracy did not improve from 0.74945

Epoch 00125: val_accuracy did not improve from 0.74945

Epoch 00126: val_accuracy did not improve from 0.74945

Epoch 00127: val_accuracy did not improve from 0.74945

Epoch 00128: val_accuracy did not improve from 0.74945

Epoch 00129: val_accuracy did not improve from 0.74945

Epoch 00130: val_accuracy did not improve from 0.74945

Epoch 00131: val_accuracy did not improve from 0.74945

Epoch 00132: val_accuracy did not improve from 0.74945

Epoch 00133: val_accuracy did not improve from 0.74945

Epoch 00134: val_accuracy did not improve from 0.74945

Epoch 00135: val_accuracy did not improve from 0.74945

Epoch 00136: val_accuracy did not improve from 0.74945

Epoch 00137: val_accuracy did not improve from 0.74945

Epoch 00138: val_accuracy did not improve from 0.74945

Epoch 00139: val_accuracy did not improve from 0.74945

Epoch 00140: val_accuracy did not improve from 0.74945

Epoch 00141: val_accuracy did not improve from 0.74945

Epoch 00142: val_accuracy did not improve from 0.74945

Epoch 00143: val_accuracy did not improve from 0.74945

Epoch 00144: val_accuracy did not improve from 0.74945

Epoch 00145: val_accuracy did not improve from 0.74945

Epoch 00146: val_accuracy did not improve from 0.74945

Epoch 00147: val_accuracy did not improve from 0.74945

Epoch 00148: val_accuracy did not improve from 0.74945

Epoch 00149: val_accuracy did not improve from 0.74945

Epoch 00150: val_accuracy did not improve from 0.74945

Epoch 00151: val_accuracy did not improve from 0.74945

Epoch 00152: val_accuracy did not improve from 0.74945

Epoch 00153: val_accuracy did not improve from 0.74945

Epoch 00154: val_accuracy did not improve from 0.74945

Epoch 00155: val_accuracy did not improve from 0.74945

Epoch 00156: val_accuracy did not improve from 0.74945

Epoch 00157: val_accuracy did not improve from 0.74945

Epoch 00158: val_accuracy did not improve from 0.74945

Epoch 00159: val_accuracy did not improve from 0.74945

Epoch 00160: val_accuracy did not improve from 0.74945

Epoch 00161: val_accuracy did not improve from 0.74945

Epoch 00162: val_accuracy did not improve from 0.74945

Epoch 00163: val_accuracy did not improve from 0.74945

Epoch 00164: val_accuracy did not improve from 0.74945

Epoch 00165: val_accuracy did not improve from 0.74945

Epoch 00166: val_accuracy did not improve from 0.74945

Epoch 00167: val_accuracy did not improve from 0.74945

Epoch 00168: val_accuracy did not improve from 0.74945

Epoch 00169: val_accuracy did not improve from 0.74945

Epoch 00170: val_accuracy did not improve from 0.74945

Epoch 00171: val_accuracy did not improve from 0.74945

Epoch 00172: val_accuracy did not improve from 0.74945

Epoch 00173: val_accuracy did not improve from 0.74945

Epoch 00174: val_accuracy did not improve from 0.74945

Epoch 00175: val_accuracy did not improve from 0.74945

Epoch 00176: val_accuracy did not improve from 0.74945

Epoch 00177: val_accuracy did not improve from 0.74945

Epoch 00178: val_accuracy did not improve from 0.74945

Epoch 00179: val_accuracy did not improve from 0.74945

Epoch 00180: val_accuracy did not improve from 0.74945

Epoch 00181: val_accuracy did not improve from 0.74945

Epoch 00182: val_accuracy did not improve from 0.74945

Epoch 00183: val_accuracy did not improve from 0.74945

Epoch 00184: val_accuracy did not improve from 0.74945

Epoch 00185: val_accuracy did not improve from 0.74945

Epoch 00186: val_accuracy did not improve from 0.74945

Epoch 00187: val_accuracy did not improve from 0.74945

Epoch 00188: val_accuracy did not improve from 0.74945

Epoch 00189: val_accuracy did not improve from 0.74945

Epoch 00190: val_accuracy did not improve from 0.74945

Epoch 00191: val_accuracy did not improve from 0.74945

Epoch 00192: val_accuracy did not improve from 0.74945

Epoch 00193: val_accuracy did not improve from 0.74945

Epoch 00194: val_accuracy did not improve from 0.74945

Epoch 00195: val_accuracy did not improve from 0.74945

Epoch 00196: val_accuracy did not improve from 0.74945

Epoch 00197: val_accuracy did not improve from 0.74945

Epoch 00198: val_accuracy did not improve from 0.74945

Epoch 00199: val_accuracy did not improve from 0.74945

Epoch 00200: val_accuracy did not improve from 0.74945
plotting history
plotting score distribution
plotting significance
finished plotting
train on  5557  background 31376  signals, validate on  618 background 3487 signals
94128 94128 10461 10461
start training on bin  44

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy did not improve from 0.50000

Epoch 00010: val_accuracy did not improve from 0.50000

Epoch 00011: val_accuracy did not improve from 0.50000

Epoch 00012: val_accuracy did not improve from 0.50000

Epoch 00013: val_accuracy did not improve from 0.50000

Epoch 00014: val_accuracy did not improve from 0.50000

Epoch 00015: val_accuracy did not improve from 0.50000

Epoch 00016: val_accuracy improved from 0.50000 to 0.50311, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00017: val_accuracy improved from 0.50311 to 0.52834, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00018: val_accuracy improved from 0.52834 to 0.55635, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00019: val_accuracy improved from 0.55635 to 0.58575, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00020: val_accuracy improved from 0.58575 to 0.59660, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00021: val_accuracy improved from 0.59660 to 0.61863, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00022: val_accuracy improved from 0.61863 to 0.62355, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00023: val_accuracy improved from 0.62355 to 0.63340, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00024: val_accuracy improved from 0.63340 to 0.64855, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00025: val_accuracy improved from 0.64855 to 0.65615, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00026: val_accuracy improved from 0.65615 to 0.66246, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00027: val_accuracy improved from 0.66246 to 0.67073, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00028: val_accuracy improved from 0.67073 to 0.67235, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00029: val_accuracy improved from 0.67235 to 0.67341, saving model to weights_T1qqqq_bin_44_try4.best.hdf5

Epoch 00030: val_accuracy did not improve from 0.67341

Epoch 00031: val_accuracy did not improve from 0.67341

Epoch 00032: val_accuracy did not improve from 0.67341

Epoch 00033: val_accuracy did not improve from 0.67341

Epoch 00034: val_accuracy did not improve from 0.67341

Epoch 00035: val_accuracy did not improve from 0.67341

Epoch 00036: val_accuracy did not improve from 0.67341

Epoch 00037: val_accuracy did not improve from 0.67341

Epoch 00038: val_accuracy did not improve from 0.67341

Epoch 00039: val_accuracy did not improve from 0.67341

Epoch 00040: val_accuracy did not improve from 0.67341

Epoch 00041: val_accuracy did not improve from 0.67341

Epoch 00042: val_accuracy did not improve from 0.67341

Epoch 00043: val_accuracy did not improve from 0.67341

Epoch 00044: val_accuracy did not improve from 0.67341

Epoch 00045: val_accuracy did not improve from 0.67341

Epoch 00046: val_accuracy did not improve from 0.67341

Epoch 00047: val_accuracy did not improve from 0.67341

Epoch 00048: val_accuracy did not improve from 0.67341

Epoch 00049: val_accuracy did not improve from 0.67341

Epoch 00050: val_accuracy did not improve from 0.67341

Epoch 00051: val_accuracy did not improve from 0.67341

Epoch 00052: val_accuracy did not improve from 0.67341

Epoch 00053: val_accuracy did not improve from 0.67341

Epoch 00054: val_accuracy did not improve from 0.67341

Epoch 00055: val_accuracy did not improve from 0.67341

Epoch 00056: val_accuracy did not improve from 0.67341

Epoch 00057: val_accuracy did not improve from 0.67341

Epoch 00058: val_accuracy did not improve from 0.67341

Epoch 00059: val_accuracy did not improve from 0.67341

Epoch 00060: val_accuracy did not improve from 0.67341

Epoch 00061: val_accuracy did not improve from 0.67341

Epoch 00062: val_accuracy did not improve from 0.67341

Epoch 00063: val_accuracy did not improve from 0.67341

Epoch 00064: val_accuracy did not improve from 0.67341

Epoch 00065: val_accuracy did not improve from 0.67341

Epoch 00066: val_accuracy did not improve from 0.67341

Epoch 00067: val_accuracy did not improve from 0.67341

Epoch 00068: val_accuracy did not improve from 0.67341

Epoch 00069: val_accuracy did not improve from 0.67341

Epoch 00070: val_accuracy did not improve from 0.67341

Epoch 00071: val_accuracy did not improve from 0.67341

Epoch 00072: val_accuracy did not improve from 0.67341

Epoch 00073: val_accuracy did not improve from 0.67341

Epoch 00074: val_accuracy did not improve from 0.67341

Epoch 00075: val_accuracy did not improve from 0.67341

Epoch 00076: val_accuracy did not improve from 0.67341

Epoch 00077: val_accuracy did not improve from 0.67341

Epoch 00078: val_accuracy did not improve from 0.67341

Epoch 00079: val_accuracy did not improve from 0.67341

Epoch 00080: val_accuracy did not improve from 0.67341

Epoch 00081: val_accuracy did not improve from 0.67341

Epoch 00082: val_accuracy did not improve from 0.67341

Epoch 00083: val_accuracy did not improve from 0.67341

Epoch 00084: val_accuracy did not improve from 0.67341

Epoch 00085: val_accuracy did not improve from 0.67341

Epoch 00086: val_accuracy did not improve from 0.67341

Epoch 00087: val_accuracy did not improve from 0.67341

Epoch 00088: val_accuracy did not improve from 0.67341

Epoch 00089: val_accuracy did not improve from 0.67341

Epoch 00090: val_accuracy did not improve from 0.67341

Epoch 00091: val_accuracy did not improve from 0.67341

Epoch 00092: val_accuracy did not improve from 0.67341

Epoch 00093: val_accuracy did not improve from 0.67341

Epoch 00094: val_accuracy did not improve from 0.67341

Epoch 00095: val_accuracy did not improve from 0.67341

Epoch 00096: val_accuracy did not improve from 0.67341

Epoch 00097: val_accuracy did not improve from 0.67341

Epoch 00098: val_accuracy did not improve from 0.67341

Epoch 00099: val_accuracy did not improve from 0.67341

Epoch 00100: val_accuracy did not improve from 0.67341

Epoch 00101: val_accuracy did not improve from 0.67341

Epoch 00102: val_accuracy did not improve from 0.67341

Epoch 00103: val_accuracy did not improve from 0.67341

Epoch 00104: val_accuracy did not improve from 0.67341

Epoch 00105: val_accuracy did not improve from 0.67341

Epoch 00106: val_accuracy did not improve from 0.67341

Epoch 00107: val_accuracy did not improve from 0.67341

Epoch 00108: val_accuracy did not improve from 0.67341

Epoch 00109: val_accuracy did not improve from 0.67341

Epoch 00110: val_accuracy did not improve from 0.67341

Epoch 00111: val_accuracy did not improve from 0.67341

Epoch 00112: val_accuracy did not improve from 0.67341

Epoch 00113: val_accuracy did not improve from 0.67341

Epoch 00114: val_accuracy did not improve from 0.67341

Epoch 00115: val_accuracy did not improve from 0.67341

Epoch 00116: val_accuracy did not improve from 0.67341

Epoch 00117: val_accuracy did not improve from 0.67341

Epoch 00118: val_accuracy did not improve from 0.67341

Epoch 00119: val_accuracy did not improve from 0.67341

Epoch 00120: val_accuracy did not improve from 0.67341

Epoch 00121: val_accuracy did not improve from 0.67341

Epoch 00122: val_accuracy did not improve from 0.67341

Epoch 00123: val_accuracy did not improve from 0.67341

Epoch 00124: val_accuracy did not improve from 0.67341

Epoch 00125: val_accuracy did not improve from 0.67341

Epoch 00126: val_accuracy did not improve from 0.67341

Epoch 00127: val_accuracy did not improve from 0.67341

Epoch 00128: val_accuracy did not improve from 0.67341

Epoch 00129: val_accuracy did not improve from 0.67341

Epoch 00130: val_accuracy did not improve from 0.67341

Epoch 00131: val_accuracy did not improve from 0.67341

Epoch 00132: val_accuracy did not improve from 0.67341

Epoch 00133: val_accuracy did not improve from 0.67341

Epoch 00134: val_accuracy did not improve from 0.67341

Epoch 00135: val_accuracy did not improve from 0.67341

Epoch 00136: val_accuracy did not improve from 0.67341

Epoch 00137: val_accuracy did not improve from 0.67341

Epoch 00138: val_accuracy did not improve from 0.67341

Epoch 00139: val_accuracy did not improve from 0.67341

Epoch 00140: val_accuracy did not improve from 0.67341

Epoch 00141: val_accuracy did not improve from 0.67341

Epoch 00142: val_accuracy did not improve from 0.67341

Epoch 00143: val_accuracy did not improve from 0.67341

Epoch 00144: val_accuracy did not improve from 0.67341

Epoch 00145: val_accuracy did not improve from 0.67341

Epoch 00146: val_accuracy did not improve from 0.67341

Epoch 00147: val_accuracy did not improve from 0.67341

Epoch 00148: val_accuracy did not improve from 0.67341

Epoch 00149: val_accuracy did not improve from 0.67341

Epoch 00150: val_accuracy did not improve from 0.67341

Epoch 00151: val_accuracy did not improve from 0.67341

Epoch 00152: val_accuracy did not improve from 0.67341

Epoch 00153: val_accuracy did not improve from 0.67341

Epoch 00154: val_accuracy did not improve from 0.67341

Epoch 00155: val_accuracy did not improve from 0.67341

Epoch 00156: val_accuracy did not improve from 0.67341

Epoch 00157: val_accuracy did not improve from 0.67341

Epoch 00158: val_accuracy did not improve from 0.67341

Epoch 00159: val_accuracy did not improve from 0.67341

Epoch 00160: val_accuracy did not improve from 0.67341

Epoch 00161: val_accuracy did not improve from 0.67341

Epoch 00162: val_accuracy did not improve from 0.67341

Epoch 00163: val_accuracy did not improve from 0.67341

Epoch 00164: val_accuracy did not improve from 0.67341

Epoch 00165: val_accuracy did not improve from 0.67341

Epoch 00166: val_accuracy did not improve from 0.67341

Epoch 00167: val_accuracy did not improve from 0.67341

Epoch 00168: val_accuracy did not improve from 0.67341

Epoch 00169: val_accuracy did not improve from 0.67341

Epoch 00170: val_accuracy did not improve from 0.67341

Epoch 00171: val_accuracy did not improve from 0.67341

Epoch 00172: val_accuracy did not improve from 0.67341

Epoch 00173: val_accuracy did not improve from 0.67341

Epoch 00174: val_accuracy did not improve from 0.67341

Epoch 00175: val_accuracy did not improve from 0.67341

Epoch 00176: val_accuracy did not improve from 0.67341

Epoch 00177: val_accuracy did not improve from 0.67341

Epoch 00178: val_accuracy did not improve from 0.67341

Epoch 00179: val_accuracy did not improve from 0.67341

Epoch 00180: val_accuracy did not improve from 0.67341

Epoch 00181: val_accuracy did not improve from 0.67341

Epoch 00182: val_accuracy did not improve from 0.67341

Epoch 00183: val_accuracy did not improve from 0.67341

Epoch 00184: val_accuracy did not improve from 0.67341

Epoch 00185: val_accuracy did not improve from 0.67341

Epoch 00186: val_accuracy did not improve from 0.67341

Epoch 00187: val_accuracy did not improve from 0.67341

Epoch 00188: val_accuracy did not improve from 0.67341

Epoch 00189: val_accuracy did not improve from 0.67341

Epoch 00190: val_accuracy did not improve from 0.67341

Epoch 00191: val_accuracy did not improve from 0.67341

Epoch 00192: val_accuracy did not improve from 0.67341

Epoch 00193: val_accuracy did not improve from 0.67341

Epoch 00194: val_accuracy did not improve from 0.67341

Epoch 00195: val_accuracy did not improve from 0.67341

Epoch 00196: val_accuracy did not improve from 0.67341

Epoch 00197: val_accuracy did not improve from 0.67341

Epoch 00198: val_accuracy did not improve from 0.67341

Epoch 00199: val_accuracy did not improve from 0.67341

Epoch 00200: val_accuracy did not improve from 0.67341
plotting history
plotting score distribution
plotting significance
finished plotting
train on  3869  background 14516  signals, validate on  430 background 1613 signals
43548 43548 4839 4839
start training on bin  54

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy did not improve from 0.50000

Epoch 00010: val_accuracy did not improve from 0.50000

Epoch 00011: val_accuracy did not improve from 0.50000

Epoch 00012: val_accuracy did not improve from 0.50000

Epoch 00013: val_accuracy did not improve from 0.50000

Epoch 00014: val_accuracy did not improve from 0.50000

Epoch 00015: val_accuracy did not improve from 0.50000

Epoch 00016: val_accuracy did not improve from 0.50000

Epoch 00017: val_accuracy did not improve from 0.50000

Epoch 00018: val_accuracy did not improve from 0.50000

Epoch 00019: val_accuracy did not improve from 0.50000

Epoch 00020: val_accuracy did not improve from 0.50000

Epoch 00021: val_accuracy did not improve from 0.50000

Epoch 00022: val_accuracy did not improve from 0.50000

Epoch 00023: val_accuracy did not improve from 0.50000

Epoch 00024: val_accuracy did not improve from 0.50000

Epoch 00025: val_accuracy did not improve from 0.50000

Epoch 00026: val_accuracy did not improve from 0.50000

Epoch 00027: val_accuracy improved from 0.50000 to 0.50672, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00028: val_accuracy improved from 0.50672 to 0.52139, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00029: val_accuracy improved from 0.52139 to 0.56065, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00030: val_accuracy improved from 0.56065 to 0.58762, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00031: val_accuracy improved from 0.58762 to 0.62224, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00032: val_accuracy improved from 0.62224 to 0.65148, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00033: val_accuracy improved from 0.65148 to 0.67163, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00034: val_accuracy improved from 0.67163 to 0.69312, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00035: val_accuracy improved from 0.69312 to 0.71182, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00036: val_accuracy improved from 0.71182 to 0.72329, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00037: val_accuracy improved from 0.72329 to 0.73021, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00038: val_accuracy improved from 0.73021 to 0.73321, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00039: val_accuracy improved from 0.73321 to 0.73569, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00040: val_accuracy did not improve from 0.73569

Epoch 00041: val_accuracy did not improve from 0.73569

Epoch 00042: val_accuracy did not improve from 0.73569

Epoch 00043: val_accuracy did not improve from 0.73569

Epoch 00044: val_accuracy did not improve from 0.73569

Epoch 00045: val_accuracy did not improve from 0.73569

Epoch 00046: val_accuracy did not improve from 0.73569

Epoch 00047: val_accuracy did not improve from 0.73569

Epoch 00048: val_accuracy did not improve from 0.73569

Epoch 00049: val_accuracy did not improve from 0.73569

Epoch 00050: val_accuracy did not improve from 0.73569

Epoch 00051: val_accuracy did not improve from 0.73569

Epoch 00052: val_accuracy did not improve from 0.73569

Epoch 00053: val_accuracy did not improve from 0.73569

Epoch 00054: val_accuracy did not improve from 0.73569

Epoch 00055: val_accuracy did not improve from 0.73569

Epoch 00056: val_accuracy did not improve from 0.73569

Epoch 00057: val_accuracy did not improve from 0.73569

Epoch 00058: val_accuracy did not improve from 0.73569

Epoch 00059: val_accuracy did not improve from 0.73569

Epoch 00060: val_accuracy improved from 0.73569 to 0.73755, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00061: val_accuracy did not improve from 0.73755

Epoch 00062: val_accuracy improved from 0.73755 to 0.74168, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00063: val_accuracy improved from 0.74168 to 0.74334, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00064: val_accuracy improved from 0.74334 to 0.74654, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00065: val_accuracy improved from 0.74654 to 0.74778, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00066: val_accuracy did not improve from 0.74778

Epoch 00067: val_accuracy did not improve from 0.74778

Epoch 00068: val_accuracy did not improve from 0.74778

Epoch 00069: val_accuracy did not improve from 0.74778

Epoch 00070: val_accuracy did not improve from 0.74778

Epoch 00071: val_accuracy improved from 0.74778 to 0.74881, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00072: val_accuracy improved from 0.74881 to 0.74985, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00073: val_accuracy did not improve from 0.74985

Epoch 00074: val_accuracy did not improve from 0.74985

Epoch 00075: val_accuracy did not improve from 0.74985

Epoch 00076: val_accuracy did not improve from 0.74985

Epoch 00077: val_accuracy did not improve from 0.74985

Epoch 00078: val_accuracy did not improve from 0.74985

Epoch 00079: val_accuracy did not improve from 0.74985

Epoch 00080: val_accuracy did not improve from 0.74985

Epoch 00081: val_accuracy did not improve from 0.74985

Epoch 00082: val_accuracy did not improve from 0.74985

Epoch 00083: val_accuracy did not improve from 0.74985

Epoch 00084: val_accuracy did not improve from 0.74985

Epoch 00085: val_accuracy did not improve from 0.74985

Epoch 00086: val_accuracy did not improve from 0.74985

Epoch 00087: val_accuracy did not improve from 0.74985

Epoch 00088: val_accuracy did not improve from 0.74985

Epoch 00089: val_accuracy did not improve from 0.74985

Epoch 00090: val_accuracy did not improve from 0.74985

Epoch 00091: val_accuracy did not improve from 0.74985

Epoch 00092: val_accuracy did not improve from 0.74985

Epoch 00093: val_accuracy did not improve from 0.74985

Epoch 00094: val_accuracy did not improve from 0.74985

Epoch 00095: val_accuracy did not improve from 0.74985

Epoch 00096: val_accuracy did not improve from 0.74985

Epoch 00097: val_accuracy did not improve from 0.74985

Epoch 00098: val_accuracy did not improve from 0.74985

Epoch 00099: val_accuracy did not improve from 0.74985

Epoch 00100: val_accuracy did not improve from 0.74985

Epoch 00101: val_accuracy did not improve from 0.74985

Epoch 00102: val_accuracy did not improve from 0.74985

Epoch 00103: val_accuracy did not improve from 0.74985

Epoch 00104: val_accuracy did not improve from 0.74985

Epoch 00105: val_accuracy did not improve from 0.74985

Epoch 00106: val_accuracy did not improve from 0.74985

Epoch 00107: val_accuracy did not improve from 0.74985

Epoch 00108: val_accuracy did not improve from 0.74985

Epoch 00109: val_accuracy did not improve from 0.74985

Epoch 00110: val_accuracy did not improve from 0.74985

Epoch 00111: val_accuracy did not improve from 0.74985

Epoch 00112: val_accuracy did not improve from 0.74985

Epoch 00113: val_accuracy did not improve from 0.74985

Epoch 00114: val_accuracy did not improve from 0.74985

Epoch 00115: val_accuracy did not improve from 0.74985

Epoch 00116: val_accuracy did not improve from 0.74985

Epoch 00117: val_accuracy did not improve from 0.74985

Epoch 00118: val_accuracy did not improve from 0.74985

Epoch 00119: val_accuracy did not improve from 0.74985

Epoch 00120: val_accuracy did not improve from 0.74985

Epoch 00121: val_accuracy did not improve from 0.74985

Epoch 00122: val_accuracy did not improve from 0.74985

Epoch 00123: val_accuracy did not improve from 0.74985

Epoch 00124: val_accuracy did not improve from 0.74985

Epoch 00125: val_accuracy did not improve from 0.74985

Epoch 00126: val_accuracy did not improve from 0.74985

Epoch 00127: val_accuracy did not improve from 0.74985

Epoch 00128: val_accuracy did not improve from 0.74985

Epoch 00129: val_accuracy did not improve from 0.74985

Epoch 00130: val_accuracy did not improve from 0.74985

Epoch 00131: val_accuracy did not improve from 0.74985

Epoch 00132: val_accuracy did not improve from 0.74985

Epoch 00133: val_accuracy did not improve from 0.74985

Epoch 00134: val_accuracy did not improve from 0.74985

Epoch 00135: val_accuracy did not improve from 0.74985

Epoch 00136: val_accuracy did not improve from 0.74985

Epoch 00137: val_accuracy did not improve from 0.74985

Epoch 00138: val_accuracy did not improve from 0.74985

Epoch 00139: val_accuracy did not improve from 0.74985

Epoch 00140: val_accuracy did not improve from 0.74985

Epoch 00141: val_accuracy did not improve from 0.74985

Epoch 00142: val_accuracy did not improve from 0.74985

Epoch 00143: val_accuracy did not improve from 0.74985

Epoch 00144: val_accuracy did not improve from 0.74985

Epoch 00145: val_accuracy did not improve from 0.74985

Epoch 00146: val_accuracy did not improve from 0.74985

Epoch 00147: val_accuracy did not improve from 0.74985

Epoch 00148: val_accuracy did not improve from 0.74985

Epoch 00149: val_accuracy did not improve from 0.74985

Epoch 00150: val_accuracy did not improve from 0.74985

Epoch 00151: val_accuracy did not improve from 0.74985

Epoch 00152: val_accuracy did not improve from 0.74985

Epoch 00153: val_accuracy did not improve from 0.74985

Epoch 00154: val_accuracy did not improve from 0.74985

Epoch 00155: val_accuracy did not improve from 0.74985

Epoch 00156: val_accuracy did not improve from 0.74985

Epoch 00157: val_accuracy did not improve from 0.74985

Epoch 00158: val_accuracy did not improve from 0.74985

Epoch 00159: val_accuracy did not improve from 0.74985

Epoch 00160: val_accuracy did not improve from 0.74985

Epoch 00161: val_accuracy did not improve from 0.74985

Epoch 00162: val_accuracy did not improve from 0.74985

Epoch 00163: val_accuracy did not improve from 0.74985

Epoch 00164: val_accuracy did not improve from 0.74985

Epoch 00165: val_accuracy did not improve from 0.74985

Epoch 00166: val_accuracy did not improve from 0.74985

Epoch 00167: val_accuracy did not improve from 0.74985

Epoch 00168: val_accuracy did not improve from 0.74985

Epoch 00169: val_accuracy did not improve from 0.74985

Epoch 00170: val_accuracy did not improve from 0.74985

Epoch 00171: val_accuracy did not improve from 0.74985

Epoch 00172: val_accuracy did not improve from 0.74985

Epoch 00173: val_accuracy did not improve from 0.74985

Epoch 00174: val_accuracy did not improve from 0.74985

Epoch 00175: val_accuracy did not improve from 0.74985

Epoch 00176: val_accuracy did not improve from 0.74985

Epoch 00177: val_accuracy did not improve from 0.74985

Epoch 00178: val_accuracy did not improve from 0.74985

Epoch 00179: val_accuracy did not improve from 0.74985

Epoch 00180: val_accuracy did not improve from 0.74985

Epoch 00181: val_accuracy improved from 0.74985 to 0.75046, saving model to weights_T1qqqq_bin_54_try4.best.hdf5

Epoch 00182: val_accuracy did not improve from 0.75046

Epoch 00183: val_accuracy did not improve from 0.75046

Epoch 00184: val_accuracy did not improve from 0.75046

Epoch 00185: val_accuracy did not improve from 0.75046

Epoch 00186: val_accuracy did not improve from 0.75046

Epoch 00187: val_accuracy did not improve from 0.75046

Epoch 00188: val_accuracy did not improve from 0.75046

Epoch 00189: val_accuracy did not improve from 0.75046

Epoch 00190: val_accuracy did not improve from 0.75046

Epoch 00191: val_accuracy did not improve from 0.75046

Epoch 00192: val_accuracy did not improve from 0.75046

Epoch 00193: val_accuracy did not improve from 0.75046

Epoch 00194: val_accuracy did not improve from 0.75046

Epoch 00195: val_accuracy did not improve from 0.75046

Epoch 00196: val_accuracy did not improve from 0.75046

Epoch 00197: val_accuracy did not improve from 0.75046

Epoch 00198: val_accuracy did not improve from 0.75046

Epoch 00199: val_accuracy did not improve from 0.75046

Epoch 00200: val_accuracy did not improve from 0.75046
plotting history
plotting score distribution
plotting significance
finished plotting
train on  31527  background 371851  signals, validate on  3503 background 41317 signals
1115553 1115553 123951 123951
start training on bin  31

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00002: val_accuracy improved from 0.50000 to 0.85137, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00003: val_accuracy improved from 0.85137 to 0.86087, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00004: val_accuracy improved from 0.86087 to 0.86312, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00005: val_accuracy improved from 0.86312 to 0.86372, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00006: val_accuracy improved from 0.86372 to 0.86477, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00007: val_accuracy did not improve from 0.86477

Epoch 00008: val_accuracy did not improve from 0.86477

Epoch 00009: val_accuracy did not improve from 0.86477

Epoch 00010: val_accuracy improved from 0.86477 to 0.86479, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00011: val_accuracy improved from 0.86479 to 0.86574, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00012: val_accuracy improved from 0.86574 to 0.86691, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00013: val_accuracy improved from 0.86691 to 0.86905, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00014: val_accuracy did not improve from 0.86905

Epoch 00015: val_accuracy improved from 0.86905 to 0.86933, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00016: val_accuracy did not improve from 0.86933

Epoch 00017: val_accuracy improved from 0.86933 to 0.86974, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00018: val_accuracy improved from 0.86974 to 0.86974, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00019: val_accuracy did not improve from 0.86974

Epoch 00020: val_accuracy did not improve from 0.86974

Epoch 00021: val_accuracy did not improve from 0.86974

Epoch 00022: val_accuracy did not improve from 0.86974

Epoch 00023: val_accuracy did not improve from 0.86974

Epoch 00024: val_accuracy did not improve from 0.86974

Epoch 00025: val_accuracy did not improve from 0.86974

Epoch 00026: val_accuracy did not improve from 0.86974

Epoch 00027: val_accuracy did not improve from 0.86974

Epoch 00028: val_accuracy did not improve from 0.86974

Epoch 00029: val_accuracy did not improve from 0.86974

Epoch 00030: val_accuracy did not improve from 0.86974

Epoch 00031: val_accuracy did not improve from 0.86974

Epoch 00032: val_accuracy did not improve from 0.86974

Epoch 00033: val_accuracy did not improve from 0.86974

Epoch 00034: val_accuracy did not improve from 0.86974

Epoch 00035: val_accuracy did not improve from 0.86974

Epoch 00036: val_accuracy did not improve from 0.86974

Epoch 00037: val_accuracy did not improve from 0.86974

Epoch 00038: val_accuracy did not improve from 0.86974

Epoch 00039: val_accuracy did not improve from 0.86974

Epoch 00040: val_accuracy did not improve from 0.86974

Epoch 00041: val_accuracy did not improve from 0.86974

Epoch 00042: val_accuracy did not improve from 0.86974

Epoch 00043: val_accuracy did not improve from 0.86974

Epoch 00044: val_accuracy did not improve from 0.86974

Epoch 00045: val_accuracy did not improve from 0.86974

Epoch 00046: val_accuracy did not improve from 0.86974

Epoch 00047: val_accuracy did not improve from 0.86974

Epoch 00048: val_accuracy did not improve from 0.86974

Epoch 00049: val_accuracy did not improve from 0.86974

Epoch 00050: val_accuracy did not improve from 0.86974

Epoch 00051: val_accuracy did not improve from 0.86974

Epoch 00052: val_accuracy did not improve from 0.86974

Epoch 00053: val_accuracy did not improve from 0.86974

Epoch 00054: val_accuracy did not improve from 0.86974

Epoch 00055: val_accuracy did not improve from 0.86974

Epoch 00056: val_accuracy did not improve from 0.86974

Epoch 00057: val_accuracy did not improve from 0.86974

Epoch 00058: val_accuracy did not improve from 0.86974

Epoch 00059: val_accuracy did not improve from 0.86974

Epoch 00060: val_accuracy did not improve from 0.86974

Epoch 00061: val_accuracy did not improve from 0.86974

Epoch 00062: val_accuracy did not improve from 0.86974

Epoch 00063: val_accuracy did not improve from 0.86974

Epoch 00064: val_accuracy did not improve from 0.86974

Epoch 00065: val_accuracy did not improve from 0.86974

Epoch 00066: val_accuracy did not improve from 0.86974

Epoch 00067: val_accuracy did not improve from 0.86974

Epoch 00068: val_accuracy did not improve from 0.86974

Epoch 00069: val_accuracy did not improve from 0.86974

Epoch 00070: val_accuracy did not improve from 0.86974

Epoch 00071: val_accuracy did not improve from 0.86974

Epoch 00072: val_accuracy did not improve from 0.86974

Epoch 00073: val_accuracy did not improve from 0.86974

Epoch 00074: val_accuracy did not improve from 0.86974

Epoch 00075: val_accuracy did not improve from 0.86974

Epoch 00076: val_accuracy did not improve from 0.86974

Epoch 00077: val_accuracy did not improve from 0.86974

Epoch 00078: val_accuracy did not improve from 0.86974

Epoch 00079: val_accuracy did not improve from 0.86974

Epoch 00080: val_accuracy did not improve from 0.86974

Epoch 00081: val_accuracy did not improve from 0.86974

Epoch 00082: val_accuracy did not improve from 0.86974

Epoch 00083: val_accuracy did not improve from 0.86974

Epoch 00084: val_accuracy did not improve from 0.86974

Epoch 00085: val_accuracy did not improve from 0.86974

Epoch 00086: val_accuracy did not improve from 0.86974

Epoch 00087: val_accuracy did not improve from 0.86974

Epoch 00088: val_accuracy did not improve from 0.86974

Epoch 00089: val_accuracy did not improve from 0.86974

Epoch 00090: val_accuracy did not improve from 0.86974

Epoch 00091: val_accuracy did not improve from 0.86974

Epoch 00092: val_accuracy did not improve from 0.86974

Epoch 00093: val_accuracy did not improve from 0.86974

Epoch 00094: val_accuracy did not improve from 0.86974

Epoch 00095: val_accuracy did not improve from 0.86974

Epoch 00096: val_accuracy did not improve from 0.86974

Epoch 00097: val_accuracy did not improve from 0.86974

Epoch 00098: val_accuracy did not improve from 0.86974

Epoch 00099: val_accuracy did not improve from 0.86974

Epoch 00100: val_accuracy did not improve from 0.86974

Epoch 00101: val_accuracy did not improve from 0.86974

Epoch 00102: val_accuracy did not improve from 0.86974

Epoch 00103: val_accuracy did not improve from 0.86974

Epoch 00104: val_accuracy did not improve from 0.86974

Epoch 00105: val_accuracy did not improve from 0.86974

Epoch 00106: val_accuracy did not improve from 0.86974

Epoch 00107: val_accuracy did not improve from 0.86974

Epoch 00108: val_accuracy did not improve from 0.86974

Epoch 00109: val_accuracy did not improve from 0.86974

Epoch 00110: val_accuracy did not improve from 0.86974

Epoch 00111: val_accuracy did not improve from 0.86974

Epoch 00112: val_accuracy did not improve from 0.86974

Epoch 00113: val_accuracy did not improve from 0.86974

Epoch 00114: val_accuracy did not improve from 0.86974

Epoch 00115: val_accuracy did not improve from 0.86974

Epoch 00116: val_accuracy did not improve from 0.86974

Epoch 00117: val_accuracy did not improve from 0.86974

Epoch 00118: val_accuracy did not improve from 0.86974

Epoch 00119: val_accuracy did not improve from 0.86974

Epoch 00120: val_accuracy did not improve from 0.86974

Epoch 00121: val_accuracy did not improve from 0.86974

Epoch 00122: val_accuracy did not improve from 0.86974

Epoch 00123: val_accuracy did not improve from 0.86974

Epoch 00124: val_accuracy did not improve from 0.86974

Epoch 00125: val_accuracy did not improve from 0.86974

Epoch 00126: val_accuracy did not improve from 0.86974

Epoch 00127: val_accuracy did not improve from 0.86974

Epoch 00128: val_accuracy did not improve from 0.86974

Epoch 00129: val_accuracy did not improve from 0.86974

Epoch 00130: val_accuracy did not improve from 0.86974

Epoch 00131: val_accuracy did not improve from 0.86974

Epoch 00132: val_accuracy did not improve from 0.86974

Epoch 00133: val_accuracy did not improve from 0.86974

Epoch 00134: val_accuracy did not improve from 0.86974

Epoch 00135: val_accuracy did not improve from 0.86974

Epoch 00136: val_accuracy did not improve from 0.86974

Epoch 00137: val_accuracy did not improve from 0.86974

Epoch 00138: val_accuracy did not improve from 0.86974

Epoch 00139: val_accuracy did not improve from 0.86974

Epoch 00140: val_accuracy did not improve from 0.86974

Epoch 00141: val_accuracy did not improve from 0.86974

Epoch 00142: val_accuracy did not improve from 0.86974

Epoch 00143: val_accuracy did not improve from 0.86974

Epoch 00144: val_accuracy did not improve from 0.86974

Epoch 00145: val_accuracy did not improve from 0.86974

Epoch 00146: val_accuracy did not improve from 0.86974

Epoch 00147: val_accuracy did not improve from 0.86974

Epoch 00148: val_accuracy did not improve from 0.86974

Epoch 00149: val_accuracy did not improve from 0.86974

Epoch 00150: val_accuracy did not improve from 0.86974

Epoch 00151: val_accuracy did not improve from 0.86974

Epoch 00152: val_accuracy did not improve from 0.86974

Epoch 00153: val_accuracy did not improve from 0.86974

Epoch 00154: val_accuracy did not improve from 0.86974

Epoch 00155: val_accuracy did not improve from 0.86974

Epoch 00156: val_accuracy did not improve from 0.86974

Epoch 00157: val_accuracy improved from 0.86974 to 0.87023, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00158: val_accuracy improved from 0.87023 to 0.87311, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00159: val_accuracy improved from 0.87311 to 0.87409, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00160: val_accuracy improved from 0.87409 to 0.87413, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00161: val_accuracy improved from 0.87413 to 0.87524, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00162: val_accuracy improved from 0.87524 to 0.87650, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00163: val_accuracy did not improve from 0.87650

Epoch 00164: val_accuracy improved from 0.87650 to 0.87701, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00165: val_accuracy improved from 0.87701 to 0.87842, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00166: val_accuracy did not improve from 0.87842

Epoch 00167: val_accuracy improved from 0.87842 to 0.87947, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00168: val_accuracy improved from 0.87947 to 0.87987, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00169: val_accuracy did not improve from 0.87987

Epoch 00170: val_accuracy improved from 0.87987 to 0.88145, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00171: val_accuracy did not improve from 0.88145

Epoch 00172: val_accuracy did not improve from 0.88145

Epoch 00173: val_accuracy did not improve from 0.88145

Epoch 00174: val_accuracy improved from 0.88145 to 0.88165, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00175: val_accuracy did not improve from 0.88165

Epoch 00176: val_accuracy improved from 0.88165 to 0.88190, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00177: val_accuracy improved from 0.88190 to 0.88322, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00178: val_accuracy did not improve from 0.88322

Epoch 00179: val_accuracy did not improve from 0.88322

Epoch 00180: val_accuracy did not improve from 0.88322

Epoch 00181: val_accuracy did not improve from 0.88322

Epoch 00182: val_accuracy improved from 0.88322 to 0.88368, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00183: val_accuracy did not improve from 0.88368

Epoch 00184: val_accuracy improved from 0.88368 to 0.88479, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00185: val_accuracy did not improve from 0.88479

Epoch 00186: val_accuracy did not improve from 0.88479

Epoch 00187: val_accuracy improved from 0.88479 to 0.88600, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00188: val_accuracy did not improve from 0.88600

Epoch 00189: val_accuracy improved from 0.88600 to 0.88652, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00190: val_accuracy improved from 0.88652 to 0.88671, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00191: val_accuracy did not improve from 0.88671

Epoch 00192: val_accuracy improved from 0.88671 to 0.88743, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00193: val_accuracy did not improve from 0.88743

Epoch 00194: val_accuracy improved from 0.88743 to 0.88762, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00195: val_accuracy improved from 0.88762 to 0.88832, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00196: val_accuracy did not improve from 0.88832

Epoch 00197: val_accuracy did not improve from 0.88832

Epoch 00198: val_accuracy did not improve from 0.88832

Epoch 00199: val_accuracy improved from 0.88832 to 0.88841, saving model to weights_T1qqqq_bin_31_try4.best.hdf5

Epoch 00200: val_accuracy improved from 0.88841 to 0.88865, saving model to weights_T1qqqq_bin_31_try4.best.hdf5
plotting history
plotting score distribution
plotting significance
finished plotting
train on  12707  background 123165  signals, validate on  1412 background 13686 signals
369495 369495 41058 41058
start training on bin  24

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy improved from 0.50000 to 0.71521, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00005: val_accuracy improved from 0.71521 to 0.78546, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00006: val_accuracy did not improve from 0.78546

Epoch 00007: val_accuracy improved from 0.78546 to 0.78803, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00008: val_accuracy improved from 0.78803 to 0.79160, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00009: val_accuracy improved from 0.79160 to 0.79652, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00010: val_accuracy did not improve from 0.79652

Epoch 00011: val_accuracy did not improve from 0.79652

Epoch 00012: val_accuracy did not improve from 0.79652

Epoch 00013: val_accuracy did not improve from 0.79652

Epoch 00014: val_accuracy did not improve from 0.79652

Epoch 00015: val_accuracy improved from 0.79652 to 0.79656, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00016: val_accuracy did not improve from 0.79656

Epoch 00017: val_accuracy improved from 0.79656 to 0.79681, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00018: val_accuracy did not improve from 0.79681

Epoch 00019: val_accuracy improved from 0.79681 to 0.79830, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00020: val_accuracy did not improve from 0.79830

Epoch 00021: val_accuracy improved from 0.79830 to 0.79904, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00022: val_accuracy did not improve from 0.79904

Epoch 00023: val_accuracy improved from 0.79904 to 0.80016, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00024: val_accuracy did not improve from 0.80016

Epoch 00025: val_accuracy did not improve from 0.80016

Epoch 00026: val_accuracy did not improve from 0.80016

Epoch 00027: val_accuracy did not improve from 0.80016

Epoch 00028: val_accuracy improved from 0.80016 to 0.80053, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00029: val_accuracy did not improve from 0.80053

Epoch 00030: val_accuracy did not improve from 0.80053

Epoch 00031: val_accuracy did not improve from 0.80053

Epoch 00032: val_accuracy did not improve from 0.80053

Epoch 00033: val_accuracy did not improve from 0.80053

Epoch 00034: val_accuracy did not improve from 0.80053

Epoch 00035: val_accuracy did not improve from 0.80053

Epoch 00036: val_accuracy did not improve from 0.80053

Epoch 00037: val_accuracy did not improve from 0.80053

Epoch 00038: val_accuracy did not improve from 0.80053

Epoch 00039: val_accuracy did not improve from 0.80053

Epoch 00040: val_accuracy did not improve from 0.80053

Epoch 00041: val_accuracy did not improve from 0.80053

Epoch 00042: val_accuracy did not improve from 0.80053

Epoch 00043: val_accuracy did not improve from 0.80053

Epoch 00044: val_accuracy did not improve from 0.80053

Epoch 00045: val_accuracy did not improve from 0.80053

Epoch 00046: val_accuracy did not improve from 0.80053

Epoch 00047: val_accuracy did not improve from 0.80053

Epoch 00048: val_accuracy did not improve from 0.80053

Epoch 00049: val_accuracy did not improve from 0.80053

Epoch 00050: val_accuracy did not improve from 0.80053

Epoch 00051: val_accuracy did not improve from 0.80053

Epoch 00052: val_accuracy did not improve from 0.80053

Epoch 00053: val_accuracy did not improve from 0.80053

Epoch 00054: val_accuracy did not improve from 0.80053

Epoch 00055: val_accuracy did not improve from 0.80053

Epoch 00056: val_accuracy did not improve from 0.80053

Epoch 00057: val_accuracy did not improve from 0.80053

Epoch 00058: val_accuracy did not improve from 0.80053

Epoch 00059: val_accuracy did not improve from 0.80053

Epoch 00060: val_accuracy did not improve from 0.80053

Epoch 00061: val_accuracy did not improve from 0.80053

Epoch 00062: val_accuracy did not improve from 0.80053

Epoch 00063: val_accuracy did not improve from 0.80053

Epoch 00064: val_accuracy did not improve from 0.80053

Epoch 00065: val_accuracy did not improve from 0.80053

Epoch 00066: val_accuracy did not improve from 0.80053

Epoch 00067: val_accuracy did not improve from 0.80053

Epoch 00068: val_accuracy did not improve from 0.80053

Epoch 00069: val_accuracy did not improve from 0.80053

Epoch 00070: val_accuracy did not improve from 0.80053

Epoch 00071: val_accuracy did not improve from 0.80053

Epoch 00072: val_accuracy did not improve from 0.80053

Epoch 00073: val_accuracy did not improve from 0.80053

Epoch 00074: val_accuracy did not improve from 0.80053

Epoch 00075: val_accuracy did not improve from 0.80053

Epoch 00076: val_accuracy did not improve from 0.80053

Epoch 00077: val_accuracy did not improve from 0.80053

Epoch 00078: val_accuracy did not improve from 0.80053

Epoch 00079: val_accuracy did not improve from 0.80053

Epoch 00080: val_accuracy did not improve from 0.80053

Epoch 00081: val_accuracy did not improve from 0.80053

Epoch 00082: val_accuracy did not improve from 0.80053

Epoch 00083: val_accuracy did not improve from 0.80053

Epoch 00084: val_accuracy did not improve from 0.80053

Epoch 00085: val_accuracy did not improve from 0.80053

Epoch 00086: val_accuracy did not improve from 0.80053

Epoch 00087: val_accuracy did not improve from 0.80053

Epoch 00088: val_accuracy did not improve from 0.80053

Epoch 00089: val_accuracy did not improve from 0.80053

Epoch 00090: val_accuracy did not improve from 0.80053

Epoch 00091: val_accuracy did not improve from 0.80053

Epoch 00092: val_accuracy did not improve from 0.80053

Epoch 00093: val_accuracy did not improve from 0.80053

Epoch 00094: val_accuracy did not improve from 0.80053

Epoch 00095: val_accuracy did not improve from 0.80053

Epoch 00096: val_accuracy did not improve from 0.80053

Epoch 00097: val_accuracy did not improve from 0.80053

Epoch 00098: val_accuracy did not improve from 0.80053

Epoch 00099: val_accuracy did not improve from 0.80053

Epoch 00100: val_accuracy did not improve from 0.80053

Epoch 00101: val_accuracy did not improve from 0.80053

Epoch 00102: val_accuracy did not improve from 0.80053

Epoch 00103: val_accuracy did not improve from 0.80053

Epoch 00104: val_accuracy did not improve from 0.80053

Epoch 00105: val_accuracy did not improve from 0.80053

Epoch 00106: val_accuracy did not improve from 0.80053

Epoch 00107: val_accuracy did not improve from 0.80053

Epoch 00108: val_accuracy did not improve from 0.80053

Epoch 00109: val_accuracy did not improve from 0.80053

Epoch 00110: val_accuracy did not improve from 0.80053

Epoch 00111: val_accuracy did not improve from 0.80053

Epoch 00112: val_accuracy did not improve from 0.80053

Epoch 00113: val_accuracy did not improve from 0.80053

Epoch 00114: val_accuracy did not improve from 0.80053

Epoch 00115: val_accuracy did not improve from 0.80053

Epoch 00116: val_accuracy did not improve from 0.80053

Epoch 00117: val_accuracy did not improve from 0.80053

Epoch 00118: val_accuracy did not improve from 0.80053

Epoch 00119: val_accuracy did not improve from 0.80053

Epoch 00120: val_accuracy did not improve from 0.80053

Epoch 00121: val_accuracy did not improve from 0.80053

Epoch 00122: val_accuracy did not improve from 0.80053

Epoch 00123: val_accuracy did not improve from 0.80053

Epoch 00124: val_accuracy did not improve from 0.80053

Epoch 00125: val_accuracy did not improve from 0.80053

Epoch 00126: val_accuracy did not improve from 0.80053

Epoch 00127: val_accuracy did not improve from 0.80053

Epoch 00128: val_accuracy did not improve from 0.80053

Epoch 00129: val_accuracy did not improve from 0.80053

Epoch 00130: val_accuracy did not improve from 0.80053

Epoch 00131: val_accuracy did not improve from 0.80053

Epoch 00132: val_accuracy did not improve from 0.80053

Epoch 00133: val_accuracy did not improve from 0.80053

Epoch 00134: val_accuracy did not improve from 0.80053

Epoch 00135: val_accuracy did not improve from 0.80053

Epoch 00136: val_accuracy did not improve from 0.80053

Epoch 00137: val_accuracy did not improve from 0.80053

Epoch 00138: val_accuracy did not improve from 0.80053

Epoch 00139: val_accuracy did not improve from 0.80053

Epoch 00140: val_accuracy did not improve from 0.80053

Epoch 00141: val_accuracy did not improve from 0.80053

Epoch 00142: val_accuracy did not improve from 0.80053

Epoch 00143: val_accuracy did not improve from 0.80053

Epoch 00144: val_accuracy did not improve from 0.80053

Epoch 00145: val_accuracy did not improve from 0.80053

Epoch 00146: val_accuracy did not improve from 0.80053

Epoch 00147: val_accuracy did not improve from 0.80053

Epoch 00148: val_accuracy did not improve from 0.80053

Epoch 00149: val_accuracy did not improve from 0.80053

Epoch 00150: val_accuracy did not improve from 0.80053

Epoch 00151: val_accuracy did not improve from 0.80053

Epoch 00152: val_accuracy did not improve from 0.80053

Epoch 00153: val_accuracy did not improve from 0.80053

Epoch 00154: val_accuracy did not improve from 0.80053

Epoch 00155: val_accuracy did not improve from 0.80053

Epoch 00156: val_accuracy did not improve from 0.80053

Epoch 00157: val_accuracy did not improve from 0.80053

Epoch 00158: val_accuracy did not improve from 0.80053

Epoch 00159: val_accuracy did not improve from 0.80053

Epoch 00160: val_accuracy did not improve from 0.80053

Epoch 00161: val_accuracy did not improve from 0.80053

Epoch 00162: val_accuracy did not improve from 0.80053

Epoch 00163: val_accuracy did not improve from 0.80053

Epoch 00164: val_accuracy did not improve from 0.80053

Epoch 00165: val_accuracy did not improve from 0.80053

Epoch 00166: val_accuracy did not improve from 0.80053

Epoch 00167: val_accuracy did not improve from 0.80053

Epoch 00168: val_accuracy did not improve from 0.80053

Epoch 00169: val_accuracy did not improve from 0.80053

Epoch 00170: val_accuracy did not improve from 0.80053

Epoch 00171: val_accuracy did not improve from 0.80053

Epoch 00172: val_accuracy did not improve from 0.80053

Epoch 00173: val_accuracy did not improve from 0.80053

Epoch 00174: val_accuracy did not improve from 0.80053

Epoch 00175: val_accuracy did not improve from 0.80053

Epoch 00176: val_accuracy did not improve from 0.80053

Epoch 00177: val_accuracy did not improve from 0.80053

Epoch 00178: val_accuracy did not improve from 0.80053

Epoch 00179: val_accuracy did not improve from 0.80053

Epoch 00180: val_accuracy did not improve from 0.80053

Epoch 00181: val_accuracy did not improve from 0.80053

Epoch 00182: val_accuracy did not improve from 0.80053

Epoch 00183: val_accuracy did not improve from 0.80053

Epoch 00184: val_accuracy did not improve from 0.80053

Epoch 00185: val_accuracy did not improve from 0.80053

Epoch 00186: val_accuracy did not improve from 0.80053

Epoch 00187: val_accuracy did not improve from 0.80053

Epoch 00188: val_accuracy did not improve from 0.80053

Epoch 00189: val_accuracy did not improve from 0.80053

Epoch 00190: val_accuracy improved from 0.80053 to 0.80335, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00191: val_accuracy did not improve from 0.80335

Epoch 00192: val_accuracy did not improve from 0.80335

Epoch 00193: val_accuracy improved from 0.80335 to 0.80565, saving model to weights_T1qqqq_bin_24_try4.best.hdf5

Epoch 00194: val_accuracy did not improve from 0.80565

Epoch 00195: val_accuracy did not improve from 0.80565

Epoch 00196: val_accuracy did not improve from 0.80565

Epoch 00197: val_accuracy did not improve from 0.80565

Epoch 00198: val_accuracy did not improve from 0.80565

Epoch 00199: val_accuracy did not improve from 0.80565

Epoch 00200: val_accuracy did not improve from 0.80565
plotting history
plotting score distribution
plotting significance
finished plotting
train on  5046  background 49955  signals, validate on  561 background 5551 signals
149865 149865 16653 16653
start training on bin  64

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy improved from 0.50000 to 0.56347, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00010: val_accuracy improved from 0.56347 to 0.70771, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00011: val_accuracy improved from 0.70771 to 0.78094, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00012: val_accuracy improved from 0.78094 to 0.80139, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00013: val_accuracy improved from 0.80139 to 0.80610, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00014: val_accuracy did not improve from 0.80610

Epoch 00015: val_accuracy improved from 0.80610 to 0.80829, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00016: val_accuracy improved from 0.80829 to 0.81012, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00017: val_accuracy did not improve from 0.81012

Epoch 00018: val_accuracy improved from 0.81012 to 0.81036, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00019: val_accuracy improved from 0.81036 to 0.81124, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00020: val_accuracy did not improve from 0.81124

Epoch 00021: val_accuracy did not improve from 0.81124

Epoch 00022: val_accuracy improved from 0.81124 to 0.81205, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00023: val_accuracy did not improve from 0.81205

Epoch 00024: val_accuracy did not improve from 0.81205

Epoch 00025: val_accuracy did not improve from 0.81205

Epoch 00026: val_accuracy did not improve from 0.81205

Epoch 00027: val_accuracy improved from 0.81205 to 0.81313, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00028: val_accuracy improved from 0.81313 to 0.81469, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00029: val_accuracy did not improve from 0.81469

Epoch 00030: val_accuracy did not improve from 0.81469

Epoch 00031: val_accuracy improved from 0.81469 to 0.81487, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00032: val_accuracy did not improve from 0.81487

Epoch 00033: val_accuracy improved from 0.81487 to 0.81532, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00034: val_accuracy improved from 0.81532 to 0.81550, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00035: val_accuracy did not improve from 0.81550

Epoch 00036: val_accuracy did not improve from 0.81550

Epoch 00037: val_accuracy did not improve from 0.81550

Epoch 00038: val_accuracy did not improve from 0.81550

Epoch 00039: val_accuracy did not improve from 0.81550

Epoch 00040: val_accuracy did not improve from 0.81550

Epoch 00041: val_accuracy did not improve from 0.81550

Epoch 00042: val_accuracy did not improve from 0.81550

Epoch 00043: val_accuracy did not improve from 0.81550

Epoch 00044: val_accuracy did not improve from 0.81550

Epoch 00045: val_accuracy did not improve from 0.81550

Epoch 00046: val_accuracy did not improve from 0.81550

Epoch 00047: val_accuracy did not improve from 0.81550

Epoch 00048: val_accuracy did not improve from 0.81550

Epoch 00049: val_accuracy did not improve from 0.81550

Epoch 00050: val_accuracy did not improve from 0.81550

Epoch 00051: val_accuracy did not improve from 0.81550

Epoch 00052: val_accuracy did not improve from 0.81550

Epoch 00053: val_accuracy did not improve from 0.81550

Epoch 00054: val_accuracy did not improve from 0.81550

Epoch 00055: val_accuracy did not improve from 0.81550

Epoch 00056: val_accuracy did not improve from 0.81550

Epoch 00057: val_accuracy did not improve from 0.81550

Epoch 00058: val_accuracy did not improve from 0.81550

Epoch 00059: val_accuracy did not improve from 0.81550

Epoch 00060: val_accuracy did not improve from 0.81550

Epoch 00061: val_accuracy did not improve from 0.81550

Epoch 00062: val_accuracy improved from 0.81550 to 0.81565, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00063: val_accuracy did not improve from 0.81565

Epoch 00064: val_accuracy did not improve from 0.81565

Epoch 00065: val_accuracy did not improve from 0.81565

Epoch 00066: val_accuracy did not improve from 0.81565

Epoch 00067: val_accuracy did not improve from 0.81565

Epoch 00068: val_accuracy improved from 0.81565 to 0.81571, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00069: val_accuracy improved from 0.81571 to 0.81655, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00070: val_accuracy improved from 0.81655 to 0.81754, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00071: val_accuracy improved from 0.81754 to 0.81820, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00072: val_accuracy improved from 0.81820 to 0.81883, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00073: val_accuracy did not improve from 0.81883

Epoch 00074: val_accuracy did not improve from 0.81883

Epoch 00075: val_accuracy did not improve from 0.81883

Epoch 00076: val_accuracy improved from 0.81883 to 0.81946, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00077: val_accuracy did not improve from 0.81946

Epoch 00078: val_accuracy did not improve from 0.81946

Epoch 00079: val_accuracy did not improve from 0.81946

Epoch 00080: val_accuracy did not improve from 0.81946

Epoch 00081: val_accuracy improved from 0.81946 to 0.81991, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00082: val_accuracy did not improve from 0.81991

Epoch 00083: val_accuracy improved from 0.81991 to 0.81997, saving model to weights_T1qqqq_bin_64_try4.best.hdf5

Epoch 00084: val_accuracy did not improve from 0.81997

Epoch 00085: val_accuracy did not improve from 0.81997

Epoch 00086: val_accuracy did not improve from 0.81997

Epoch 00087: val_accuracy did not improve from 0.81997

Epoch 00088: val_accuracy did not improve from 0.81997

Epoch 00089: val_accuracy did not improve from 0.81997

Epoch 00090: val_accuracy did not improve from 0.81997

Epoch 00091: val_accuracy did not improve from 0.81997

Epoch 00092: val_accuracy did not improve from 0.81997

Epoch 00093: val_accuracy did not improve from 0.81997

Epoch 00094: val_accuracy did not improve from 0.81997

Epoch 00095: val_accuracy did not improve from 0.81997

Epoch 00096: val_accuracy did not improve from 0.81997

Epoch 00097: val_accuracy did not improve from 0.81997

Epoch 00098: val_accuracy did not improve from 0.81997

Epoch 00099: val_accuracy did not improve from 0.81997

Epoch 00100: val_accuracy did not improve from 0.81997

Epoch 00101: val_accuracy did not improve from 0.81997

Epoch 00102: val_accuracy did not improve from 0.81997

Epoch 00103: val_accuracy did not improve from 0.81997

Epoch 00104: val_accuracy did not improve from 0.81997

Epoch 00105: val_accuracy did not improve from 0.81997

Epoch 00106: val_accuracy did not improve from 0.81997

Epoch 00107: val_accuracy did not improve from 0.81997

Epoch 00108: val_accuracy did not improve from 0.81997

Epoch 00109: val_accuracy did not improve from 0.81997

Epoch 00110: val_accuracy did not improve from 0.81997

Epoch 00111: val_accuracy did not improve from 0.81997

Epoch 00112: val_accuracy did not improve from 0.81997

Epoch 00113: val_accuracy did not improve from 0.81997

Epoch 00114: val_accuracy did not improve from 0.81997

Epoch 00115: val_accuracy did not improve from 0.81997

Epoch 00116: val_accuracy did not improve from 0.81997

Epoch 00117: val_accuracy did not improve from 0.81997

Epoch 00118: val_accuracy did not improve from 0.81997

Epoch 00119: val_accuracy did not improve from 0.81997

Epoch 00120: val_accuracy did not improve from 0.81997

Epoch 00121: val_accuracy did not improve from 0.81997

Epoch 00122: val_accuracy did not improve from 0.81997

Epoch 00123: val_accuracy did not improve from 0.81997

Epoch 00124: val_accuracy did not improve from 0.81997

Epoch 00125: val_accuracy did not improve from 0.81997

Epoch 00126: val_accuracy did not improve from 0.81997

Epoch 00127: val_accuracy did not improve from 0.81997

Epoch 00128: val_accuracy did not improve from 0.81997

Epoch 00129: val_accuracy did not improve from 0.81997

Epoch 00130: val_accuracy did not improve from 0.81997

Epoch 00131: val_accuracy did not improve from 0.81997

Epoch 00132: val_accuracy did not improve from 0.81997

Epoch 00133: val_accuracy did not improve from 0.81997

Epoch 00134: val_accuracy did not improve from 0.81997

Epoch 00135: val_accuracy did not improve from 0.81997

Epoch 00136: val_accuracy did not improve from 0.81997

Epoch 00137: val_accuracy did not improve from 0.81997

Epoch 00138: val_accuracy did not improve from 0.81997

Epoch 00139: val_accuracy did not improve from 0.81997

Epoch 00140: val_accuracy did not improve from 0.81997

Epoch 00141: val_accuracy did not improve from 0.81997

Epoch 00142: val_accuracy did not improve from 0.81997

Epoch 00143: val_accuracy did not improve from 0.81997

Epoch 00144: val_accuracy did not improve from 0.81997

Epoch 00145: val_accuracy did not improve from 0.81997

Epoch 00146: val_accuracy did not improve from 0.81997

Epoch 00147: val_accuracy did not improve from 0.81997

Epoch 00148: val_accuracy did not improve from 0.81997

Epoch 00149: val_accuracy did not improve from 0.81997

Epoch 00150: val_accuracy did not improve from 0.81997

Epoch 00151: val_accuracy did not improve from 0.81997

Epoch 00152: val_accuracy did not improve from 0.81997

Epoch 00153: val_accuracy did not improve from 0.81997

Epoch 00154: val_accuracy did not improve from 0.81997

Epoch 00155: val_accuracy did not improve from 0.81997

Epoch 00156: val_accuracy did not improve from 0.81997

Epoch 00157: val_accuracy did not improve from 0.81997

Epoch 00158: val_accuracy did not improve from 0.81997

Epoch 00159: val_accuracy did not improve from 0.81997

Epoch 00160: val_accuracy did not improve from 0.81997

Epoch 00161: val_accuracy did not improve from 0.81997

Epoch 00162: val_accuracy did not improve from 0.81997

Epoch 00163: val_accuracy did not improve from 0.81997

Epoch 00164: val_accuracy did not improve from 0.81997

Epoch 00165: val_accuracy did not improve from 0.81997

Epoch 00166: val_accuracy did not improve from 0.81997

Epoch 00167: val_accuracy did not improve from 0.81997

Epoch 00168: val_accuracy did not improve from 0.81997

Epoch 00169: val_accuracy did not improve from 0.81997

Epoch 00170: val_accuracy did not improve from 0.81997

Epoch 00171: val_accuracy did not improve from 0.81997

Epoch 00172: val_accuracy did not improve from 0.81997

Epoch 00173: val_accuracy did not improve from 0.81997

Epoch 00174: val_accuracy did not improve from 0.81997

Epoch 00175: val_accuracy did not improve from 0.81997

Epoch 00176: val_accuracy did not improve from 0.81997

Epoch 00177: val_accuracy did not improve from 0.81997

Epoch 00178: val_accuracy did not improve from 0.81997

Epoch 00179: val_accuracy did not improve from 0.81997

Epoch 00180: val_accuracy did not improve from 0.81997

Epoch 00181: val_accuracy did not improve from 0.81997

Epoch 00182: val_accuracy did not improve from 0.81997

Epoch 00183: val_accuracy did not improve from 0.81997

Epoch 00184: val_accuracy did not improve from 0.81997

Epoch 00185: val_accuracy did not improve from 0.81997

Epoch 00186: val_accuracy did not improve from 0.81997

Epoch 00187: val_accuracy did not improve from 0.81997

Epoch 00188: val_accuracy did not improve from 0.81997

Epoch 00189: val_accuracy did not improve from 0.81997

Epoch 00190: val_accuracy did not improve from 0.81997

Epoch 00191: val_accuracy did not improve from 0.81997

Epoch 00192: val_accuracy did not improve from 0.81997

Epoch 00193: val_accuracy did not improve from 0.81997

Epoch 00194: val_accuracy did not improve from 0.81997

Epoch 00195: val_accuracy did not improve from 0.81997

Epoch 00196: val_accuracy did not improve from 0.81997

Epoch 00197: val_accuracy did not improve from 0.81997

Epoch 00198: val_accuracy did not improve from 0.81997

Epoch 00199: val_accuracy did not improve from 0.81997

Epoch 00200: val_accuracy did not improve from 0.81997
plotting history
plotting score distribution
plotting significance
finished plotting
train on  7251  background 26368  signals, validate on  806 background 2930 signals
79104 79104 8790 8790
start training on bin  25

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy did not improve from 0.50000

Epoch 00010: val_accuracy did not improve from 0.50000

Epoch 00011: val_accuracy did not improve from 0.50000

Epoch 00012: val_accuracy did not improve from 0.50000

Epoch 00013: val_accuracy did not improve from 0.50000

Epoch 00014: val_accuracy did not improve from 0.50000

Epoch 00015: val_accuracy did not improve from 0.50000

Epoch 00016: val_accuracy improved from 0.50000 to 0.51263, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00017: val_accuracy improved from 0.51263 to 0.57799, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00018: val_accuracy improved from 0.57799 to 0.64647, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00019: val_accuracy improved from 0.64647 to 0.71809, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00020: val_accuracy improved from 0.71809 to 0.75171, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00021: val_accuracy improved from 0.75171 to 0.77241, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00022: val_accuracy improved from 0.77241 to 0.78919, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00023: val_accuracy improved from 0.78919 to 0.79898, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00024: val_accuracy did not improve from 0.79898

Epoch 00025: val_accuracy did not improve from 0.79898

Epoch 00026: val_accuracy did not improve from 0.79898

Epoch 00027: val_accuracy did not improve from 0.79898

Epoch 00028: val_accuracy did not improve from 0.79898

Epoch 00029: val_accuracy did not improve from 0.79898

Epoch 00030: val_accuracy did not improve from 0.79898

Epoch 00031: val_accuracy did not improve from 0.79898

Epoch 00032: val_accuracy did not improve from 0.79898

Epoch 00033: val_accuracy improved from 0.79898 to 0.79983, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00034: val_accuracy did not improve from 0.79983

Epoch 00035: val_accuracy did not improve from 0.79983

Epoch 00036: val_accuracy did not improve from 0.79983

Epoch 00037: val_accuracy did not improve from 0.79983

Epoch 00038: val_accuracy improved from 0.79983 to 0.80108, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00039: val_accuracy improved from 0.80108 to 0.80370, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00040: val_accuracy improved from 0.80370 to 0.80518, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00041: val_accuracy improved from 0.80518 to 0.80580, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00042: val_accuracy improved from 0.80580 to 0.80643, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00043: val_accuracy improved from 0.80643 to 0.80671, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00044: val_accuracy improved from 0.80671 to 0.80779, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00045: val_accuracy improved from 0.80779 to 0.80922, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00046: val_accuracy did not improve from 0.80922

Epoch 00047: val_accuracy did not improve from 0.80922

Epoch 00048: val_accuracy did not improve from 0.80922

Epoch 00049: val_accuracy did not improve from 0.80922

Epoch 00050: val_accuracy did not improve from 0.80922

Epoch 00051: val_accuracy did not improve from 0.80922

Epoch 00052: val_accuracy did not improve from 0.80922

Epoch 00053: val_accuracy did not improve from 0.80922

Epoch 00054: val_accuracy did not improve from 0.80922

Epoch 00055: val_accuracy did not improve from 0.80922

Epoch 00056: val_accuracy did not improve from 0.80922

Epoch 00057: val_accuracy did not improve from 0.80922

Epoch 00058: val_accuracy did not improve from 0.80922

Epoch 00059: val_accuracy did not improve from 0.80922

Epoch 00060: val_accuracy did not improve from 0.80922

Epoch 00061: val_accuracy did not improve from 0.80922

Epoch 00062: val_accuracy did not improve from 0.80922

Epoch 00063: val_accuracy did not improve from 0.80922

Epoch 00064: val_accuracy did not improve from 0.80922

Epoch 00065: val_accuracy did not improve from 0.80922

Epoch 00066: val_accuracy did not improve from 0.80922

Epoch 00067: val_accuracy did not improve from 0.80922

Epoch 00068: val_accuracy did not improve from 0.80922

Epoch 00069: val_accuracy did not improve from 0.80922

Epoch 00070: val_accuracy did not improve from 0.80922

Epoch 00071: val_accuracy did not improve from 0.80922

Epoch 00072: val_accuracy did not improve from 0.80922

Epoch 00073: val_accuracy did not improve from 0.80922

Epoch 00074: val_accuracy did not improve from 0.80922

Epoch 00075: val_accuracy did not improve from 0.80922

Epoch 00076: val_accuracy did not improve from 0.80922

Epoch 00077: val_accuracy did not improve from 0.80922

Epoch 00078: val_accuracy did not improve from 0.80922

Epoch 00079: val_accuracy did not improve from 0.80922

Epoch 00080: val_accuracy did not improve from 0.80922

Epoch 00081: val_accuracy did not improve from 0.80922

Epoch 00082: val_accuracy did not improve from 0.80922

Epoch 00083: val_accuracy did not improve from 0.80922

Epoch 00084: val_accuracy did not improve from 0.80922

Epoch 00085: val_accuracy did not improve from 0.80922

Epoch 00086: val_accuracy did not improve from 0.80922

Epoch 00087: val_accuracy did not improve from 0.80922

Epoch 00088: val_accuracy did not improve from 0.80922

Epoch 00089: val_accuracy did not improve from 0.80922

Epoch 00090: val_accuracy improved from 0.80922 to 0.80933, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00091: val_accuracy did not improve from 0.80933

Epoch 00092: val_accuracy did not improve from 0.80933

Epoch 00093: val_accuracy did not improve from 0.80933

Epoch 00094: val_accuracy did not improve from 0.80933

Epoch 00095: val_accuracy improved from 0.80933 to 0.80995, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00096: val_accuracy did not improve from 0.80995

Epoch 00097: val_accuracy did not improve from 0.80995

Epoch 00098: val_accuracy did not improve from 0.80995

Epoch 00099: val_accuracy did not improve from 0.80995

Epoch 00100: val_accuracy did not improve from 0.80995

Epoch 00101: val_accuracy did not improve from 0.80995

Epoch 00102: val_accuracy did not improve from 0.80995

Epoch 00103: val_accuracy did not improve from 0.80995

Epoch 00104: val_accuracy did not improve from 0.80995

Epoch 00105: val_accuracy did not improve from 0.80995

Epoch 00106: val_accuracy did not improve from 0.80995

Epoch 00107: val_accuracy did not improve from 0.80995

Epoch 00108: val_accuracy did not improve from 0.80995

Epoch 00109: val_accuracy did not improve from 0.80995

Epoch 00110: val_accuracy did not improve from 0.80995

Epoch 00111: val_accuracy did not improve from 0.80995

Epoch 00112: val_accuracy did not improve from 0.80995

Epoch 00113: val_accuracy did not improve from 0.80995

Epoch 00114: val_accuracy did not improve from 0.80995

Epoch 00115: val_accuracy did not improve from 0.80995

Epoch 00116: val_accuracy did not improve from 0.80995

Epoch 00117: val_accuracy did not improve from 0.80995

Epoch 00118: val_accuracy did not improve from 0.80995

Epoch 00119: val_accuracy did not improve from 0.80995

Epoch 00120: val_accuracy did not improve from 0.80995

Epoch 00121: val_accuracy improved from 0.80995 to 0.81109, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00122: val_accuracy did not improve from 0.81109

Epoch 00123: val_accuracy improved from 0.81109 to 0.81132, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00124: val_accuracy did not improve from 0.81132

Epoch 00125: val_accuracy improved from 0.81132 to 0.81160, saving model to weights_T1qqqq_bin_25_try4.best.hdf5

Epoch 00126: val_accuracy did not improve from 0.81160

Epoch 00127: val_accuracy did not improve from 0.81160

Epoch 00128: val_accuracy did not improve from 0.81160

Epoch 00129: val_accuracy did not improve from 0.81160

Epoch 00130: val_accuracy did not improve from 0.81160

Epoch 00131: val_accuracy did not improve from 0.81160

Epoch 00132: val_accuracy did not improve from 0.81160

Epoch 00133: val_accuracy did not improve from 0.81160

Epoch 00134: val_accuracy did not improve from 0.81160

Epoch 00135: val_accuracy did not improve from 0.81160

Epoch 00136: val_accuracy did not improve from 0.81160

Epoch 00137: val_accuracy did not improve from 0.81160

Epoch 00138: val_accuracy did not improve from 0.81160

Epoch 00139: val_accuracy did not improve from 0.81160

Epoch 00140: val_accuracy did not improve from 0.81160

Epoch 00141: val_accuracy did not improve from 0.81160

Epoch 00142: val_accuracy did not improve from 0.81160

Epoch 00143: val_accuracy did not improve from 0.81160

Epoch 00144: val_accuracy did not improve from 0.81160

Epoch 00145: val_accuracy did not improve from 0.81160

Epoch 00146: val_accuracy did not improve from 0.81160

Epoch 00147: val_accuracy did not improve from 0.81160

Epoch 00148: val_accuracy did not improve from 0.81160

Epoch 00149: val_accuracy did not improve from 0.81160

Epoch 00150: val_accuracy did not improve from 0.81160

Epoch 00151: val_accuracy did not improve from 0.81160

Epoch 00152: val_accuracy did not improve from 0.81160

Epoch 00153: val_accuracy did not improve from 0.81160

Epoch 00154: val_accuracy did not improve from 0.81160

Epoch 00155: val_accuracy did not improve from 0.81160

Epoch 00156: val_accuracy did not improve from 0.81160

Epoch 00157: val_accuracy did not improve from 0.81160

Epoch 00158: val_accuracy did not improve from 0.81160

Epoch 00159: val_accuracy did not improve from 0.81160

Epoch 00160: val_accuracy did not improve from 0.81160

Epoch 00161: val_accuracy did not improve from 0.81160

Epoch 00162: val_accuracy did not improve from 0.81160

Epoch 00163: val_accuracy did not improve from 0.81160

Epoch 00164: val_accuracy did not improve from 0.81160

Epoch 00165: val_accuracy did not improve from 0.81160

Epoch 00166: val_accuracy did not improve from 0.81160

Epoch 00167: val_accuracy did not improve from 0.81160

Epoch 00168: val_accuracy did not improve from 0.81160

Epoch 00169: val_accuracy did not improve from 0.81160

Epoch 00170: val_accuracy did not improve from 0.81160

Epoch 00171: val_accuracy did not improve from 0.81160

Epoch 00172: val_accuracy did not improve from 0.81160

Epoch 00173: val_accuracy did not improve from 0.81160

Epoch 00174: val_accuracy did not improve from 0.81160

Epoch 00175: val_accuracy did not improve from 0.81160

Epoch 00176: val_accuracy did not improve from 0.81160

Epoch 00177: val_accuracy did not improve from 0.81160

Epoch 00178: val_accuracy did not improve from 0.81160

Epoch 00179: val_accuracy did not improve from 0.81160

Epoch 00180: val_accuracy did not improve from 0.81160

Epoch 00181: val_accuracy did not improve from 0.81160

Epoch 00182: val_accuracy did not improve from 0.81160

Epoch 00183: val_accuracy did not improve from 0.81160

Epoch 00184: val_accuracy did not improve from 0.81160

Epoch 00185: val_accuracy did not improve from 0.81160

Epoch 00186: val_accuracy did not improve from 0.81160

Epoch 00187: val_accuracy did not improve from 0.81160

Epoch 00188: val_accuracy did not improve from 0.81160

Epoch 00189: val_accuracy did not improve from 0.81160

Epoch 00190: val_accuracy did not improve from 0.81160

Epoch 00191: val_accuracy did not improve from 0.81160

Epoch 00192: val_accuracy did not improve from 0.81160

Epoch 00193: val_accuracy did not improve from 0.81160

Epoch 00194: val_accuracy did not improve from 0.81160

Epoch 00195: val_accuracy did not improve from 0.81160

Epoch 00196: val_accuracy did not improve from 0.81160

Epoch 00197: val_accuracy did not improve from 0.81160

Epoch 00198: val_accuracy did not improve from 0.81160

Epoch 00199: val_accuracy did not improve from 0.81160

Epoch 00200: val_accuracy did not improve from 0.81160
plotting history
plotting score distribution
plotting significance
finished plotting
train on  286  background 11087  signals, validate on  32 background 1232 signals
33261 33261 3696 3696
start training on bin  48

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy did not improve from 0.50000

Epoch 00010: val_accuracy did not improve from 0.50000

Epoch 00011: val_accuracy did not improve from 0.50000

Epoch 00012: val_accuracy did not improve from 0.50000

Epoch 00013: val_accuracy did not improve from 0.50000

Epoch 00014: val_accuracy did not improve from 0.50000

Epoch 00015: val_accuracy did not improve from 0.50000

Epoch 00016: val_accuracy did not improve from 0.50000

Epoch 00017: val_accuracy did not improve from 0.50000

Epoch 00018: val_accuracy did not improve from 0.50000

Epoch 00019: val_accuracy did not improve from 0.50000

Epoch 00020: val_accuracy did not improve from 0.50000

Epoch 00021: val_accuracy did not improve from 0.50000

Epoch 00022: val_accuracy did not improve from 0.50000

Epoch 00023: val_accuracy did not improve from 0.50000

Epoch 00024: val_accuracy did not improve from 0.50000

Epoch 00025: val_accuracy did not improve from 0.50000

Epoch 00026: val_accuracy did not improve from 0.50000

Epoch 00027: val_accuracy did not improve from 0.50000

Epoch 00028: val_accuracy did not improve from 0.50000

Epoch 00029: val_accuracy did not improve from 0.50000

Epoch 00030: val_accuracy improved from 0.50000 to 0.50257, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00031: val_accuracy improved from 0.50257 to 0.50933, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00032: val_accuracy improved from 0.50933 to 0.52773, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00033: val_accuracy improved from 0.52773 to 0.56453, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00034: val_accuracy improved from 0.56453 to 0.58523, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00035: val_accuracy improved from 0.58523 to 0.63799, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00036: val_accuracy improved from 0.63799 to 0.69129, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00037: val_accuracy improved from 0.69129 to 0.72254, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00038: val_accuracy improved from 0.72254 to 0.76420, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00039: val_accuracy improved from 0.76420 to 0.77976, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00040: val_accuracy improved from 0.77976 to 0.79478, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00041: val_accuracy improved from 0.79478 to 0.82251, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00042: val_accuracy improved from 0.82251 to 0.82887, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00043: val_accuracy improved from 0.82887 to 0.84943, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00044: val_accuracy improved from 0.84943 to 0.86147, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00045: val_accuracy improved from 0.86147 to 0.87135, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00046: val_accuracy did not improve from 0.87135

Epoch 00047: val_accuracy improved from 0.87135 to 0.87148, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00048: val_accuracy improved from 0.87148 to 0.87405, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00049: val_accuracy improved from 0.87405 to 0.87581, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00050: val_accuracy improved from 0.87581 to 0.87771, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00051: val_accuracy improved from 0.87771 to 0.87933, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00052: val_accuracy improved from 0.87933 to 0.88041, saving model to weights_T1qqqq_bin_48_try4.best.hdf5

Epoch 00053: val_accuracy did not improve from 0.88041

Epoch 00054: val_accuracy did not improve from 0.88041

Epoch 00055: val_accuracy did not improve from 0.88041

Epoch 00056: val_accuracy did not improve from 0.88041

Epoch 00057: val_accuracy did not improve from 0.88041

Epoch 00058: val_accuracy did not improve from 0.88041

Epoch 00059: val_accuracy did not improve from 0.88041

Epoch 00060: val_accuracy did not improve from 0.88041

Epoch 00061: val_accuracy did not improve from 0.88041

Epoch 00062: val_accuracy did not improve from 0.88041

Epoch 00063: val_accuracy did not improve from 0.88041

Epoch 00064: val_accuracy did not improve from 0.88041

Epoch 00065: val_accuracy did not improve from 0.88041

Epoch 00066: val_accuracy did not improve from 0.88041

Epoch 00067: val_accuracy did not improve from 0.88041

Epoch 00068: val_accuracy did not improve from 0.88041

Epoch 00069: val_accuracy did not improve from 0.88041

Epoch 00070: val_accuracy did not improve from 0.88041

Epoch 00071: val_accuracy did not improve from 0.88041

Epoch 00072: val_accuracy did not improve from 0.88041

Epoch 00073: val_accuracy did not improve from 0.88041

Epoch 00074: val_accuracy did not improve from 0.88041

Epoch 00075: val_accuracy did not improve from 0.88041

Epoch 00076: val_accuracy did not improve from 0.88041

Epoch 00077: val_accuracy did not improve from 0.88041

Epoch 00078: val_accuracy did not improve from 0.88041

Epoch 00079: val_accuracy did not improve from 0.88041

Epoch 00080: val_accuracy did not improve from 0.88041

Epoch 00081: val_accuracy did not improve from 0.88041

Epoch 00082: val_accuracy did not improve from 0.88041

Epoch 00083: val_accuracy did not improve from 0.88041

Epoch 00084: val_accuracy did not improve from 0.88041

Epoch 00085: val_accuracy did not improve from 0.88041

Epoch 00086: val_accuracy did not improve from 0.88041

Epoch 00087: val_accuracy did not improve from 0.88041

Epoch 00088: val_accuracy did not improve from 0.88041

Epoch 00089: val_accuracy did not improve from 0.88041

Epoch 00090: val_accuracy did not improve from 0.88041

Epoch 00091: val_accuracy did not improve from 0.88041

Epoch 00092: val_accuracy did not improve from 0.88041

Epoch 00093: val_accuracy did not improve from 0.88041

Epoch 00094: val_accuracy did not improve from 0.88041

Epoch 00095: val_accuracy did not improve from 0.88041

Epoch 00096: val_accuracy did not improve from 0.88041

Epoch 00097: val_accuracy did not improve from 0.88041

Epoch 00098: val_accuracy did not improve from 0.88041

Epoch 00099: val_accuracy did not improve from 0.88041

Epoch 00100: val_accuracy did not improve from 0.88041

Epoch 00101: val_accuracy did not improve from 0.88041

Epoch 00102: val_accuracy did not improve from 0.88041

Epoch 00103: val_accuracy did not improve from 0.88041

Epoch 00104: val_accuracy did not improve from 0.88041

Epoch 00105: val_accuracy did not improve from 0.88041

Epoch 00106: val_accuracy did not improve from 0.88041

Epoch 00107: val_accuracy did not improve from 0.88041

Epoch 00108: val_accuracy did not improve from 0.88041

Epoch 00109: val_accuracy did not improve from 0.88041

Epoch 00110: val_accuracy did not improve from 0.88041

Epoch 00111: val_accuracy did not improve from 0.88041

Epoch 00112: val_accuracy did not improve from 0.88041

Epoch 00113: val_accuracy did not improve from 0.88041

Epoch 00114: val_accuracy did not improve from 0.88041

Epoch 00115: val_accuracy did not improve from 0.88041

Epoch 00116: val_accuracy did not improve from 0.88041

Epoch 00117: val_accuracy did not improve from 0.88041

Epoch 00118: val_accuracy did not improve from 0.88041

Epoch 00119: val_accuracy did not improve from 0.88041

Epoch 00120: val_accuracy did not improve from 0.88041

Epoch 00121: val_accuracy did not improve from 0.88041

Epoch 00122: val_accuracy did not improve from 0.88041

Epoch 00123: val_accuracy did not improve from 0.88041

Epoch 00124: val_accuracy did not improve from 0.88041

Epoch 00125: val_accuracy did not improve from 0.88041

Epoch 00126: val_accuracy did not improve from 0.88041

Epoch 00127: val_accuracy did not improve from 0.88041

Epoch 00128: val_accuracy did not improve from 0.88041

Epoch 00129: val_accuracy did not improve from 0.88041

Epoch 00130: val_accuracy did not improve from 0.88041

Epoch 00131: val_accuracy did not improve from 0.88041

Epoch 00132: val_accuracy did not improve from 0.88041

Epoch 00133: val_accuracy did not improve from 0.88041

Epoch 00134: val_accuracy did not improve from 0.88041

Epoch 00135: val_accuracy did not improve from 0.88041

Epoch 00136: val_accuracy did not improve from 0.88041

Epoch 00137: val_accuracy did not improve from 0.88041

Epoch 00138: val_accuracy did not improve from 0.88041

Epoch 00139: val_accuracy did not improve from 0.88041

Epoch 00140: val_accuracy did not improve from 0.88041

Epoch 00141: val_accuracy did not improve from 0.88041

Epoch 00142: val_accuracy did not improve from 0.88041

Epoch 00143: val_accuracy did not improve from 0.88041

Epoch 00144: val_accuracy did not improve from 0.88041

Epoch 00145: val_accuracy did not improve from 0.88041

Epoch 00146: val_accuracy did not improve from 0.88041

Epoch 00147: val_accuracy did not improve from 0.88041

Epoch 00148: val_accuracy did not improve from 0.88041

Epoch 00149: val_accuracy did not improve from 0.88041

Epoch 00150: val_accuracy did not improve from 0.88041

Epoch 00151: val_accuracy did not improve from 0.88041

Epoch 00152: val_accuracy did not improve from 0.88041

Epoch 00153: val_accuracy did not improve from 0.88041

Epoch 00154: val_accuracy did not improve from 0.88041

Epoch 00155: val_accuracy did not improve from 0.88041

Epoch 00156: val_accuracy did not improve from 0.88041

Epoch 00157: val_accuracy did not improve from 0.88041

Epoch 00158: val_accuracy did not improve from 0.88041

Epoch 00159: val_accuracy did not improve from 0.88041

Epoch 00160: val_accuracy did not improve from 0.88041

Epoch 00161: val_accuracy did not improve from 0.88041

Epoch 00162: val_accuracy did not improve from 0.88041

Epoch 00163: val_accuracy did not improve from 0.88041

Epoch 00164: val_accuracy did not improve from 0.88041

Epoch 00165: val_accuracy did not improve from 0.88041

Epoch 00166: val_accuracy did not improve from 0.88041

Epoch 00167: val_accuracy did not improve from 0.88041

Epoch 00168: val_accuracy did not improve from 0.88041

Epoch 00169: val_accuracy did not improve from 0.88041

Epoch 00170: val_accuracy did not improve from 0.88041

Epoch 00171: val_accuracy did not improve from 0.88041

Epoch 00172: val_accuracy did not improve from 0.88041

Epoch 00173: val_accuracy did not improve from 0.88041

Epoch 00174: val_accuracy did not improve from 0.88041

Epoch 00175: val_accuracy did not improve from 0.88041

Epoch 00176: val_accuracy did not improve from 0.88041

Epoch 00177: val_accuracy did not improve from 0.88041

Epoch 00178: val_accuracy did not improve from 0.88041

Epoch 00179: val_accuracy did not improve from 0.88041

Epoch 00180: val_accuracy did not improve from 0.88041

Epoch 00181: val_accuracy did not improve from 0.88041

Epoch 00182: val_accuracy did not improve from 0.88041

Epoch 00183: val_accuracy did not improve from 0.88041

Epoch 00184: val_accuracy did not improve from 0.88041

Epoch 00185: val_accuracy did not improve from 0.88041

Epoch 00186: val_accuracy did not improve from 0.88041

Epoch 00187: val_accuracy did not improve from 0.88041

Epoch 00188: val_accuracy did not improve from 0.88041

Epoch 00189: val_accuracy did not improve from 0.88041

Epoch 00190: val_accuracy did not improve from 0.88041

Epoch 00191: val_accuracy did not improve from 0.88041

Epoch 00192: val_accuracy did not improve from 0.88041

Epoch 00193: val_accuracy did not improve from 0.88041

Epoch 00194: val_accuracy did not improve from 0.88041

Epoch 00195: val_accuracy did not improve from 0.88041

Epoch 00196: val_accuracy did not improve from 0.88041

Epoch 00197: val_accuracy did not improve from 0.88041

Epoch 00198: val_accuracy did not improve from 0.88041

Epoch 00199: val_accuracy did not improve from 0.88041

Epoch 00200: val_accuracy did not improve from 0.88041
plotting history
plotting score distribution
plotting significance
finished plotting
train on  88794  background 404352  signals, validate on  9866 background 44928 signals
1213056 1213056 134784 134784
start training on bin  17

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_17_try4.best.hdf5

Epoch 00002: val_accuracy improved from 0.50000 to 0.70555, saving model to weights_T1qqqq_bin_17_try4.best.hdf5

Epoch 00003: val_accuracy improved from 0.70555 to 0.70734, saving model to weights_T1qqqq_bin_17_try4.best.hdf5

Epoch 00004: val_accuracy improved from 0.70734 to 0.70867, saving model to weights_T1qqqq_bin_17_try4.best.hdf5

Epoch 00005: val_accuracy did not improve from 0.70867

Epoch 00006: val_accuracy did not improve from 0.70867

Epoch 00007: val_accuracy did not improve from 0.70867

Epoch 00008: val_accuracy did not improve from 0.70867

Epoch 00009: val_accuracy did not improve from 0.70867

Epoch 00010: val_accuracy did not improve from 0.70867

Epoch 00011: val_accuracy did not improve from 0.70867

Epoch 00012: val_accuracy improved from 0.70867 to 0.70918, saving model to weights_T1qqqq_bin_17_try4.best.hdf5

Epoch 00013: val_accuracy improved from 0.70918 to 0.70989, saving model to weights_T1qqqq_bin_17_try4.best.hdf5

Epoch 00014: val_accuracy did not improve from 0.70989

Epoch 00015: val_accuracy improved from 0.70989 to 0.71060, saving model to weights_T1qqqq_bin_17_try4.best.hdf5

Epoch 00016: val_accuracy did not improve from 0.71060

Epoch 00017: val_accuracy did not improve from 0.71060

Epoch 00018: val_accuracy did not improve from 0.71060

Epoch 00019: val_accuracy did not improve from 0.71060

Epoch 00020: val_accuracy did not improve from 0.71060

Epoch 00021: val_accuracy did not improve from 0.71060

Epoch 00022: val_accuracy did not improve from 0.71060

Epoch 00023: val_accuracy did not improve from 0.71060

Epoch 00024: val_accuracy did not improve from 0.71060

Epoch 00025: val_accuracy did not improve from 0.71060

Epoch 00026: val_accuracy did not improve from 0.71060

Epoch 00027: val_accuracy did not improve from 0.71060

Epoch 00028: val_accuracy did not improve from 0.71060

Epoch 00029: val_accuracy did not improve from 0.71060

Epoch 00030: val_accuracy did not improve from 0.71060

Epoch 00031: val_accuracy did not improve from 0.71060

Epoch 00032: val_accuracy did not improve from 0.71060

Epoch 00033: val_accuracy did not improve from 0.71060

Epoch 00034: val_accuracy did not improve from 0.71060

Epoch 00035: val_accuracy did not improve from 0.71060

Epoch 00036: val_accuracy did not improve from 0.71060

Epoch 00037: val_accuracy did not improve from 0.71060

Epoch 00038: val_accuracy did not improve from 0.71060

Epoch 00039: val_accuracy did not improve from 0.71060

Epoch 00040: val_accuracy did not improve from 0.71060

Epoch 00041: val_accuracy did not improve from 0.71060

Epoch 00042: val_accuracy did not improve from 0.71060

Epoch 00043: val_accuracy did not improve from 0.71060

Epoch 00044: val_accuracy did not improve from 0.71060

Epoch 00045: val_accuracy did not improve from 0.71060

Epoch 00046: val_accuracy did not improve from 0.71060

Epoch 00047: val_accuracy did not improve from 0.71060

Epoch 00048: val_accuracy did not improve from 0.71060

Epoch 00049: val_accuracy did not improve from 0.71060

Epoch 00050: val_accuracy did not improve from 0.71060

Epoch 00051: val_accuracy did not improve from 0.71060

Epoch 00052: val_accuracy did not improve from 0.71060

Epoch 00053: val_accuracy did not improve from 0.71060

Epoch 00054: val_accuracy did not improve from 0.71060

Epoch 00055: val_accuracy did not improve from 0.71060

Epoch 00056: val_accuracy did not improve from 0.71060

Epoch 00057: val_accuracy did not improve from 0.71060

Epoch 00058: val_accuracy did not improve from 0.71060

Epoch 00059: val_accuracy did not improve from 0.71060

Epoch 00060: val_accuracy did not improve from 0.71060

Epoch 00061: val_accuracy did not improve from 0.71060

Epoch 00062: val_accuracy did not improve from 0.71060

Epoch 00063: val_accuracy did not improve from 0.71060

Epoch 00064: val_accuracy did not improve from 0.71060

Epoch 00065: val_accuracy did not improve from 0.71060

Epoch 00066: val_accuracy did not improve from 0.71060

Epoch 00067: val_accuracy did not improve from 0.71060

Epoch 00068: val_accuracy did not improve from 0.71060

Epoch 00069: val_accuracy did not improve from 0.71060

Epoch 00070: val_accuracy did not improve from 0.71060

Epoch 00071: val_accuracy did not improve from 0.71060

Epoch 00072: val_accuracy did not improve from 0.71060

Epoch 00073: val_accuracy did not improve from 0.71060

Epoch 00074: val_accuracy did not improve from 0.71060

Epoch 00075: val_accuracy did not improve from 0.71060

Epoch 00076: val_accuracy did not improve from 0.71060

Epoch 00077: val_accuracy did not improve from 0.71060

Epoch 00078: val_accuracy did not improve from 0.71060

Epoch 00079: val_accuracy did not improve from 0.71060

Epoch 00080: val_accuracy did not improve from 0.71060

Epoch 00081: val_accuracy did not improve from 0.71060

Epoch 00082: val_accuracy did not improve from 0.71060

Epoch 00083: val_accuracy did not improve from 0.71060

Epoch 00084: val_accuracy did not improve from 0.71060

Epoch 00085: val_accuracy did not improve from 0.71060

Epoch 00086: val_accuracy did not improve from 0.71060

Epoch 00087: val_accuracy did not improve from 0.71060

Epoch 00088: val_accuracy did not improve from 0.71060

Epoch 00089: val_accuracy did not improve from 0.71060

Epoch 00090: val_accuracy did not improve from 0.71060

Epoch 00091: val_accuracy did not improve from 0.71060

Epoch 00092: val_accuracy did not improve from 0.71060

Epoch 00093: val_accuracy did not improve from 0.71060

Epoch 00094: val_accuracy did not improve from 0.71060

Epoch 00095: val_accuracy did not improve from 0.71060

Epoch 00096: val_accuracy did not improve from 0.71060

Epoch 00097: val_accuracy did not improve from 0.71060

Epoch 00098: val_accuracy did not improve from 0.71060

Epoch 00099: val_accuracy did not improve from 0.71060

Epoch 00100: val_accuracy did not improve from 0.71060

Epoch 00101: val_accuracy did not improve from 0.71060

Epoch 00102: val_accuracy did not improve from 0.71060

Epoch 00103: val_accuracy did not improve from 0.71060

Epoch 00104: val_accuracy did not improve from 0.71060

Epoch 00105: val_accuracy did not improve from 0.71060

Epoch 00106: val_accuracy did not improve from 0.71060

Epoch 00107: val_accuracy did not improve from 0.71060

Epoch 00108: val_accuracy did not improve from 0.71060

Epoch 00109: val_accuracy did not improve from 0.71060

Epoch 00110: val_accuracy did not improve from 0.71060

Epoch 00111: val_accuracy did not improve from 0.71060

Epoch 00112: val_accuracy did not improve from 0.71060

Epoch 00113: val_accuracy did not improve from 0.71060

Epoch 00114: val_accuracy did not improve from 0.71060

Epoch 00115: val_accuracy did not improve from 0.71060

Epoch 00116: val_accuracy did not improve from 0.71060

Epoch 00117: val_accuracy did not improve from 0.71060

Epoch 00118: val_accuracy did not improve from 0.71060

Epoch 00119: val_accuracy did not improve from 0.71060

Epoch 00120: val_accuracy did not improve from 0.71060

Epoch 00121: val_accuracy did not improve from 0.71060

Epoch 00122: val_accuracy did not improve from 0.71060

Epoch 00123: val_accuracy did not improve from 0.71060

Epoch 00124: val_accuracy did not improve from 0.71060

Epoch 00125: val_accuracy did not improve from 0.71060

Epoch 00126: val_accuracy did not improve from 0.71060

Epoch 00127: val_accuracy did not improve from 0.71060

Epoch 00128: val_accuracy did not improve from 0.71060

Epoch 00129: val_accuracy did not improve from 0.71060

Epoch 00130: val_accuracy did not improve from 0.71060

Epoch 00131: val_accuracy did not improve from 0.71060

Epoch 00132: val_accuracy did not improve from 0.71060

Epoch 00133: val_accuracy did not improve from 0.71060

Epoch 00134: val_accuracy did not improve from 0.71060

Epoch 00135: val_accuracy did not improve from 0.71060

Epoch 00136: val_accuracy did not improve from 0.71060

Epoch 00137: val_accuracy did not improve from 0.71060

Epoch 00138: val_accuracy did not improve from 0.71060

Epoch 00139: val_accuracy did not improve from 0.71060

Epoch 00140: val_accuracy did not improve from 0.71060

Epoch 00141: val_accuracy did not improve from 0.71060

Epoch 00142: val_accuracy did not improve from 0.71060

Epoch 00143: val_accuracy did not improve from 0.71060

Epoch 00144: val_accuracy did not improve from 0.71060

Epoch 00145: val_accuracy did not improve from 0.71060

Epoch 00146: val_accuracy did not improve from 0.71060

Epoch 00147: val_accuracy did not improve from 0.71060

Epoch 00148: val_accuracy did not improve from 0.71060

Epoch 00149: val_accuracy did not improve from 0.71060

Epoch 00150: val_accuracy did not improve from 0.71060

Epoch 00151: val_accuracy did not improve from 0.71060

Epoch 00152: val_accuracy did not improve from 0.71060

Epoch 00153: val_accuracy did not improve from 0.71060

Epoch 00154: val_accuracy did not improve from 0.71060

Epoch 00155: val_accuracy did not improve from 0.71060

Epoch 00156: val_accuracy did not improve from 0.71060

Epoch 00157: val_accuracy did not improve from 0.71060

Epoch 00158: val_accuracy did not improve from 0.71060

Epoch 00159: val_accuracy did not improve from 0.71060

Epoch 00160: val_accuracy did not improve from 0.71060

Epoch 00161: val_accuracy did not improve from 0.71060

Epoch 00162: val_accuracy did not improve from 0.71060

Epoch 00163: val_accuracy did not improve from 0.71060

Epoch 00164: val_accuracy did not improve from 0.71060

Epoch 00165: val_accuracy did not improve from 0.71060

Epoch 00166: val_accuracy did not improve from 0.71060

Epoch 00167: val_accuracy did not improve from 0.71060

Epoch 00168: val_accuracy did not improve from 0.71060

Epoch 00169: val_accuracy did not improve from 0.71060

Epoch 00170: val_accuracy did not improve from 0.71060

Epoch 00171: val_accuracy did not improve from 0.71060

Epoch 00172: val_accuracy did not improve from 0.71060

Epoch 00173: val_accuracy did not improve from 0.71060

Epoch 00174: val_accuracy did not improve from 0.71060

Epoch 00175: val_accuracy did not improve from 0.71060

Epoch 00176: val_accuracy did not improve from 0.71060

Epoch 00177: val_accuracy did not improve from 0.71060

Epoch 00178: val_accuracy did not improve from 0.71060

Epoch 00179: val_accuracy did not improve from 0.71060

Epoch 00180: val_accuracy did not improve from 0.71060

Epoch 00181: val_accuracy did not improve from 0.71060

Epoch 00182: val_accuracy did not improve from 0.71060

Epoch 00183: val_accuracy did not improve from 0.71060

Epoch 00184: val_accuracy did not improve from 0.71060

Epoch 00185: val_accuracy did not improve from 0.71060

Epoch 00186: val_accuracy did not improve from 0.71060

Epoch 00187: val_accuracy did not improve from 0.71060

Epoch 00188: val_accuracy did not improve from 0.71060

Epoch 00189: val_accuracy did not improve from 0.71060

Epoch 00190: val_accuracy did not improve from 0.71060

Epoch 00191: val_accuracy did not improve from 0.71060

Epoch 00192: val_accuracy did not improve from 0.71060

Epoch 00193: val_accuracy did not improve from 0.71060

Epoch 00194: val_accuracy did not improve from 0.71060

Epoch 00195: val_accuracy did not improve from 0.71060

Epoch 00196: val_accuracy did not improve from 0.71060

Epoch 00197: val_accuracy did not improve from 0.71060

Epoch 00198: val_accuracy did not improve from 0.71060

Epoch 00199: val_accuracy did not improve from 0.71060

Epoch 00200: val_accuracy did not improve from 0.71060
plotting history
plotting score distribution
plotting significance
finished plotting
train on  9555  background 72197  signals, validate on  1062 background 8022 signals
216591 216591 24066 24066
start training on bin  32

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy improved from 0.50000 to 0.60417, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00007: val_accuracy improved from 0.60417 to 0.80988, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00008: val_accuracy improved from 0.80988 to 0.85133, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00009: val_accuracy did not improve from 0.85133

Epoch 00010: val_accuracy improved from 0.85133 to 0.85170, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00011: val_accuracy improved from 0.85170 to 0.85295, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00012: val_accuracy did not improve from 0.85295

Epoch 00013: val_accuracy improved from 0.85295 to 0.85382, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00014: val_accuracy improved from 0.85382 to 0.85442, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00015: val_accuracy did not improve from 0.85442

Epoch 00016: val_accuracy improved from 0.85442 to 0.85482, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00017: val_accuracy improved from 0.85482 to 0.85571, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00018: val_accuracy did not improve from 0.85571

Epoch 00019: val_accuracy improved from 0.85571 to 0.85585, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00020: val_accuracy did not improve from 0.85585

Epoch 00021: val_accuracy improved from 0.85585 to 0.85604, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00022: val_accuracy did not improve from 0.85604

Epoch 00023: val_accuracy did not improve from 0.85604

Epoch 00024: val_accuracy improved from 0.85604 to 0.85619, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00025: val_accuracy improved from 0.85619 to 0.85681, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00026: val_accuracy improved from 0.85681 to 0.85783, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00027: val_accuracy did not improve from 0.85783

Epoch 00028: val_accuracy improved from 0.85783 to 0.85814, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00029: val_accuracy improved from 0.85814 to 0.85864, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00030: val_accuracy improved from 0.85864 to 0.85895, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00031: val_accuracy did not improve from 0.85895

Epoch 00032: val_accuracy did not improve from 0.85895

Epoch 00033: val_accuracy did not improve from 0.85895

Epoch 00034: val_accuracy did not improve from 0.85895

Epoch 00035: val_accuracy did not improve from 0.85895

Epoch 00036: val_accuracy did not improve from 0.85895

Epoch 00037: val_accuracy did not improve from 0.85895

Epoch 00038: val_accuracy did not improve from 0.85895

Epoch 00039: val_accuracy did not improve from 0.85895

Epoch 00040: val_accuracy did not improve from 0.85895

Epoch 00041: val_accuracy did not improve from 0.85895

Epoch 00042: val_accuracy did not improve from 0.85895

Epoch 00043: val_accuracy did not improve from 0.85895

Epoch 00044: val_accuracy did not improve from 0.85895

Epoch 00045: val_accuracy did not improve from 0.85895

Epoch 00046: val_accuracy did not improve from 0.85895

Epoch 00047: val_accuracy did not improve from 0.85895

Epoch 00048: val_accuracy did not improve from 0.85895

Epoch 00049: val_accuracy did not improve from 0.85895

Epoch 00050: val_accuracy did not improve from 0.85895

Epoch 00051: val_accuracy did not improve from 0.85895

Epoch 00052: val_accuracy did not improve from 0.85895

Epoch 00053: val_accuracy did not improve from 0.85895

Epoch 00054: val_accuracy did not improve from 0.85895

Epoch 00055: val_accuracy did not improve from 0.85895

Epoch 00056: val_accuracy did not improve from 0.85895

Epoch 00057: val_accuracy did not improve from 0.85895

Epoch 00058: val_accuracy did not improve from 0.85895

Epoch 00059: val_accuracy did not improve from 0.85895

Epoch 00060: val_accuracy improved from 0.85895 to 0.86036, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00061: val_accuracy did not improve from 0.86036

Epoch 00062: val_accuracy improved from 0.86036 to 0.86045, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00063: val_accuracy did not improve from 0.86045

Epoch 00064: val_accuracy did not improve from 0.86045

Epoch 00065: val_accuracy did not improve from 0.86045

Epoch 00066: val_accuracy did not improve from 0.86045

Epoch 00067: val_accuracy did not improve from 0.86045

Epoch 00068: val_accuracy improved from 0.86045 to 0.86051, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00069: val_accuracy did not improve from 0.86051

Epoch 00070: val_accuracy did not improve from 0.86051

Epoch 00071: val_accuracy did not improve from 0.86051

Epoch 00072: val_accuracy did not improve from 0.86051

Epoch 00073: val_accuracy improved from 0.86051 to 0.86132, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00074: val_accuracy did not improve from 0.86132

Epoch 00075: val_accuracy improved from 0.86132 to 0.86196, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00076: val_accuracy did not improve from 0.86196

Epoch 00077: val_accuracy did not improve from 0.86196

Epoch 00078: val_accuracy did not improve from 0.86196

Epoch 00079: val_accuracy did not improve from 0.86196

Epoch 00080: val_accuracy did not improve from 0.86196

Epoch 00081: val_accuracy did not improve from 0.86196

Epoch 00082: val_accuracy did not improve from 0.86196

Epoch 00083: val_accuracy did not improve from 0.86196

Epoch 00084: val_accuracy did not improve from 0.86196

Epoch 00085: val_accuracy did not improve from 0.86196

Epoch 00086: val_accuracy did not improve from 0.86196

Epoch 00087: val_accuracy did not improve from 0.86196

Epoch 00088: val_accuracy improved from 0.86196 to 0.86223, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00089: val_accuracy improved from 0.86223 to 0.86238, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00090: val_accuracy did not improve from 0.86238

Epoch 00091: val_accuracy did not improve from 0.86238

Epoch 00092: val_accuracy did not improve from 0.86238

Epoch 00093: val_accuracy did not improve from 0.86238

Epoch 00094: val_accuracy did not improve from 0.86238

Epoch 00095: val_accuracy did not improve from 0.86238

Epoch 00096: val_accuracy did not improve from 0.86238

Epoch 00097: val_accuracy did not improve from 0.86238

Epoch 00098: val_accuracy improved from 0.86238 to 0.86335, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00099: val_accuracy improved from 0.86335 to 0.86381, saving model to weights_T1qqqq_bin_32_try4.best.hdf5

Epoch 00100: val_accuracy did not improve from 0.86381

Epoch 00101: val_accuracy did not improve from 0.86381

Epoch 00102: val_accuracy did not improve from 0.86381

Epoch 00103: val_accuracy did not improve from 0.86381

Epoch 00104: val_accuracy did not improve from 0.86381

Epoch 00105: val_accuracy did not improve from 0.86381

Epoch 00106: val_accuracy did not improve from 0.86381

Epoch 00107: val_accuracy did not improve from 0.86381

Epoch 00108: val_accuracy did not improve from 0.86381

Epoch 00109: val_accuracy did not improve from 0.86381

Epoch 00110: val_accuracy did not improve from 0.86381

Epoch 00111: val_accuracy did not improve from 0.86381

Epoch 00112: val_accuracy did not improve from 0.86381

Epoch 00113: val_accuracy did not improve from 0.86381

Epoch 00114: val_accuracy did not improve from 0.86381

Epoch 00115: val_accuracy did not improve from 0.86381

Epoch 00116: val_accuracy did not improve from 0.86381

Epoch 00117: val_accuracy did not improve from 0.86381

Epoch 00118: val_accuracy did not improve from 0.86381

Epoch 00119: val_accuracy did not improve from 0.86381

Epoch 00120: val_accuracy did not improve from 0.86381

Epoch 00121: val_accuracy did not improve from 0.86381

Epoch 00122: val_accuracy did not improve from 0.86381

Epoch 00123: val_accuracy did not improve from 0.86381

Epoch 00124: val_accuracy did not improve from 0.86381

Epoch 00125: val_accuracy did not improve from 0.86381

Epoch 00126: val_accuracy did not improve from 0.86381

Epoch 00127: val_accuracy did not improve from 0.86381

Epoch 00128: val_accuracy did not improve from 0.86381

Epoch 00129: val_accuracy did not improve from 0.86381

Epoch 00130: val_accuracy did not improve from 0.86381

Epoch 00131: val_accuracy did not improve from 0.86381

Epoch 00132: val_accuracy did not improve from 0.86381

Epoch 00133: val_accuracy did not improve from 0.86381

Epoch 00134: val_accuracy did not improve from 0.86381

Epoch 00135: val_accuracy did not improve from 0.86381

Epoch 00136: val_accuracy did not improve from 0.86381

Epoch 00137: val_accuracy did not improve from 0.86381

Epoch 00138: val_accuracy did not improve from 0.86381

Epoch 00139: val_accuracy did not improve from 0.86381

Epoch 00140: val_accuracy did not improve from 0.86381

Epoch 00141: val_accuracy did not improve from 0.86381

Epoch 00142: val_accuracy did not improve from 0.86381

Epoch 00143: val_accuracy did not improve from 0.86381

Epoch 00144: val_accuracy did not improve from 0.86381

Epoch 00145: val_accuracy did not improve from 0.86381

Epoch 00146: val_accuracy did not improve from 0.86381

Epoch 00147: val_accuracy did not improve from 0.86381

Epoch 00148: val_accuracy did not improve from 0.86381

Epoch 00149: val_accuracy did not improve from 0.86381

Epoch 00150: val_accuracy did not improve from 0.86381

Epoch 00151: val_accuracy did not improve from 0.86381

Epoch 00152: val_accuracy did not improve from 0.86381

Epoch 00153: val_accuracy did not improve from 0.86381

Epoch 00154: val_accuracy did not improve from 0.86381

Epoch 00155: val_accuracy did not improve from 0.86381

Epoch 00156: val_accuracy did not improve from 0.86381

Epoch 00157: val_accuracy did not improve from 0.86381

Epoch 00158: val_accuracy did not improve from 0.86381

Epoch 00159: val_accuracy did not improve from 0.86381

Epoch 00160: val_accuracy did not improve from 0.86381

Epoch 00161: val_accuracy did not improve from 0.86381

Epoch 00162: val_accuracy did not improve from 0.86381

Epoch 00163: val_accuracy did not improve from 0.86381

Epoch 00164: val_accuracy did not improve from 0.86381

Epoch 00165: val_accuracy did not improve from 0.86381

Epoch 00166: val_accuracy did not improve from 0.86381

Epoch 00167: val_accuracy did not improve from 0.86381

Epoch 00168: val_accuracy did not improve from 0.86381

Epoch 00169: val_accuracy did not improve from 0.86381

Epoch 00170: val_accuracy did not improve from 0.86381

Epoch 00171: val_accuracy did not improve from 0.86381

Epoch 00172: val_accuracy did not improve from 0.86381

Epoch 00173: val_accuracy did not improve from 0.86381

Epoch 00174: val_accuracy did not improve from 0.86381

Epoch 00175: val_accuracy did not improve from 0.86381

Epoch 00176: val_accuracy did not improve from 0.86381

Epoch 00177: val_accuracy did not improve from 0.86381

Epoch 00178: val_accuracy did not improve from 0.86381

Epoch 00179: val_accuracy did not improve from 0.86381

Epoch 00180: val_accuracy did not improve from 0.86381

Epoch 00181: val_accuracy did not improve from 0.86381

Epoch 00182: val_accuracy did not improve from 0.86381

Epoch 00183: val_accuracy did not improve from 0.86381

Epoch 00184: val_accuracy did not improve from 0.86381

Epoch 00185: val_accuracy did not improve from 0.86381

Epoch 00186: val_accuracy did not improve from 0.86381

Epoch 00187: val_accuracy did not improve from 0.86381

Epoch 00188: val_accuracy did not improve from 0.86381

Epoch 00189: val_accuracy did not improve from 0.86381

Epoch 00190: val_accuracy did not improve from 0.86381

Epoch 00191: val_accuracy did not improve from 0.86381

Epoch 00192: val_accuracy did not improve from 0.86381

Epoch 00193: val_accuracy did not improve from 0.86381

Epoch 00194: val_accuracy did not improve from 0.86381

Epoch 00195: val_accuracy did not improve from 0.86381

Epoch 00196: val_accuracy did not improve from 0.86381

Epoch 00197: val_accuracy did not improve from 0.86381

Epoch 00198: val_accuracy did not improve from 0.86381

Epoch 00199: val_accuracy did not improve from 0.86381

Epoch 00200: val_accuracy did not improve from 0.86381
plotting history
plotting score distribution
plotting significance
finished plotting
for mass1=  1800 , mass2=  1200
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
train on  22014  background 54427  signals, validate on  2446 background 6048 signals
163281 163281 18144 18144
start training on bin  18

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy improved from 0.50000 to 0.54991, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00010: val_accuracy improved from 0.54991 to 0.63095, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00011: val_accuracy improved from 0.63095 to 0.67055, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00012: val_accuracy improved from 0.67055 to 0.68474, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00013: val_accuracy improved from 0.68474 to 0.69205, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00014: val_accuracy improved from 0.69205 to 0.69679, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00015: val_accuracy improved from 0.69679 to 0.69731, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00016: val_accuracy improved from 0.69731 to 0.69759, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00017: val_accuracy improved from 0.69759 to 0.69803, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00018: val_accuracy improved from 0.69803 to 0.69971, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00019: val_accuracy did not improve from 0.69971

Epoch 00020: val_accuracy did not improve from 0.69971

Epoch 00021: val_accuracy did not improve from 0.69971

Epoch 00022: val_accuracy did not improve from 0.69971

Epoch 00023: val_accuracy did not improve from 0.69971

Epoch 00024: val_accuracy did not improve from 0.69971

Epoch 00025: val_accuracy did not improve from 0.69971

Epoch 00026: val_accuracy did not improve from 0.69971

Epoch 00027: val_accuracy did not improve from 0.69971

Epoch 00028: val_accuracy did not improve from 0.69971

Epoch 00029: val_accuracy did not improve from 0.69971

Epoch 00030: val_accuracy did not improve from 0.69971

Epoch 00031: val_accuracy did not improve from 0.69971

Epoch 00032: val_accuracy did not improve from 0.69971

Epoch 00033: val_accuracy did not improve from 0.69971

Epoch 00034: val_accuracy did not improve from 0.69971

Epoch 00035: val_accuracy did not improve from 0.69971

Epoch 00036: val_accuracy did not improve from 0.69971

Epoch 00037: val_accuracy improved from 0.69971 to 0.69982, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00038: val_accuracy did not improve from 0.69982

Epoch 00039: val_accuracy improved from 0.69982 to 0.70076, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00040: val_accuracy improved from 0.70076 to 0.70131, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00041: val_accuracy did not improve from 0.70131

Epoch 00042: val_accuracy did not improve from 0.70131

Epoch 00043: val_accuracy did not improve from 0.70131

Epoch 00044: val_accuracy did not improve from 0.70131

Epoch 00045: val_accuracy did not improve from 0.70131

Epoch 00046: val_accuracy did not improve from 0.70131

Epoch 00047: val_accuracy did not improve from 0.70131

Epoch 00048: val_accuracy did not improve from 0.70131

Epoch 00049: val_accuracy improved from 0.70131 to 0.70136, saving model to weights_T1qqqq_bin_18_try4.best.hdf5

Epoch 00050: val_accuracy did not improve from 0.70136

Epoch 00051: val_accuracy did not improve from 0.70136

Epoch 00052: val_accuracy did not improve from 0.70136

Epoch 00053: val_accuracy did not improve from 0.70136

Epoch 00054: val_accuracy did not improve from 0.70136

Epoch 00055: val_accuracy did not improve from 0.70136

Epoch 00056: val_accuracy did not improve from 0.70136

Epoch 00057: val_accuracy did not improve from 0.70136

Epoch 00058: val_accuracy did not improve from 0.70136

Epoch 00059: val_accuracy did not improve from 0.70136

Epoch 00060: val_accuracy did not improve from 0.70136

Epoch 00061: val_accuracy did not improve from 0.70136

Epoch 00062: val_accuracy did not improve from 0.70136

Epoch 00063: val_accuracy did not improve from 0.70136

Epoch 00064: val_accuracy did not improve from 0.70136

Epoch 00065: val_accuracy did not improve from 0.70136

Epoch 00066: val_accuracy did not improve from 0.70136

Epoch 00067: val_accuracy did not improve from 0.70136

Epoch 00068: val_accuracy did not improve from 0.70136

Epoch 00069: val_accuracy did not improve from 0.70136

Epoch 00070: val_accuracy did not improve from 0.70136

Epoch 00071: val_accuracy did not improve from 0.70136

Epoch 00072: val_accuracy did not improve from 0.70136

Epoch 00073: val_accuracy did not improve from 0.70136

Epoch 00074: val_accuracy did not improve from 0.70136

Epoch 00075: val_accuracy did not improve from 0.70136

Epoch 00076: val_accuracy did not improve from 0.70136

Epoch 00077: val_accuracy did not improve from 0.70136

Epoch 00078: val_accuracy did not improve from 0.70136

Epoch 00079: val_accuracy did not improve from 0.70136

Epoch 00080: val_accuracy did not improve from 0.70136

Epoch 00081: val_accuracy did not improve from 0.70136

Epoch 00082: val_accuracy did not improve from 0.70136

Epoch 00083: val_accuracy did not improve from 0.70136

Epoch 00084: val_accuracy did not improve from 0.70136

Epoch 00085: val_accuracy did not improve from 0.70136

Epoch 00086: val_accuracy did not improve from 0.70136

Epoch 00087: val_accuracy did not improve from 0.70136

Epoch 00088: val_accuracy did not improve from 0.70136

Epoch 00089: val_accuracy did not improve from 0.70136

Epoch 00090: val_accuracy did not improve from 0.70136

Epoch 00091: val_accuracy did not improve from 0.70136

Epoch 00092: val_accuracy did not improve from 0.70136

Epoch 00093: val_accuracy did not improve from 0.70136

Epoch 00094: val_accuracy did not improve from 0.70136

Epoch 00095: val_accuracy did not improve from 0.70136

Epoch 00096: val_accuracy did not improve from 0.70136

Epoch 00097: val_accuracy did not improve from 0.70136

Epoch 00098: val_accuracy did not improve from 0.70136

Epoch 00099: val_accuracy did not improve from 0.70136

Epoch 00100: val_accuracy did not improve from 0.70136

Epoch 00101: val_accuracy did not improve from 0.70136

Epoch 00102: val_accuracy did not improve from 0.70136

Epoch 00103: val_accuracy did not improve from 0.70136

Epoch 00104: val_accuracy did not improve from 0.70136

Epoch 00105: val_accuracy did not improve from 0.70136

Epoch 00106: val_accuracy did not improve from 0.70136

Epoch 00107: val_accuracy did not improve from 0.70136

Epoch 00108: val_accuracy did not improve from 0.70136

Epoch 00109: val_accuracy did not improve from 0.70136

Epoch 00110: val_accuracy did not improve from 0.70136

Epoch 00111: val_accuracy did not improve from 0.70136

Epoch 00112: val_accuracy did not improve from 0.70136

Epoch 00113: val_accuracy did not improve from 0.70136

Epoch 00114: val_accuracy did not improve from 0.70136

Epoch 00115: val_accuracy did not improve from 0.70136

Epoch 00116: val_accuracy did not improve from 0.70136

Epoch 00117: val_accuracy did not improve from 0.70136

Epoch 00118: val_accuracy did not improve from 0.70136

Epoch 00119: val_accuracy did not improve from 0.70136

Epoch 00120: val_accuracy did not improve from 0.70136

Epoch 00121: val_accuracy did not improve from 0.70136

Epoch 00122: val_accuracy did not improve from 0.70136

Epoch 00123: val_accuracy did not improve from 0.70136

Epoch 00124: val_accuracy did not improve from 0.70136

Epoch 00125: val_accuracy did not improve from 0.70136

Epoch 00126: val_accuracy did not improve from 0.70136

Epoch 00127: val_accuracy did not improve from 0.70136

Epoch 00128: val_accuracy did not improve from 0.70136

Epoch 00129: val_accuracy did not improve from 0.70136

Epoch 00130: val_accuracy did not improve from 0.70136

Epoch 00131: val_accuracy did not improve from 0.70136

Epoch 00132: val_accuracy did not improve from 0.70136

Epoch 00133: val_accuracy did not improve from 0.70136

Epoch 00134: val_accuracy did not improve from 0.70136

Epoch 00135: val_accuracy did not improve from 0.70136

Epoch 00136: val_accuracy did not improve from 0.70136

Epoch 00137: val_accuracy did not improve from 0.70136

Epoch 00138: val_accuracy did not improve from 0.70136

Epoch 00139: val_accuracy did not improve from 0.70136

Epoch 00140: val_accuracy did not improve from 0.70136

Epoch 00141: val_accuracy did not improve from 0.70136

Epoch 00142: val_accuracy did not improve from 0.70136

Epoch 00143: val_accuracy did not improve from 0.70136

Epoch 00144: val_accuracy did not improve from 0.70136

Epoch 00145: val_accuracy did not improve from 0.70136

Epoch 00146: val_accuracy did not improve from 0.70136

Epoch 00147: val_accuracy did not improve from 0.70136

Epoch 00148: val_accuracy did not improve from 0.70136

Epoch 00149: val_accuracy did not improve from 0.70136

Epoch 00150: val_accuracy did not improve from 0.70136

Epoch 00151: val_accuracy did not improve from 0.70136

Epoch 00152: val_accuracy did not improve from 0.70136

Epoch 00153: val_accuracy did not improve from 0.70136

Epoch 00154: val_accuracy did not improve from 0.70136

Epoch 00155: val_accuracy did not improve from 0.70136

Epoch 00156: val_accuracy did not improve from 0.70136

Epoch 00157: val_accuracy did not improve from 0.70136

Epoch 00158: val_accuracy did not improve from 0.70136

Epoch 00159: val_accuracy did not improve from 0.70136

Epoch 00160: val_accuracy did not improve from 0.70136

Epoch 00161: val_accuracy did not improve from 0.70136

Epoch 00162: val_accuracy did not improve from 0.70136

Epoch 00163: val_accuracy did not improve from 0.70136

Epoch 00164: val_accuracy did not improve from 0.70136

Epoch 00165: val_accuracy did not improve from 0.70136

Epoch 00166: val_accuracy did not improve from 0.70136

Epoch 00167: val_accuracy did not improve from 0.70136

Epoch 00168: val_accuracy did not improve from 0.70136

Epoch 00169: val_accuracy did not improve from 0.70136

Epoch 00170: val_accuracy did not improve from 0.70136

Epoch 00171: val_accuracy did not improve from 0.70136

Epoch 00172: val_accuracy did not improve from 0.70136

Epoch 00173: val_accuracy did not improve from 0.70136

Epoch 00174: val_accuracy did not improve from 0.70136

Epoch 00175: val_accuracy did not improve from 0.70136

Epoch 00176: val_accuracy did not improve from 0.70136

Epoch 00177: val_accuracy did not improve from 0.70136

Epoch 00178: val_accuracy did not improve from 0.70136

Epoch 00179: val_accuracy did not improve from 0.70136

Epoch 00180: val_accuracy did not improve from 0.70136

Epoch 00181: val_accuracy did not improve from 0.70136

Epoch 00182: val_accuracy did not improve from 0.70136

Epoch 00183: val_accuracy did not improve from 0.70136

Epoch 00184: val_accuracy did not improve from 0.70136

Epoch 00185: val_accuracy did not improve from 0.70136

Epoch 00186: val_accuracy did not improve from 0.70136

Epoch 00187: val_accuracy did not improve from 0.70136

Epoch 00188: val_accuracy did not improve from 0.70136

Epoch 00189: val_accuracy did not improve from 0.70136

Epoch 00190: val_accuracy did not improve from 0.70136

Epoch 00191: val_accuracy did not improve from 0.70136

Epoch 00192: val_accuracy did not improve from 0.70136

Epoch 00193: val_accuracy did not improve from 0.70136

Epoch 00194: val_accuracy did not improve from 0.70136

Epoch 00195: val_accuracy did not improve from 0.70136

Epoch 00196: val_accuracy did not improve from 0.70136

Epoch 00197: val_accuracy did not improve from 0.70136

Epoch 00198: val_accuracy did not improve from 0.70136

Epoch 00199: val_accuracy did not improve from 0.70136

Epoch 00200: val_accuracy did not improve from 0.70136
plotting history
plotting score distribution
plotting significance
finished plotting
plotting significance
finished plotting
train on  3580  background 8189  signals, validate on  398 background 910 signals
24567 24567 2730 2730
start training on bin  26

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy did not improve from 0.50000

Epoch 00010: val_accuracy did not improve from 0.50000

Epoch 00011: val_accuracy did not improve from 0.50000

Epoch 00012: val_accuracy did not improve from 0.50000

Epoch 00013: val_accuracy did not improve from 0.50000

Epoch 00014: val_accuracy did not improve from 0.50000

Epoch 00015: val_accuracy did not improve from 0.50000

Epoch 00016: val_accuracy did not improve from 0.50000

Epoch 00017: val_accuracy did not improve from 0.50000

Epoch 00018: val_accuracy did not improve from 0.50000

Epoch 00019: val_accuracy did not improve from 0.50000

Epoch 00020: val_accuracy did not improve from 0.50000

Epoch 00021: val_accuracy did not improve from 0.50000

Epoch 00022: val_accuracy did not improve from 0.50000

Epoch 00023: val_accuracy did not improve from 0.50000

Epoch 00024: val_accuracy did not improve from 0.50000

Epoch 00025: val_accuracy did not improve from 0.50000

Epoch 00026: val_accuracy did not improve from 0.50000

Epoch 00027: val_accuracy did not improve from 0.50000

Epoch 00028: val_accuracy did not improve from 0.50000

Epoch 00029: val_accuracy did not improve from 0.50000

Epoch 00030: val_accuracy did not improve from 0.50000

Epoch 00031: val_accuracy did not improve from 0.50000

Epoch 00032: val_accuracy did not improve from 0.50000

Epoch 00033: val_accuracy did not improve from 0.50000

Epoch 00034: val_accuracy did not improve from 0.50000

Epoch 00035: val_accuracy did not improve from 0.50000

Epoch 00036: val_accuracy did not improve from 0.50000

Epoch 00037: val_accuracy did not improve from 0.50000

Epoch 00038: val_accuracy did not improve from 0.50000

Epoch 00039: val_accuracy did not improve from 0.50000

Epoch 00040: val_accuracy did not improve from 0.50000

Epoch 00041: val_accuracy did not improve from 0.50000

Epoch 00042: val_accuracy improved from 0.50000 to 0.50037, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00043: val_accuracy improved from 0.50037 to 0.50659, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00044: val_accuracy improved from 0.50659 to 0.52271, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00045: val_accuracy improved from 0.52271 to 0.54707, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00046: val_accuracy improved from 0.54707 to 0.57875, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00047: val_accuracy improved from 0.57875 to 0.60092, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00048: val_accuracy improved from 0.60092 to 0.62363, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00049: val_accuracy improved from 0.62363 to 0.64853, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00050: val_accuracy improved from 0.64853 to 0.67930, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00051: val_accuracy improved from 0.67930 to 0.69817, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00052: val_accuracy improved from 0.69817 to 0.72253, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00053: val_accuracy improved from 0.72253 to 0.73315, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00054: val_accuracy improved from 0.73315 to 0.74487, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00055: val_accuracy improved from 0.74487 to 0.74963, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00056: val_accuracy improved from 0.74963 to 0.75458, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00057: val_accuracy improved from 0.75458 to 0.76007, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00058: val_accuracy improved from 0.76007 to 0.76538, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00059: val_accuracy did not improve from 0.76538

Epoch 00060: val_accuracy improved from 0.76538 to 0.76777, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00061: val_accuracy improved from 0.76777 to 0.77289, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00062: val_accuracy did not improve from 0.77289

Epoch 00063: val_accuracy did not improve from 0.77289

Epoch 00064: val_accuracy did not improve from 0.77289

Epoch 00065: val_accuracy did not improve from 0.77289

Epoch 00066: val_accuracy did not improve from 0.77289

Epoch 00067: val_accuracy did not improve from 0.77289

Epoch 00068: val_accuracy did not improve from 0.77289

Epoch 00069: val_accuracy did not improve from 0.77289

Epoch 00070: val_accuracy did not improve from 0.77289

Epoch 00071: val_accuracy did not improve from 0.77289

Epoch 00072: val_accuracy did not improve from 0.77289

Epoch 00073: val_accuracy did not improve from 0.77289

Epoch 00074: val_accuracy did not improve from 0.77289

Epoch 00075: val_accuracy did not improve from 0.77289

Epoch 00076: val_accuracy did not improve from 0.77289

Epoch 00077: val_accuracy did not improve from 0.77289

Epoch 00078: val_accuracy did not improve from 0.77289

Epoch 00079: val_accuracy did not improve from 0.77289

Epoch 00080: val_accuracy did not improve from 0.77289

Epoch 00081: val_accuracy did not improve from 0.77289

Epoch 00082: val_accuracy did not improve from 0.77289

Epoch 00083: val_accuracy did not improve from 0.77289

Epoch 00084: val_accuracy did not improve from 0.77289

Epoch 00085: val_accuracy did not improve from 0.77289

Epoch 00086: val_accuracy did not improve from 0.77289

Epoch 00087: val_accuracy did not improve from 0.77289

Epoch 00088: val_accuracy did not improve from 0.77289

Epoch 00089: val_accuracy did not improve from 0.77289

Epoch 00090: val_accuracy did not improve from 0.77289

Epoch 00091: val_accuracy did not improve from 0.77289

Epoch 00092: val_accuracy did not improve from 0.77289

Epoch 00093: val_accuracy did not improve from 0.77289

Epoch 00094: val_accuracy did not improve from 0.77289

Epoch 00095: val_accuracy did not improve from 0.77289

Epoch 00096: val_accuracy did not improve from 0.77289

Epoch 00097: val_accuracy did not improve from 0.77289

Epoch 00098: val_accuracy did not improve from 0.77289

Epoch 00099: val_accuracy did not improve from 0.77289

Epoch 00100: val_accuracy did not improve from 0.77289

Epoch 00101: val_accuracy improved from 0.77289 to 0.77473, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00102: val_accuracy improved from 0.77473 to 0.77601, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00103: val_accuracy did not improve from 0.77601

Epoch 00104: val_accuracy did not improve from 0.77601

Epoch 00105: val_accuracy improved from 0.77601 to 0.77656, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00106: val_accuracy improved from 0.77656 to 0.77857, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00107: val_accuracy did not improve from 0.77857

Epoch 00108: val_accuracy improved from 0.77857 to 0.77875, saving model to weights_T1qqqq_bin_26_try4.best.hdf5

Epoch 00109: val_accuracy did not improve from 0.77875

Epoch 00110: val_accuracy did not improve from 0.77875

Epoch 00111: val_accuracy did not improve from 0.77875

Epoch 00112: val_accuracy did not improve from 0.77875

Epoch 00113: val_accuracy did not improve from 0.77875

Epoch 00114: val_accuracy did not improve from 0.77875

Epoch 00115: val_accuracy did not improve from 0.77875

Epoch 00116: val_accuracy did not improve from 0.77875

Epoch 00117: val_accuracy did not improve from 0.77875

Epoch 00118: val_accuracy did not improve from 0.77875

Epoch 00119: val_accuracy did not improve from 0.77875

Epoch 00120: val_accuracy did not improve from 0.77875

Epoch 00121: val_accuracy did not improve from 0.77875

Epoch 00122: val_accuracy did not improve from 0.77875

Epoch 00123: val_accuracy did not improve from 0.77875

Epoch 00124: val_accuracy did not improve from 0.77875

Epoch 00125: val_accuracy did not improve from 0.77875

Epoch 00126: val_accuracy did not improve from 0.77875

Epoch 00127: val_accuracy did not improve from 0.77875

Epoch 00128: val_accuracy did not improve from 0.77875

Epoch 00129: val_accuracy did not improve from 0.77875

Epoch 00130: val_accuracy did not improve from 0.77875

Epoch 00131: val_accuracy did not improve from 0.77875

Epoch 00132: val_accuracy did not improve from 0.77875

Epoch 00133: val_accuracy did not improve from 0.77875

Epoch 00134: val_accuracy did not improve from 0.77875

Epoch 00135: val_accuracy did not improve from 0.77875

Epoch 00136: val_accuracy did not improve from 0.77875

Epoch 00137: val_accuracy did not improve from 0.77875

Epoch 00138: val_accuracy did not improve from 0.77875

Epoch 00139: val_accuracy did not improve from 0.77875

Epoch 00140: val_accuracy did not improve from 0.77875

Epoch 00141: val_accuracy did not improve from 0.77875

Epoch 00142: val_accuracy did not improve from 0.77875

Epoch 00143: val_accuracy did not improve from 0.77875

Epoch 00144: val_accuracy did not improve from 0.77875

Epoch 00145: val_accuracy did not improve from 0.77875

Epoch 00146: val_accuracy did not improve from 0.77875

Epoch 00147: val_accuracy did not improve from 0.77875

Epoch 00148: val_accuracy did not improve from 0.77875

Epoch 00149: val_accuracy did not improve from 0.77875

Epoch 00150: val_accuracy did not improve from 0.77875

Epoch 00151: val_accuracy did not improve from 0.77875

Epoch 00152: val_accuracy did not improve from 0.77875

Epoch 00153: val_accuracy did not improve from 0.77875

Epoch 00154: val_accuracy did not improve from 0.77875

Epoch 00155: val_accuracy did not improve from 0.77875

Epoch 00156: val_accuracy did not improve from 0.77875

Epoch 00157: val_accuracy did not improve from 0.77875

Epoch 00158: val_accuracy did not improve from 0.77875

Epoch 00159: val_accuracy did not improve from 0.77875

Epoch 00160: val_accuracy did not improve from 0.77875

Epoch 00161: val_accuracy did not improve from 0.77875

Epoch 00162: val_accuracy did not improve from 0.77875

Epoch 00163: val_accuracy did not improve from 0.77875

Epoch 00164: val_accuracy did not improve from 0.77875

Epoch 00165: val_accuracy did not improve from 0.77875

Epoch 00166: val_accuracy did not improve from 0.77875

Epoch 00167: val_accuracy did not improve from 0.77875

Epoch 00168: val_accuracy did not improve from 0.77875

Epoch 00169: val_accuracy did not improve from 0.77875

Epoch 00170: val_accuracy did not improve from 0.77875

Epoch 00171: val_accuracy did not improve from 0.77875

Epoch 00172: val_accuracy did not improve from 0.77875

Epoch 00173: val_accuracy did not improve from 0.77875

Epoch 00174: val_accuracy did not improve from 0.77875

Epoch 00175: val_accuracy did not improve from 0.77875

Epoch 00176: val_accuracy did not improve from 0.77875

Epoch 00177: val_accuracy did not improve from 0.77875

Epoch 00178: val_accuracy did not improve from 0.77875

Epoch 00179: val_accuracy did not improve from 0.77875

Epoch 00180: val_accuracy did not improve from 0.77875

Epoch 00181: val_accuracy did not improve from 0.77875

Epoch 00182: val_accuracy did not improve from 0.77875

Epoch 00183: val_accuracy did not improve from 0.77875

Epoch 00184: val_accuracy did not improve from 0.77875

Epoch 00185: val_accuracy did not improve from 0.77875

Epoch 00186: val_accuracy did not improve from 0.77875

Epoch 00187: val_accuracy did not improve from 0.77875

Epoch 00188: val_accuracy did not improve from 0.77875

Epoch 00189: val_accuracy did not improve from 0.77875

Epoch 00190: val_accuracy did not improve from 0.77875

Epoch 00191: val_accuracy did not improve from 0.77875

Epoch 00192: val_accuracy did not improve from 0.77875

Epoch 00193: val_accuracy did not improve from 0.77875

Epoch 00194: val_accuracy did not improve from 0.77875

Epoch 00195: val_accuracy did not improve from 0.77875

Epoch 00196: val_accuracy did not improve from 0.77875

Epoch 00197: val_accuracy did not improve from 0.77875

Epoch 00198: val_accuracy did not improve from 0.77875

Epoch 00199: val_accuracy did not improve from 0.77875

Epoch 00200: val_accuracy did not improve from 0.77875
plotting history
plotting score distribution
plotting significance
finished plotting
for mass1=  2200 , mass2=  200
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
train on  5370  background 8836  signals, validate on  597 background 982 signals
26508 26508 2946 2946
start training on bin  33

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy did not improve from 0.50000

Epoch 00010: val_accuracy did not improve from 0.50000

Epoch 00011: val_accuracy did not improve from 0.50000

Epoch 00012: val_accuracy did not improve from 0.50000

Epoch 00013: val_accuracy did not improve from 0.50000

Epoch 00014: val_accuracy did not improve from 0.50000

Epoch 00015: val_accuracy did not improve from 0.50000

Epoch 00016: val_accuracy did not improve from 0.50000

Epoch 00017: val_accuracy did not improve from 0.50000

Epoch 00018: val_accuracy did not improve from 0.50000

Epoch 00019: val_accuracy did not improve from 0.50000

Epoch 00020: val_accuracy did not improve from 0.50000

Epoch 00021: val_accuracy did not improve from 0.50000

Epoch 00022: val_accuracy did not improve from 0.50000

Epoch 00023: val_accuracy did not improve from 0.50000

Epoch 00024: val_accuracy did not improve from 0.50000

Epoch 00025: val_accuracy did not improve from 0.50000

Epoch 00026: val_accuracy did not improve from 0.50000

Epoch 00027: val_accuracy did not improve from 0.50000

Epoch 00028: val_accuracy did not improve from 0.50000

Epoch 00029: val_accuracy did not improve from 0.50000

Epoch 00030: val_accuracy did not improve from 0.50000

Epoch 00031: val_accuracy did not improve from 0.50000

Epoch 00032: val_accuracy did not improve from 0.50000

Epoch 00033: val_accuracy did not improve from 0.50000

Epoch 00034: val_accuracy did not improve from 0.50000

Epoch 00035: val_accuracy did not improve from 0.50000

Epoch 00036: val_accuracy did not improve from 0.50000

Epoch 00037: val_accuracy did not improve from 0.50000

Epoch 00038: val_accuracy did not improve from 0.50000

Epoch 00039: val_accuracy did not improve from 0.50000

Epoch 00040: val_accuracy improved from 0.50000 to 0.50153, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00041: val_accuracy improved from 0.50153 to 0.50594, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00042: val_accuracy improved from 0.50594 to 0.52172, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00043: val_accuracy improved from 0.52172 to 0.53971, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00044: val_accuracy improved from 0.53971 to 0.57587, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00045: val_accuracy improved from 0.57587 to 0.61439, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00046: val_accuracy improved from 0.61439 to 0.64240, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00047: val_accuracy improved from 0.64240 to 0.68347, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00048: val_accuracy improved from 0.68347 to 0.72437, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00049: val_accuracy improved from 0.72437 to 0.74915, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00050: val_accuracy improved from 0.74915 to 0.77766, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00051: val_accuracy improved from 0.77766 to 0.79277, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00052: val_accuracy improved from 0.79277 to 0.80465, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00053: val_accuracy improved from 0.80465 to 0.81721, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00054: val_accuracy improved from 0.81721 to 0.82400, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00055: val_accuracy improved from 0.82400 to 0.82943, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00056: val_accuracy improved from 0.82943 to 0.83656, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00057: val_accuracy improved from 0.83656 to 0.84453, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00058: val_accuracy improved from 0.84453 to 0.84827, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00059: val_accuracy did not improve from 0.84827

Epoch 00060: val_accuracy did not improve from 0.84827

Epoch 00061: val_accuracy did not improve from 0.84827

Epoch 00062: val_accuracy did not improve from 0.84827

Epoch 00063: val_accuracy did not improve from 0.84827

Epoch 00064: val_accuracy did not improve from 0.84827

Epoch 00065: val_accuracy did not improve from 0.84827

Epoch 00066: val_accuracy did not improve from 0.84827

Epoch 00067: val_accuracy did not improve from 0.84827

Epoch 00068: val_accuracy did not improve from 0.84827

Epoch 00069: val_accuracy did not improve from 0.84827

Epoch 00070: val_accuracy did not improve from 0.84827

Epoch 00071: val_accuracy did not improve from 0.84827

Epoch 00072: val_accuracy did not improve from 0.84827

Epoch 00073: val_accuracy did not improve from 0.84827

Epoch 00074: val_accuracy did not improve from 0.84827

Epoch 00075: val_accuracy did not improve from 0.84827

Epoch 00076: val_accuracy did not improve from 0.84827

Epoch 00077: val_accuracy did not improve from 0.84827

Epoch 00078: val_accuracy did not improve from 0.84827

Epoch 00079: val_accuracy did not improve from 0.84827

Epoch 00080: val_accuracy did not improve from 0.84827

Epoch 00081: val_accuracy did not improve from 0.84827

Epoch 00082: val_accuracy did not improve from 0.84827

Epoch 00083: val_accuracy did not improve from 0.84827

Epoch 00084: val_accuracy did not improve from 0.84827

Epoch 00085: val_accuracy did not improve from 0.84827

Epoch 00086: val_accuracy did not improve from 0.84827

Epoch 00087: val_accuracy did not improve from 0.84827

Epoch 00088: val_accuracy did not improve from 0.84827

Epoch 00089: val_accuracy did not improve from 0.84827

Epoch 00090: val_accuracy did not improve from 0.84827

Epoch 00091: val_accuracy did not improve from 0.84827

Epoch 00092: val_accuracy did not improve from 0.84827

Epoch 00093: val_accuracy did not improve from 0.84827

Epoch 00094: val_accuracy did not improve from 0.84827

Epoch 00095: val_accuracy improved from 0.84827 to 0.84912, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00096: val_accuracy did not improve from 0.84912

Epoch 00097: val_accuracy did not improve from 0.84912

Epoch 00098: val_accuracy improved from 0.84912 to 0.84929, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00099: val_accuracy improved from 0.84929 to 0.85302, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00100: val_accuracy improved from 0.85302 to 0.85370, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00101: val_accuracy improved from 0.85370 to 0.85489, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00102: val_accuracy did not improve from 0.85489

Epoch 00103: val_accuracy improved from 0.85489 to 0.85523, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00104: val_accuracy did not improve from 0.85523

Epoch 00105: val_accuracy did not improve from 0.85523

Epoch 00106: val_accuracy did not improve from 0.85523

Epoch 00107: val_accuracy did not improve from 0.85523

Epoch 00108: val_accuracy did not improve from 0.85523

Epoch 00109: val_accuracy did not improve from 0.85523

Epoch 00110: val_accuracy did not improve from 0.85523

Epoch 00111: val_accuracy improved from 0.85523 to 0.85794, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00112: val_accuracy did not improve from 0.85794

Epoch 00113: val_accuracy did not improve from 0.85794

Epoch 00114: val_accuracy did not improve from 0.85794

Epoch 00115: val_accuracy did not improve from 0.85794

Epoch 00116: val_accuracy did not improve from 0.85794

Epoch 00117: val_accuracy did not improve from 0.85794

Epoch 00118: val_accuracy did not improve from 0.85794

Epoch 00119: val_accuracy did not improve from 0.85794

Epoch 00120: val_accuracy did not improve from 0.85794

Epoch 00121: val_accuracy did not improve from 0.85794

Epoch 00122: val_accuracy did not improve from 0.85794

Epoch 00123: val_accuracy did not improve from 0.85794

Epoch 00124: val_accuracy improved from 0.85794 to 0.85811, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00125: val_accuracy did not improve from 0.85811

Epoch 00126: val_accuracy did not improve from 0.85811

Epoch 00127: val_accuracy did not improve from 0.85811

Epoch 00128: val_accuracy did not improve from 0.85811

Epoch 00129: val_accuracy did not improve from 0.85811

Epoch 00130: val_accuracy did not improve from 0.85811

Epoch 00131: val_accuracy did not improve from 0.85811

Epoch 00132: val_accuracy did not improve from 0.85811

Epoch 00133: val_accuracy did not improve from 0.85811

Epoch 00134: val_accuracy did not improve from 0.85811

Epoch 00135: val_accuracy did not improve from 0.85811

Epoch 00136: val_accuracy did not improve from 0.85811

Epoch 00137: val_accuracy did not improve from 0.85811

Epoch 00138: val_accuracy did not improve from 0.85811

Epoch 00139: val_accuracy did not improve from 0.85811

Epoch 00140: val_accuracy did not improve from 0.85811

Epoch 00141: val_accuracy did not improve from 0.85811

Epoch 00142: val_accuracy did not improve from 0.85811

Epoch 00143: val_accuracy did not improve from 0.85811

Epoch 00144: val_accuracy did not improve from 0.85811

Epoch 00145: val_accuracy did not improve from 0.85811

Epoch 00146: val_accuracy did not improve from 0.85811

Epoch 00147: val_accuracy improved from 0.85811 to 0.86049, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00148: val_accuracy improved from 0.86049 to 0.86117, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00149: val_accuracy improved from 0.86117 to 0.86185, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00150: val_accuracy did not improve from 0.86185

Epoch 00151: val_accuracy improved from 0.86185 to 0.86219, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00152: val_accuracy did not improve from 0.86219

Epoch 00153: val_accuracy did not improve from 0.86219

Epoch 00154: val_accuracy did not improve from 0.86219

Epoch 00155: val_accuracy did not improve from 0.86219

Epoch 00156: val_accuracy did not improve from 0.86219

Epoch 00157: val_accuracy did not improve from 0.86219

Epoch 00158: val_accuracy did not improve from 0.86219

Epoch 00159: val_accuracy did not improve from 0.86219

Epoch 00160: val_accuracy did not improve from 0.86219

Epoch 00161: val_accuracy did not improve from 0.86219

Epoch 00162: val_accuracy did not improve from 0.86219

Epoch 00163: val_accuracy did not improve from 0.86219

Epoch 00164: val_accuracy did not improve from 0.86219

Epoch 00165: val_accuracy did not improve from 0.86219

Epoch 00166: val_accuracy did not improve from 0.86219

Epoch 00167: val_accuracy did not improve from 0.86219

Epoch 00168: val_accuracy did not improve from 0.86219

Epoch 00169: val_accuracy did not improve from 0.86219

Epoch 00170: val_accuracy did not improve from 0.86219

Epoch 00171: val_accuracy did not improve from 0.86219

Epoch 00172: val_accuracy did not improve from 0.86219

Epoch 00173: val_accuracy did not improve from 0.86219

Epoch 00174: val_accuracy improved from 0.86219 to 0.86236, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00175: val_accuracy did not improve from 0.86236

Epoch 00176: val_accuracy did not improve from 0.86236

Epoch 00177: val_accuracy did not improve from 0.86236

Epoch 00178: val_accuracy did not improve from 0.86236

Epoch 00179: val_accuracy improved from 0.86236 to 0.86270, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00180: val_accuracy did not improve from 0.86270

Epoch 00181: val_accuracy did not improve from 0.86270

Epoch 00182: val_accuracy improved from 0.86270 to 0.86337, saving model to weights_T1qqqq_bin_33_try4.best.hdf5

Epoch 00183: val_accuracy did not improve from 0.86337

Epoch 00184: val_accuracy did not improve from 0.86337

Epoch 00185: val_accuracy did not improve from 0.86337

Epoch 00186: val_accuracy did not improve from 0.86337

Epoch 00187: val_accuracy did not improve from 0.86337

Epoch 00188: val_accuracy did not improve from 0.86337

Epoch 00189: val_accuracy did not improve from 0.86337

Epoch 00190: val_accuracy did not improve from 0.86337

Epoch 00191: val_accuracy did not improve from 0.86337

Epoch 00192: val_accuracy did not improve from 0.86337

Epoch 00193: val_accuracy did not improve from 0.86337

Epoch 00194: val_accuracy did not improve from 0.86337

Epoch 00195: val_accuracy did not improve from 0.86337

Epoch 00196: val_accuracy did not improve from 0.86337

Epoch 00197: val_accuracy did not improve from 0.86337

Epoch 00198: val_accuracy did not improve from 0.86337

Epoch 00199: val_accuracy did not improve from 0.86337

Epoch 00200: val_accuracy did not improve from 0.86337
plotting history
plotting score distribution
plotting significance
finished plotting
train on  3131  background 9702  signals, validate on  348 background 1079 signals
29106 29106 3237 3237
start training on bin  65

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy did not improve from 0.50000

Epoch 00010: val_accuracy did not improve from 0.50000

Epoch 00011: val_accuracy did not improve from 0.50000

Epoch 00012: val_accuracy did not improve from 0.50000

Epoch 00013: val_accuracy did not improve from 0.50000

Epoch 00014: val_accuracy did not improve from 0.50000

Epoch 00015: val_accuracy did not improve from 0.50000

Epoch 00016: val_accuracy did not improve from 0.50000

Epoch 00017: val_accuracy did not improve from 0.50000

Epoch 00018: val_accuracy did not improve from 0.50000

Epoch 00019: val_accuracy did not improve from 0.50000

Epoch 00020: val_accuracy did not improve from 0.50000

Epoch 00021: val_accuracy did not improve from 0.50000

Epoch 00022: val_accuracy did not improve from 0.50000

Epoch 00023: val_accuracy did not improve from 0.50000

Epoch 00024: val_accuracy did not improve from 0.50000

Epoch 00025: val_accuracy did not improve from 0.50000

Epoch 00026: val_accuracy did not improve from 0.50000

Epoch 00027: val_accuracy did not improve from 0.50000

Epoch 00028: val_accuracy did not improve from 0.50000

Epoch 00029: val_accuracy did not improve from 0.50000

Epoch 00030: val_accuracy did not improve from 0.50000

Epoch 00031: val_accuracy did not improve from 0.50000

Epoch 00032: val_accuracy did not improve from 0.50000

Epoch 00033: val_accuracy did not improve from 0.50000

Epoch 00034: val_accuracy did not improve from 0.50000

Epoch 00035: val_accuracy did not improve from 0.50000

Epoch 00036: val_accuracy did not improve from 0.50000

Epoch 00037: val_accuracy did not improve from 0.50000

Epoch 00038: val_accuracy did not improve from 0.50000

Epoch 00039: val_accuracy did not improve from 0.50000

Epoch 00040: val_accuracy did not improve from 0.50000

Epoch 00041: val_accuracy improved from 0.50000 to 0.50062, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00042: val_accuracy improved from 0.50062 to 0.50525, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00043: val_accuracy improved from 0.50525 to 0.52240, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00044: val_accuracy improved from 0.52240 to 0.53537, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00045: val_accuracy improved from 0.53537 to 0.56688, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00046: val_accuracy improved from 0.56688 to 0.59361, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00047: val_accuracy improved from 0.59361 to 0.62790, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00048: val_accuracy improved from 0.62790 to 0.64767, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00049: val_accuracy improved from 0.64767 to 0.67717, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00050: val_accuracy improved from 0.67717 to 0.70575, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00051: val_accuracy improved from 0.70575 to 0.72459, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00052: val_accuracy improved from 0.72459 to 0.74853, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00053: val_accuracy improved from 0.74853 to 0.76352, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00054: val_accuracy improved from 0.76352 to 0.77989, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00055: val_accuracy improved from 0.77989 to 0.78514, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00056: val_accuracy improved from 0.78514 to 0.79178, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00057: val_accuracy improved from 0.79178 to 0.79379, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00058: val_accuracy improved from 0.79379 to 0.80028, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00059: val_accuracy improved from 0.80028 to 0.80244, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00060: val_accuracy improved from 0.80244 to 0.80507, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00061: val_accuracy improved from 0.80507 to 0.80985, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00062: val_accuracy did not improve from 0.80985

Epoch 00063: val_accuracy improved from 0.80985 to 0.81063, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00064: val_accuracy improved from 0.81063 to 0.81294, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00065: val_accuracy did not improve from 0.81294

Epoch 00066: val_accuracy did not improve from 0.81294

Epoch 00067: val_accuracy did not improve from 0.81294

Epoch 00068: val_accuracy did not improve from 0.81294

Epoch 00069: val_accuracy did not improve from 0.81294

Epoch 00070: val_accuracy did not improve from 0.81294

Epoch 00071: val_accuracy did not improve from 0.81294

Epoch 00072: val_accuracy did not improve from 0.81294

Epoch 00073: val_accuracy did not improve from 0.81294

Epoch 00074: val_accuracy did not improve from 0.81294

Epoch 00075: val_accuracy did not improve from 0.81294

Epoch 00076: val_accuracy did not improve from 0.81294

Epoch 00077: val_accuracy did not improve from 0.81294

Epoch 00078: val_accuracy did not improve from 0.81294

Epoch 00079: val_accuracy did not improve from 0.81294

Epoch 00080: val_accuracy did not improve from 0.81294

Epoch 00081: val_accuracy did not improve from 0.81294

Epoch 00082: val_accuracy did not improve from 0.81294

Epoch 00083: val_accuracy did not improve from 0.81294

Epoch 00084: val_accuracy did not improve from 0.81294

Epoch 00085: val_accuracy did not improve from 0.81294

Epoch 00086: val_accuracy did not improve from 0.81294

Epoch 00087: val_accuracy did not improve from 0.81294

Epoch 00088: val_accuracy did not improve from 0.81294

Epoch 00089: val_accuracy did not improve from 0.81294

Epoch 00090: val_accuracy did not improve from 0.81294

Epoch 00091: val_accuracy did not improve from 0.81294

Epoch 00092: val_accuracy did not improve from 0.81294

Epoch 00093: val_accuracy did not improve from 0.81294

Epoch 00094: val_accuracy did not improve from 0.81294

Epoch 00095: val_accuracy improved from 0.81294 to 0.81495, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00096: val_accuracy did not improve from 0.81495

Epoch 00097: val_accuracy did not improve from 0.81495

Epoch 00098: val_accuracy improved from 0.81495 to 0.81850, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00099: val_accuracy did not improve from 0.81850

Epoch 00100: val_accuracy did not improve from 0.81850

Epoch 00101: val_accuracy did not improve from 0.81850

Epoch 00102: val_accuracy did not improve from 0.81850

Epoch 00103: val_accuracy did not improve from 0.81850

Epoch 00104: val_accuracy did not improve from 0.81850

Epoch 00105: val_accuracy did not improve from 0.81850

Epoch 00106: val_accuracy did not improve from 0.81850

Epoch 00107: val_accuracy did not improve from 0.81850

Epoch 00108: val_accuracy improved from 0.81850 to 0.82082, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00109: val_accuracy did not improve from 0.82082

Epoch 00110: val_accuracy did not improve from 0.82082

Epoch 00111: val_accuracy did not improve from 0.82082

Epoch 00112: val_accuracy did not improve from 0.82082

Epoch 00113: val_accuracy did not improve from 0.82082

Epoch 00114: val_accuracy did not improve from 0.82082

Epoch 00115: val_accuracy improved from 0.82082 to 0.82113, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00116: val_accuracy improved from 0.82113 to 0.82129, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00117: val_accuracy improved from 0.82129 to 0.82268, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00118: val_accuracy did not improve from 0.82268

Epoch 00119: val_accuracy did not improve from 0.82268

Epoch 00120: val_accuracy did not improve from 0.82268

Epoch 00121: val_accuracy did not improve from 0.82268

Epoch 00122: val_accuracy did not improve from 0.82268

Epoch 00123: val_accuracy did not improve from 0.82268

Epoch 00124: val_accuracy did not improve from 0.82268

Epoch 00125: val_accuracy improved from 0.82268 to 0.82283, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00126: val_accuracy did not improve from 0.82283

Epoch 00127: val_accuracy did not improve from 0.82283

Epoch 00128: val_accuracy did not improve from 0.82283

Epoch 00129: val_accuracy did not improve from 0.82283

Epoch 00130: val_accuracy did not improve from 0.82283

Epoch 00131: val_accuracy did not improve from 0.82283

Epoch 00132: val_accuracy did not improve from 0.82283

Epoch 00133: val_accuracy did not improve from 0.82283

Epoch 00134: val_accuracy did not improve from 0.82283

Epoch 00135: val_accuracy did not improve from 0.82283

Epoch 00136: val_accuracy did not improve from 0.82283

Epoch 00137: val_accuracy did not improve from 0.82283

Epoch 00138: val_accuracy did not improve from 0.82283

Epoch 00139: val_accuracy did not improve from 0.82283

Epoch 00140: val_accuracy did not improve from 0.82283

Epoch 00141: val_accuracy did not improve from 0.82283

Epoch 00142: val_accuracy did not improve from 0.82283

Epoch 00143: val_accuracy did not improve from 0.82283

Epoch 00144: val_accuracy did not improve from 0.82283

Epoch 00145: val_accuracy did not improve from 0.82283

Epoch 00146: val_accuracy did not improve from 0.82283

Epoch 00147: val_accuracy did not improve from 0.82283

Epoch 00148: val_accuracy did not improve from 0.82283

Epoch 00149: val_accuracy did not improve from 0.82283

Epoch 00150: val_accuracy did not improve from 0.82283

Epoch 00151: val_accuracy did not improve from 0.82283

Epoch 00152: val_accuracy did not improve from 0.82283

Epoch 00153: val_accuracy did not improve from 0.82283

Epoch 00154: val_accuracy did not improve from 0.82283

Epoch 00155: val_accuracy did not improve from 0.82283

Epoch 00156: val_accuracy did not improve from 0.82283

Epoch 00157: val_accuracy did not improve from 0.82283

Epoch 00158: val_accuracy did not improve from 0.82283

Epoch 00159: val_accuracy did not improve from 0.82283

Epoch 00160: val_accuracy did not improve from 0.82283

Epoch 00161: val_accuracy did not improve from 0.82283

Epoch 00162: val_accuracy did not improve from 0.82283

Epoch 00163: val_accuracy did not improve from 0.82283

Epoch 00164: val_accuracy did not improve from 0.82283

Epoch 00165: val_accuracy did not improve from 0.82283

Epoch 00166: val_accuracy did not improve from 0.82283

Epoch 00167: val_accuracy did not improve from 0.82283

Epoch 00168: val_accuracy did not improve from 0.82283

Epoch 00169: val_accuracy did not improve from 0.82283

Epoch 00170: val_accuracy did not improve from 0.82283

Epoch 00171: val_accuracy did not improve from 0.82283

Epoch 00172: val_accuracy improved from 0.82283 to 0.82345, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00173: val_accuracy did not improve from 0.82345

Epoch 00174: val_accuracy improved from 0.82345 to 0.82453, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00175: val_accuracy improved from 0.82453 to 0.82499, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00176: val_accuracy did not improve from 0.82499

Epoch 00177: val_accuracy improved from 0.82499 to 0.82546, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00178: val_accuracy improved from 0.82546 to 0.82607, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00179: val_accuracy did not improve from 0.82607

Epoch 00180: val_accuracy did not improve from 0.82607

Epoch 00181: val_accuracy improved from 0.82607 to 0.82669, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00182: val_accuracy did not improve from 0.82669

Epoch 00183: val_accuracy improved from 0.82669 to 0.82777, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00184: val_accuracy did not improve from 0.82777

Epoch 00185: val_accuracy did not improve from 0.82777

Epoch 00186: val_accuracy did not improve from 0.82777

Epoch 00187: val_accuracy did not improve from 0.82777

Epoch 00188: val_accuracy did not improve from 0.82777

Epoch 00189: val_accuracy did not improve from 0.82777

Epoch 00190: val_accuracy did not improve from 0.82777

Epoch 00191: val_accuracy improved from 0.82777 to 0.82839, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00192: val_accuracy improved from 0.82839 to 0.82901, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00193: val_accuracy improved from 0.82901 to 0.82947, saving model to weights_T1qqqq_bin_65_try4.best.hdf5

Epoch 00194: val_accuracy did not improve from 0.82947

Epoch 00195: val_accuracy did not improve from 0.82947

Epoch 00196: val_accuracy did not improve from 0.82947

Epoch 00197: val_accuracy did not improve from 0.82947

Epoch 00198: val_accuracy did not improve from 0.82947

Epoch 00199: val_accuracy did not improve from 0.82947

Epoch 00200: val_accuracy did not improve from 0.82947
plotting history
plotting score distribution
plotting significance
finished plotting
train on  19175  background 19373  signals, validate on  2131 background 2153 signals
58119 58119 6459 6459
start training on bin  28

Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00002: val_accuracy did not improve from 0.50000

Epoch 00003: val_accuracy did not improve from 0.50000

Epoch 00004: val_accuracy did not improve from 0.50000

Epoch 00005: val_accuracy did not improve from 0.50000

Epoch 00006: val_accuracy did not improve from 0.50000

Epoch 00007: val_accuracy did not improve from 0.50000

Epoch 00008: val_accuracy did not improve from 0.50000

Epoch 00009: val_accuracy did not improve from 0.50000

Epoch 00010: val_accuracy did not improve from 0.50000

Epoch 00011: val_accuracy did not improve from 0.50000

Epoch 00012: val_accuracy did not improve from 0.50000

Epoch 00013: val_accuracy did not improve from 0.50000

Epoch 00014: val_accuracy did not improve from 0.50000

Epoch 00015: val_accuracy did not improve from 0.50000

Epoch 00016: val_accuracy did not improve from 0.50000

Epoch 00017: val_accuracy did not improve from 0.50000

Epoch 00018: val_accuracy did not improve from 0.50000

Epoch 00019: val_accuracy did not improve from 0.50000

Epoch 00020: val_accuracy improved from 0.50000 to 0.50008, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00021: val_accuracy improved from 0.50008 to 0.52237, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00022: val_accuracy improved from 0.52237 to 0.61232, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00023: val_accuracy improved from 0.61232 to 0.71226, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00024: val_accuracy improved from 0.71226 to 0.79083, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00025: val_accuracy improved from 0.79083 to 0.82157, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00026: val_accuracy improved from 0.82157 to 0.83867, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00027: val_accuracy improved from 0.83867 to 0.84967, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00028: val_accuracy improved from 0.84967 to 0.85741, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00029: val_accuracy improved from 0.85741 to 0.85872, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00030: val_accuracy improved from 0.85872 to 0.85973, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00031: val_accuracy did not improve from 0.85973

Epoch 00032: val_accuracy did not improve from 0.85973

Epoch 00033: val_accuracy did not improve from 0.85973

Epoch 00034: val_accuracy did not improve from 0.85973

Epoch 00035: val_accuracy did not improve from 0.85973

Epoch 00036: val_accuracy did not improve from 0.85973

Epoch 00037: val_accuracy improved from 0.85973 to 0.86004, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00038: val_accuracy did not improve from 0.86004

Epoch 00039: val_accuracy improved from 0.86004 to 0.86066, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00040: val_accuracy did not improve from 0.86066

Epoch 00041: val_accuracy improved from 0.86066 to 0.86112, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00042: val_accuracy improved from 0.86112 to 0.86159, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00043: val_accuracy improved from 0.86159 to 0.86267, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00044: val_accuracy did not improve from 0.86267

Epoch 00045: val_accuracy did not improve from 0.86267

Epoch 00046: val_accuracy did not improve from 0.86267

Epoch 00047: val_accuracy did not improve from 0.86267

Epoch 00048: val_accuracy did not improve from 0.86267

Epoch 00049: val_accuracy did not improve from 0.86267

Epoch 00050: val_accuracy did not improve from 0.86267

Epoch 00051: val_accuracy did not improve from 0.86267

Epoch 00052: val_accuracy did not improve from 0.86267

Epoch 00053: val_accuracy did not improve from 0.86267

Epoch 00054: val_accuracy did not improve from 0.86267

Epoch 00055: val_accuracy did not improve from 0.86267

Epoch 00056: val_accuracy did not improve from 0.86267

Epoch 00057: val_accuracy did not improve from 0.86267

Epoch 00058: val_accuracy did not improve from 0.86267

Epoch 00059: val_accuracy did not improve from 0.86267

Epoch 00060: val_accuracy did not improve from 0.86267

Epoch 00061: val_accuracy did not improve from 0.86267

Epoch 00062: val_accuracy did not improve from 0.86267

Epoch 00063: val_accuracy did not improve from 0.86267

Epoch 00064: val_accuracy did not improve from 0.86267

Epoch 00065: val_accuracy did not improve from 0.86267

Epoch 00066: val_accuracy did not improve from 0.86267

Epoch 00067: val_accuracy did not improve from 0.86267

Epoch 00068: val_accuracy did not improve from 0.86267

Epoch 00069: val_accuracy did not improve from 0.86267

Epoch 00070: val_accuracy did not improve from 0.86267

Epoch 00071: val_accuracy did not improve from 0.86267

Epoch 00072: val_accuracy did not improve from 0.86267

Epoch 00073: val_accuracy did not improve from 0.86267

Epoch 00074: val_accuracy did not improve from 0.86267

Epoch 00075: val_accuracy improved from 0.86267 to 0.86275, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00076: val_accuracy improved from 0.86275 to 0.86329, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00077: val_accuracy improved from 0.86329 to 0.86422, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00078: val_accuracy did not improve from 0.86422

Epoch 00079: val_accuracy did not improve from 0.86422

Epoch 00080: val_accuracy did not improve from 0.86422

Epoch 00081: val_accuracy did not improve from 0.86422

Epoch 00082: val_accuracy did not improve from 0.86422

Epoch 00083: val_accuracy did not improve from 0.86422

Epoch 00084: val_accuracy did not improve from 0.86422

Epoch 00085: val_accuracy did not improve from 0.86422

Epoch 00086: val_accuracy did not improve from 0.86422

Epoch 00087: val_accuracy did not improve from 0.86422

Epoch 00088: val_accuracy did not improve from 0.86422

Epoch 00089: val_accuracy did not improve from 0.86422

Epoch 00090: val_accuracy improved from 0.86422 to 0.86430, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00091: val_accuracy did not improve from 0.86430

Epoch 00092: val_accuracy did not improve from 0.86430

Epoch 00093: val_accuracy improved from 0.86430 to 0.86507, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00094: val_accuracy did not improve from 0.86507

Epoch 00095: val_accuracy did not improve from 0.86507

Epoch 00096: val_accuracy did not improve from 0.86507

Epoch 00097: val_accuracy did not improve from 0.86507

Epoch 00098: val_accuracy did not improve from 0.86507

Epoch 00099: val_accuracy improved from 0.86507 to 0.86530, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00100: val_accuracy did not improve from 0.86530

Epoch 00101: val_accuracy improved from 0.86530 to 0.86561, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00102: val_accuracy improved from 0.86561 to 0.86616, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00103: val_accuracy improved from 0.86616 to 0.86631, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00104: val_accuracy did not improve from 0.86631

Epoch 00105: val_accuracy improved from 0.86631 to 0.86639, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00106: val_accuracy did not improve from 0.86639

Epoch 00107: val_accuracy did not improve from 0.86639

Epoch 00108: val_accuracy did not improve from 0.86639

Epoch 00109: val_accuracy did not improve from 0.86639

Epoch 00110: val_accuracy did not improve from 0.86639

Epoch 00111: val_accuracy did not improve from 0.86639

Epoch 00112: val_accuracy did not improve from 0.86639

Epoch 00113: val_accuracy did not improve from 0.86639

Epoch 00114: val_accuracy did not improve from 0.86639

Epoch 00115: val_accuracy did not improve from 0.86639

Epoch 00116: val_accuracy improved from 0.86639 to 0.86654, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00117: val_accuracy did not improve from 0.86654

Epoch 00118: val_accuracy did not improve from 0.86654

Epoch 00119: val_accuracy did not improve from 0.86654

Epoch 00120: val_accuracy improved from 0.86654 to 0.86670, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00121: val_accuracy improved from 0.86670 to 0.86693, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00122: val_accuracy did not improve from 0.86693

Epoch 00123: val_accuracy did not improve from 0.86693

Epoch 00124: val_accuracy did not improve from 0.86693

Epoch 00125: val_accuracy did not improve from 0.86693

Epoch 00126: val_accuracy did not improve from 0.86693

Epoch 00127: val_accuracy improved from 0.86693 to 0.86701, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00128: val_accuracy did not improve from 0.86701

Epoch 00129: val_accuracy did not improve from 0.86701

Epoch 00130: val_accuracy did not improve from 0.86701

Epoch 00131: val_accuracy did not improve from 0.86701

Epoch 00132: val_accuracy did not improve from 0.86701

Epoch 00133: val_accuracy did not improve from 0.86701

Epoch 00134: val_accuracy improved from 0.86701 to 0.86708, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00135: val_accuracy did not improve from 0.86708

Epoch 00136: val_accuracy improved from 0.86708 to 0.86770, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00137: val_accuracy improved from 0.86770 to 0.86794, saving model to weights_T1qqqq_bin_28_try4.best.hdf5

Epoch 00138: val_accuracy did not improve from 0.86794

Epoch 00139: val_accuracy did not improve from 0.86794

Epoch 00140: val_accuracy did not improve from 0.86794

Epoch 00141: val_accuracy did not improve from 0.86794

Epoch 00142: val_accuracy did not improve from 0.86794

Epoch 00143: val_accuracy did not improve from 0.86794

Epoch 00144: val_accuracy did not improve from 0.86794

Epoch 00145: val_accuracy did not improve from 0.86794

Epoch 00146: val_accuracy did not improve from 0.86794

Epoch 00147: val_accuracy did not improve from 0.86794

Epoch 00148: val_accuracy did not improve from 0.86794

Epoch 00149: val_accuracy did not improve from 0.86794

Epoch 00150: val_accuracy did not improve from 0.86794

Epoch 00151: val_accuracy did not improve from 0.86794

Epoch 00152: val_accuracy did not improve from 0.86794

Epoch 00153: val_accuracy did not improve from 0.86794

Epoch 00154: val_accuracy did not improve from 0.86794

Epoch 00155: val_accuracy did not improve from 0.86794

Epoch 00156: val_accuracy did not improve from 0.86794

Epoch 00157: val_accuracy did not improve from 0.86794

Epoch 00158: val_accuracy did not improve from 0.86794

Epoch 00159: val_accuracy did not improve from 0.86794

Epoch 00160: val_accuracy did not improve from 0.86794

Epoch 00161: val_accuracy did not improve from 0.86794

Epoch 00162: val_accuracy did not improve from 0.86794

Epoch 00163: val_accuracy did not improve from 0.86794

Epoch 00164: val_accuracy did not improve from 0.86794

Epoch 00165: val_accuracy did not improve from 0.86794

Epoch 00166: val_accuracy did not improve from 0.86794

Epoch 00167: val_accuracy did not improve from 0.86794

Epoch 00168: val_accuracy did not improve from 0.86794

Epoch 00169: val_accuracy did not improve from 0.86794

Epoch 00170: val_accuracy did not improve from 0.86794

Epoch 00171: val_accuracy did not improve from 0.86794

Epoch 00172: val_accuracy did not improve from 0.86794

Epoch 00173: val_accuracy did not improve from 0.86794

Epoch 00174: val_accuracy did not improve from 0.86794

Epoch 00175: val_accuracy did not improve from 0.86794

Epoch 00176: val_accuracy did not improve from 0.86794

Epoch 00177: val_accuracy did not improve from 0.86794

Epoch 00178: val_accuracy did not improve from 0.86794

Epoch 00179: val_accuracy did not improve from 0.86794

Epoch 00180: val_accuracy did not improve from 0.86794

Epoch 00181: val_accuracy did not improve from 0.86794

Epoch 00182: val_accuracy did not improve from 0.86794

Epoch 00183: val_accuracy did not improve from 0.86794

Epoch 00184: val_accuracy did not improve from 0.86794

Epoch 00185: val_accuracy did not improve from 0.86794

Epoch 00186: val_accuracy did not improve from 0.86794

Epoch 00187: val_accuracy did not improve from 0.86794

Epoch 00188: val_accuracy did not improve from 0.86794

Epoch 00189: val_accuracy did not improve from 0.86794

Epoch 00190: val_accuracy did not improve from 0.86794

Epoch 00191: val_accuracy did not improve from 0.86794

Epoch 00192: val_accuracy did not improve from 0.86794

Epoch 00193: val_accuracy did not improve from 0.86794

Epoch 00194: val_accuracy did not improve from 0.86794

Epoch 00195: val_accuracy did not improve from 0.86794

Epoch 00196: val_accuracy did not improve from 0.86794

Epoch 00197: val_accuracy did not improve from 0.86794

Epoch 00198: val_accuracy did not improve from 0.86794

Epoch 00199: val_accuracy did not improve from 0.86794

Epoch 00200: val_accuracy did not improve from 0.86794
plotting history
plotting score distribution
plotting significance
finished plotting
for mass1=  2200 , mass2=  800
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
plotting significance
finished plotting
